{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "### local imports \n",
    "from src.environment import EnvironmentObjective\n",
    "from src.vanillagp import step\n",
    "from src.policy import MyMLP,MyMLP2\n",
    "\n",
    "### botorch\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "### general imports\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "### Logging \n",
    "import logging\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Toy kernel for warningging\n",
    "\n",
    "class MyKernel(gpytorch.kernels.RBFKernel):\n",
    "   \n",
    "    def forward(self,x1,x2,**params):\n",
    "        \n",
    "        logger.warning(f'x1 {x1.shape} / x2 {x2.shape}')\n",
    "        kernel = super().forward(x1,x2,**params)\n",
    "        logger.warning(f'pair kernel {kernel.shape}')\n",
    "        return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import *\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "class GridKernel(Kernel):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 policy,states):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #tester = PolicyTester(policy,states)\n",
    "        tester = PolicyTester(states)\n",
    "        rbf_module = ScaleKernel(RBFKernel(ard_num_dims=states.shape[0]))\n",
    "\n",
    "        # save params to instance\n",
    "        self.__dict__.update(locals())\n",
    "        \n",
    "        \n",
    "    def forward(self,x1,x2,**params):\n",
    "        \n",
    "        #logger.warning(f'x1 {x1.shape} / x2 {x2.shape}')\n",
    "        \n",
    "        #Evaluate current parameters\n",
    "        \n",
    "        actions2 = self.tester(x2).squeeze()#temp\n",
    "        actions1 = self.tester(x1).squeeze()#temp\n",
    "        #logger.critical(f'actions1 {actions1.shape} actions2 {actions2.shape} ')\n",
    "        print(f'actions1 {actions1.shape} actions2 {actions2.shape} ')\n",
    "        \n",
    "        # Compute pairwise pairwise kernel \n",
    "        \n",
    "        kernel = self.rbf_module(actions1, actions2, **params)\n",
    "        logger.warning(f'pair kernel {kernel.shape}')\n",
    "        \n",
    "        return kernel\n",
    "        \n",
    "        \n",
    "class PolicyTester():\n",
    "    \n",
    "    def __init__(self,states):\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "    \n",
    "    def compute_actions(self,states,params_batch):\n",
    "        \n",
    "        logger.warning(f'Tester : params_batch.shape{params_batch.shape}')\n",
    "        mlp = MyMLP([3,1],params_batch)\n",
    "        return mlp(states)\n",
    "        \n",
    "        ## linear policy hotfix\n",
    "        # print(f'params_batch{params_batch.shape}/ states{states.shape}')\n",
    "        # return params_batch@states.T\n",
    "    \n",
    "    def __call__(self,params_batch):\n",
    "        \n",
    "        return self.compute_actions(self.states,\n",
    "                                    params_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "\n",
    "class GridGPModel(ExactGP,GPyTorchModel):\n",
    "    \n",
    "    _num_outputs = 1\n",
    "    \n",
    "    def __init__(self, train_x, train_y, likelihood,\n",
    "                 mlp,states):\n",
    "        \n",
    "        ExactGP.__init__(self, train_x, train_y, likelihood)\n",
    "        self.covar_module = GridKernel(mlp,states)\n",
    "        #self.covar_module = MyKernel()\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env=gym.make(\"Pendulum-v1\")\n",
    "# # env.reset()\n",
    "# # env.step(env.action_space.sample())\n",
    "# env.__dict__\n",
    "\n",
    "# box = env._observation_space\n",
    "# low,high = box.low,box.high \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize policy\n",
    "mlp = MyMLP2([3,1])\n",
    "\n",
    "# Initialize environment\n",
    "\n",
    "objective_env = EnvironmentObjective(\n",
    "  env=gym.make(\"Pendulum-v1\"),\n",
    "  policy=mlp,\n",
    "  manipulate_state=None,\n",
    "  manipulate_reward=None,\n",
    ")\n",
    "\n",
    "### initialize train_x, train_y\n",
    "train_x = torch.rand(100,mlp.len_params) ## [n_trials,n_params]\n",
    "train_y = [objective_env.run(p) for p in train_x]\n",
    "train_y = torch.Tensor(train_y).reshape(-1)  ## [n_trials,1]\n",
    "\n",
    "# initialize likelihood and model\n",
    "\n",
    "states = objective_env.get_grid()\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GridGPModel(train_x, train_y, likelihood,\n",
    "                    mlp,states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "Tester : params_batch.shapetorch.Size([100, 3])\n",
      "pair kernel torch.Size([100, 100])\n",
      "Tester : params_batch.shapetorch.Size([1, 101, 3])\n",
      "Tester : params_batch.shapetorch.Size([1, 1, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([100, 3])\n",
      "MyMLP weight size torch.Size([100, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([100, 1, 3])\n",
      "forward: output.shape torch.Size([100, 1, 1000])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "MyMLP received params with shape torch.Size([1, 101, 3])\n",
      "MyMLP weight size torch.Size([1, 101, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([1, 101, 1, 3])\n",
      "forward: output.shape torch.Size([1, 101, 1, 1000])\n",
      "MyMLP received params with shape torch.Size([1, 1, 3])\n",
      "MyMLP weight size torch.Size([1, 1, 1, 3])\n",
      "forward: states.shape torch.Size([1000, 3]) params_batch.shape torch.Size([1, 1, 1, 3])\n",
      "forward: output.shape torch.Size([1, 1, 1, 1000])\n",
      "actions1 torch.Size([1000]) actions2 torch.Size([101, 1000]) \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "x1_ and x2_ must have the same number of dimensions!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/kernel.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000006?line=1'>2</a>\u001b[0m max_iter \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000006?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iter):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000006?line=5'>6</a>\u001b[0m   step(model,objective_env)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000006?line=7'>8</a>\u001b[0m   \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000006?line=9'>10</a>\u001b[0m     best_val \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain_targets\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/vanillagp.py:23\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(model, objective_env)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=19'>20</a>\u001b[0m len_params \u001b[39m=\u001b[39m objective_env\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mlen_params\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=20'>21</a>\u001b[0m EI \u001b[39m=\u001b[39m ExpectedImprovement(model\u001b[39m=\u001b[39mmodel, best_f\u001b[39m=\u001b[39mbest_value)\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=22'>23</a>\u001b[0m new_x, _ \u001b[39m=\u001b[39m optimize_acqf(\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=23'>24</a>\u001b[0m   acq_function\u001b[39m=\u001b[39;49mEI,\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=24'>25</a>\u001b[0m   bounds\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m0.0\u001b[39;49m] \u001b[39m*\u001b[39;49m len_params, [\u001b[39m1.0\u001b[39;49m] \u001b[39m*\u001b[39;49m len_params]),\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=25'>26</a>\u001b[0m   q\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=26'>27</a>\u001b[0m   num_restarts\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=27'>28</a>\u001b[0m   raw_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=28'>29</a>\u001b[0m   options\u001b[39m=\u001b[39;49m{},\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=29'>30</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=31'>32</a>\u001b[0m new_y \u001b[39m=\u001b[39m objective_env(new_x)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=32'>33</a>\u001b[0m \u001b[39m#logger.warning(f'new_x.requires_grad {new_x.requires_grad}')\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/vanillagp.py?line=33'>34</a>\u001b[0m \u001b[39m### Update training points.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py:205\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=195'>196</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=196'>197</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMust specify `raw_samples` when `batch_initial_conditions` is `None`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=197'>198</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=199'>200</a>\u001b[0m     ic_gen \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=200'>201</a>\u001b[0m         gen_one_shot_kg_initial_conditions\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=201'>202</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(acq_function, qKnowledgeGradient)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=202'>203</a>\u001b[0m         \u001b[39melse\u001b[39;00m gen_batch_initial_conditions\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=203'>204</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=204'>205</a>\u001b[0m     batch_initial_conditions \u001b[39m=\u001b[39m ic_gen(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=205'>206</a>\u001b[0m         acq_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=206'>207</a>\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=207'>208</a>\u001b[0m         q\u001b[39m=\u001b[39;49mq,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=208'>209</a>\u001b[0m         num_restarts\u001b[39m=\u001b[39;49mnum_restarts,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=209'>210</a>\u001b[0m         raw_samples\u001b[39m=\u001b[39;49mraw_samples,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=210'>211</a>\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=211'>212</a>\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=212'>213</a>\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=213'>214</a>\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=214'>215</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=216'>217</a>\u001b[0m batch_limit: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=217'>218</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbatch_limit\u001b[39m\u001b[39m\"\u001b[39m, num_restarts \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nonlinear_inequality_constraints \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=218'>219</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=219'>220</a>\u001b[0m batch_candidates_list: List[Tensor] \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py:183\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=180'>181</a>\u001b[0m \u001b[39mwhile\u001b[39;00m start_idx \u001b[39m<\u001b[39m X_rnd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=181'>182</a>\u001b[0m     end_idx \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start_idx \u001b[39m+\u001b[39m batch_limit, X_rnd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=182'>183</a>\u001b[0m     Y_rnd_curr \u001b[39m=\u001b[39m acq_function(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=183'>184</a>\u001b[0m         X_rnd[start_idx:end_idx]\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=184'>185</a>\u001b[0m     )\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=185'>186</a>\u001b[0m     Y_rnd_list\u001b[39m.\u001b[39mappend(Y_rnd_curr)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=186'>187</a>\u001b[0m     start_idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_limit\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py:258\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=255'>256</a>\u001b[0m \u001b[39m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=256'>257</a>\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=257'>258</a>\u001b[0m output \u001b[39m=\u001b[39m method(acqf, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=258'>259</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(acqf, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m is_fully_bayesian(acqf\u001b[39m.\u001b[39mmodel):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=259'>260</a>\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py:130\u001b[0m, in \u001b[0;36mExpectedImprovement.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=116'>117</a>\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Evaluate Expected Improvement on the candidate set X.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=117'>118</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=118'>119</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=126'>127</a>\u001b[0m \u001b[39m    given design points `X`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=127'>128</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=128'>129</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_f\u001b[39m.\u001b[39mto(X)\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=129'>130</a>\u001b[0m posterior \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mposterior(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=130'>131</a>\u001b[0m     X\u001b[39m=\u001b[39;49mX, posterior_transform\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposterior_transform\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=131'>132</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=132'>133</a>\u001b[0m mean \u001b[39m=\u001b[39m posterior\u001b[39m.\u001b[39mmean\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/acquisition/analytic.py?line=133'>134</a>\u001b[0m \u001b[39m# deal with batch evaluation and broadcasting\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py:148\u001b[0m, in \u001b[0;36mGPyTorchModel.posterior\u001b[0;34m(self, X, observation_noise, posterior_transform, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py?line=145'>146</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_inputs(X)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py?line=146'>147</a>\u001b[0m \u001b[39mwith\u001b[39;00m gpt_posterior_settings():\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py?line=147'>148</a>\u001b[0m     mvn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(X)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py?line=148'>149</a>\u001b[0m     \u001b[39mif\u001b[39;00m observation_noise \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py?line=149'>150</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(observation_noise):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/models/gpytorch.py?line=150'>151</a>\u001b[0m             \u001b[39m# TODO: Make sure observation noise is transformed correctly\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_gp.py:319\u001b[0m, in \u001b[0;36mExactGP.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_gp.py?line=316'>317</a>\u001b[0m \u001b[39m# Make the prediction\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_gp.py?line=317'>318</a>\u001b[0m \u001b[39mwith\u001b[39;00m settings\u001b[39m.\u001b[39m_use_eval_tolerance():\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_gp.py?line=318'>319</a>\u001b[0m     predictive_mean, predictive_covar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprediction_strategy\u001b[39m.\u001b[39;49mexact_prediction(full_mean, full_covar)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_gp.py?line=320'>321</a>\u001b[0m \u001b[39m# Reshape predictive mean to match the appropriate event shape\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_gp.py?line=321'>322</a>\u001b[0m predictive_mean \u001b[39m=\u001b[39m predictive_mean\u001b[39m.\u001b[39mview(\u001b[39m*\u001b[39mbatch_shape, \u001b[39m*\u001b[39mtest_shape)\u001b[39m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py:254\u001b[0m, in \u001b[0;36mDefaultPredictionStrategy.exact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py?line=251'>252</a>\u001b[0m \u001b[39m# For efficiency - we can make things more efficient\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py?line=252'>253</a>\u001b[0m \u001b[39mif\u001b[39;00m joint_covar\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mmax_eager_kernel_size\u001b[39m.\u001b[39mvalue():\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py?line=253'>254</a>\u001b[0m     test_covar \u001b[39m=\u001b[39m joint_covar[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_train :, :]\u001b[39m.\u001b[39;49mevaluate()\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py?line=254'>255</a>\u001b[0m     test_test_covar \u001b[39m=\u001b[39m test_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train :]\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py?line=255'>256</a>\u001b[0m     test_train_covar \u001b[39m=\u001b[39m test_covar[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_train]\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=56'>57</a>\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=57'>58</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=58'>59</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=59'>60</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:353\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=350'>351</a>\u001b[0m \u001b[39m@cached\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=351'>352</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=352'>353</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_kernel()\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=56'>57</a>\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=57'>58</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=58'>59</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/utils/memoize.py?line=59'>60</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:332\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=329'>330</a>\u001b[0m     temp_active_dims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=330'>331</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=331'>332</a>\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=332'>333</a>\u001b[0m         x1,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=333'>334</a>\u001b[0m         x2,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=334'>335</a>\u001b[0m         diag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=335'>336</a>\u001b[0m         last_dim_is_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_dim_is_batch,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=336'>337</a>\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=337'>338</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=338'>339</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m temp_active_dims\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py?line=340'>341</a>\u001b[0m \u001b[39m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:402\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=399'>400</a>\u001b[0m     res \u001b[39m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, last_dim_is_batch\u001b[39m=\u001b[39mlast_dim_is_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=400'>401</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=401'>402</a>\u001b[0m     res \u001b[39m=\u001b[39m lazify(\u001b[39msuper\u001b[39;49m(Kernel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x1_, x2_, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams))\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=402'>403</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=29'>30</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=31'>32</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/kernel.ipynb Cell 4'\u001b[0m in \u001b[0;36mGridKernel.forward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000003?line=27'>28</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mactions1 \u001b[39m\u001b[39m{\u001b[39;00mactions1\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m actions2 \u001b[39m\u001b[39m{\u001b[39;00mactions2\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000003?line=29'>30</a>\u001b[0m \u001b[39m# Compute pairwise pairwise kernel \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000003?line=31'>32</a>\u001b[0m kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrbf_module(actions1, actions2, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000003?line=32'>33</a>\u001b[0m logger\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpair kernel \u001b[39m\u001b[39m{\u001b[39;00mkernel\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000003?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m kernel\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:376\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=373'>374</a>\u001b[0m         x2_ \u001b[39m=\u001b[39m x2_\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=374'>375</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m x1_\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m x2_\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=375'>376</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx1_ and x2_ must have the same number of dimensions!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=377'>378</a>\u001b[0m \u001b[39mif\u001b[39;00m x2_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=378'>379</a>\u001b[0m     x2_ \u001b[39m=\u001b[39m x1_\n",
      "\u001b[0;31mRuntimeError\u001b[0m: x1_ and x2_ must have the same number of dimensions!"
     ]
    }
   ],
   "source": [
    "### now we loop :\n",
    "max_iter = 1\n",
    "\n",
    "for i in range(max_iter):\n",
    "\n",
    "  step(model,objective_env)\n",
    "\n",
    "  if i % 100 == 0:\n",
    "\n",
    "    best_val = model.train_targets.max()\n",
    "    curr_val = model.train_targets[-1]\n",
    "    print(f'curr {curr_val} max {best_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_batch = torch.rand(2,9,3)\n",
    "states = torch.rand(100,3)\n",
    "(params_batch@states.T).shape\n",
    "\n",
    "# states = torch.rand(9,3) ## [n_states,state_dim]\n",
    "# params = torch.rand(3,2,7) ## [in_size,out_size,n_parallel]\n",
    "# #out = [2,9,7].T ==> [7,9,2]\n",
    "\n",
    "# states @ params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually fitting GP (maximizing likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_iter = 100 \n",
    "\n",
    "# # Find optimal model hyperparameters\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # Use the adam optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.25)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# # \"Loss\" for GPs - the marginal log likelihood\n",
    "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# for i in range(3):\n",
    "#     # Zero gradients from previous iteration\n",
    "#     optimizer.zero_grad()\n",
    "#     # Output from model\n",
    "#     output = model(train_x)\n",
    "#     # Calc loss and backprop gradients\n",
    "#     loss = -mll(output, train_y)\n",
    "#     logger.warning(f'Loss {loss.shape}')\n",
    "#     loss.backward()\n",
    "#     print('Iter %d/%d - Loss: %.3f noise: %.3f' % \n",
    "#         (\n",
    "#         i + 1, training_iter, loss.item(),\n",
    "#         model.likelihood.noise.item())\n",
    "#         )\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter = 1\n",
    "# for i in range(max_iter):\n",
    "      \n",
    "    \n",
    "#   ### fit hypers of GP\n",
    "#   mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "#   fit_gpytorch_model(mll)\n",
    "  \n",
    "#   # logger.setLevel(logging.WARNING)\n",
    "#   # logger.warning(\"Optimized hypers\")\n",
    "\n",
    "#   ### optimize acqf\n",
    "  \n",
    "#   best_value = model.train_targets.max()\n",
    "#   len_params = objective_env.policy.len_params\n",
    "#   EI = ExpectedImprovement(model=model, best_f=best_value)\n",
    "  \n",
    "#   new_x, _ = optimize_acqf(\n",
    "#     acq_function=EI,\n",
    "#     bounds=torch.tensor([[0.0] * len_params, [1.0] * len_params]),\n",
    "#     q=1,\n",
    "#     num_restarts=3,\n",
    "#     raw_samples=5,\n",
    "#     options={},\n",
    "#   )\n",
    "  \n",
    "#   logger.setLevel(logging.WARNING)\n",
    "#   logger.warning(\"Acquisition function finished\")\n",
    "\n",
    "#   new_y = objective_env(new_x)\n",
    "\n",
    "#   ### Update training points.\n",
    "#   train_x = torch.cat([model.train_inputs[0], new_x])\n",
    "#   train_y = torch.cat([model.train_targets, new_y])\n",
    "#   model.set_train_data(inputs=train_x, targets=train_y, strict=False)\n",
    "\n",
    "#   if i % 10 == 0:\n",
    "\n",
    "#     best_val = model.train_targets.max()\n",
    "#     curr_val = model.train_targets[-1]\n",
    "#     print(f'curr {curr_val} max {best_val}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
