{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "### local imports \n",
    "from src.environment import EnvironmentObjective\n",
    "from src.vanillagp import step\n",
    "from src.policy import MLP\n",
    "\n",
    "### botorch\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "### general imports\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "### Logging \n",
    "import logging\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Toy kernel for warningging\n",
    "\n",
    "class MyKernel(gpytorch.kernels.RBFKernel):\n",
    "   \n",
    "    def forward(self,x1,x2,**params):\n",
    "        \n",
    "        logger.warning(f'x1 {x1.shape} / x2 {x2.shape}')\n",
    "        kernel = super().forward(x1,x2,**params)\n",
    "        logger.warning(f'pair kernel {kernel.shape}')\n",
    "        return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import *\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "class GridKernel(Kernel):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 policy,states):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        tester = PolicyTester(policy,states)\n",
    "        # rbf_module = ScaleKernel(\n",
    "        #         MaternKernel(\n",
    "        #             nu=2.5,\n",
    "        #             ard_num_dims=states.shape[0], ## number of dims in L2 norm\n",
    "        #             lengthscale_prior=GammaPrior(3.0, 6.0),\n",
    "        #         ),\n",
    "        #         outputscale_prior=GammaPrior(2.0, 0.15),\n",
    "        #     ) \n",
    "        \n",
    "        rbf_module = ScaleKernel(RBFKernel(ard_num_dims=states.shape[0]))\n",
    "\n",
    "        # save params to instance\n",
    "        self.__dict__.update(locals())\n",
    "        \n",
    "        \n",
    "    def forward(self,x1,x2,**params):\n",
    "        \n",
    "        logger.warning(f'x1 {x1.shape} / x2 {x2.shape}')\n",
    "        \n",
    "        if len(x1.size())==3:\n",
    "            logger.warning(f'x1 {x1[0,0]} / x2_0 {x2[0,0]} x2_101{x2[0,100]}')\n",
    "        \n",
    "        \n",
    "        #Evaluate current parameters\n",
    "        \n",
    "        actions2 = self.tester(x2)\n",
    "        actions1 = self.tester(x1)\n",
    "        logger.warning(f'actions1 {actions1.shape} actions2 {actions2.shape} ')\n",
    "        \n",
    "        # Compute pairwise pairwise kernel \n",
    "        \n",
    "        kernel = self.rbf_module(actions1, actions2, **params)\n",
    "        logger.warning(f'pair kernel {kernel.shape}')\n",
    "        \n",
    "        return kernel\n",
    "        \n",
    "        \n",
    "class PolicyTester():\n",
    "    \n",
    "    def __init__(self,mlp,states):\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "    \n",
    "    def compute_actions(self,mlp,states,params_batch):\n",
    "        \n",
    "        # logger.info(f'Tester : params_batch {params_batch.shape}')\n",
    "        \n",
    "        # actions = [mlp(states,p).squeeze() \n",
    "        #         for p in params_batch.flatten(end_dim=-2)\n",
    "        #         ]\n",
    "        \n",
    "        # #### WARNING THIS MIGHT BE A SOURCE OF ERROR\n",
    "        # first_dims = params_batch.size()[:-1]\n",
    "        # last_dim = actions[0].size(-1)\n",
    "        # actions = torch.stack(actions).reshape(*first_dims,last_dim) ## hotfix\n",
    "        # ###############################################\"\"\"\"\n",
    "        \n",
    "        # logger.info(f'Tester : actions {actions.shape}')\n",
    "        # return actions\n",
    "        \n",
    "        ### linear policy hotfix\n",
    "        return params_batch@states.T\n",
    "    \n",
    "    def __call__(self,params_batch):\n",
    "        \n",
    "        return self.compute_actions(self.mlp,\n",
    "                                    self.states,\n",
    "                                    params_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "\n",
    "class GridGPModel(ExactGP,GPyTorchModel):\n",
    "    \n",
    "    _num_outputs = 1\n",
    "    \n",
    "    def __init__(self, train_x, train_y, likelihood,\n",
    "                 mlp,states):\n",
    "        \n",
    "        ExactGP.__init__(self, train_x, train_y, likelihood)\n",
    "        self.covar_module = GridKernel(mlp,states)\n",
    "        #self.covar_module = MyKernel()\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize policy\n",
    "mlp = MLP([3,1])\n",
    "\n",
    "# Initialize environment\n",
    "\n",
    "objective_env = EnvironmentObjective(\n",
    "  env=gym.make(\"Pendulum-v1\"),\n",
    "  policy=mlp,\n",
    "  manipulate_state=None,\n",
    "  manipulate_reward=None,\n",
    ")\n",
    "\n",
    "### initialize train_x, train_y\n",
    "train_x = torch.rand(100,mlp.len_params) ## [n_trials,n_params]\n",
    "train_y = [objective_env.run(p) for p in train_x]\n",
    "train_y = torch.Tensor(train_y).reshape(-1)  ## [n_trials,1]\n",
    "\n",
    "# initialize likelihood and model\n",
    "\n",
    "states = objective_env.get_grid()\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GridGPModel(train_x, train_y, likelihood,\n",
    "                    mlp,states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimized hypers\n",
      "x1 torch.Size([1, 1, 3]) / x2 torch.Size([1, 101, 3])\n",
      "x1 tensor([0.7745, 0.0339, 0.4774]) / x2_0 tensor([0.1182, 0.5515, 0.7509]) x2_101tensor([0.7745, 0.0339, 0.4774])\n",
      "actions1 torch.Size([1, 1, 1000]) actions2 torch.Size([1, 101, 1000]) \n",
      "pair kernel torch.Size([1, 1, 101])\n",
      "x1 torch.Size([100, 3]) / x2 torch.Size([100, 3])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "pair kernel torch.Size([100, 100])\n",
      "x1 torch.Size([1, 1, 3]) / x2 torch.Size([1, 101, 3])\n",
      "x1 tensor([0.7745, 0.0339, 0.4774], grad_fn=<SelectBackward>) / x2_0 tensor([0.1182, 0.5515, 0.7509], grad_fn=<SelectBackward>) x2_101tensor([0.7745, 0.0339, 0.4774], grad_fn=<SelectBackward>)\n",
      "actions1 torch.Size([1, 1, 1000]) actions2 torch.Size([1, 101, 1000]) \n",
      "pair kernel torch.Size([1, 1, 101])\n",
      "x1 torch.Size([1, 1, 3]) / x2 torch.Size([1, 101, 3])\n",
      "x1 tensor([0.7745, 0.0339, 0.4774]) / x2_0 tensor([0.1182, 0.5515, 0.7509]) x2_101tensor([0.7745, 0.0339, 0.4774])\n",
      "actions1 torch.Size([1, 1, 1000]) actions2 torch.Size([1, 101, 1000]) \n",
      "pair kernel torch.Size([1, 1, 101])\n",
      "Acquisition function finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr -1598.6431884765625 max -897.07958984375\n"
     ]
    }
   ],
   "source": [
    "max_iter = 1\n",
    "for i in range(max_iter):\n",
    "      \n",
    "  ### fit hypers of GP\n",
    "  mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "  fit_gpytorch_model(mll)\n",
    "  \n",
    "  logger.setLevel(logging.WARNING)\n",
    "  logger.warning(\"Optimized hypers\")\n",
    "\n",
    "  ### optimize acqf\n",
    "  \n",
    "  best_value = model.train_targets.max()\n",
    "  len_params = objective_env.policy.len_params\n",
    "  EI = ExpectedImprovement(model=model, best_f=best_value)\n",
    "  \n",
    "  new_x, _ = optimize_acqf(\n",
    "    acq_function=EI,\n",
    "    bounds=torch.tensor([[0.0] * len_params, [1.0] * len_params]),\n",
    "    q=1,\n",
    "    num_restarts=1,\n",
    "    raw_samples=1,\n",
    "    options={},\n",
    "  )\n",
    "  \n",
    "  logger.setLevel(logging.WARNING)\n",
    "  logger.warning(\"Acquisition function finished\")\n",
    "\n",
    "  new_y = objective_env(new_x)\n",
    "\n",
    "  ### Update training points.\n",
    "  train_x = torch.cat([model.train_inputs[0], new_x])\n",
    "  train_y = torch.cat([model.train_targets, new_y])\n",
    "  model.set_train_data(inputs=train_x, targets=train_y, strict=False)\n",
    "\n",
    "  if i % 10 == 0:\n",
    "\n",
    "    best_val = model.train_targets.max()\n",
    "    curr_val = model.train_targets[-1]\n",
    "    print(f'curr {curr_val} max {best_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### now we loop :\n",
    "# max_iter = 1000\n",
    "\n",
    "# for i in range(max_iter):\n",
    "\n",
    "#   step(model,objective_env)\n",
    "\n",
    "#   if i % 100 == 0:\n",
    "\n",
    "#     best_val = model.train_targets.max()\n",
    "#     curr_val = model.train_targets[-1]\n",
    "#     print(f'curr {curr_val} max {best_val}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually fitting GP (maximizing likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_iter = 100 \n",
    "\n",
    "# # Find optimal model hyperparameters\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # Use the adam optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.25)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# # \"Loss\" for GPs - the marginal log likelihood\n",
    "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# for i in range(3):\n",
    "#     # Zero gradients from previous iteration\n",
    "#     optimizer.zero_grad()\n",
    "#     # Output from model\n",
    "#     output = model(train_x)\n",
    "#     # Calc loss and backprop gradients\n",
    "#     loss = -mll(output, train_y)\n",
    "#     logger.warning(f'Loss {loss.shape}')\n",
    "#     loss.backward()\n",
    "#     print('Iter %d/%d - Loss: %.3f noise: %.3f' % \n",
    "#         (\n",
    "#         i + 1, training_iter, loss.item(),\n",
    "#         model.likelihood.noise.item())\n",
    "#         )\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter = 1\n",
    "# for i in range(max_iter):\n",
    "      \n",
    "    \n",
    "#   ### fit hypers of GP\n",
    "#   mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "#   fit_gpytorch_model(mll)\n",
    "  \n",
    "#   # logger.setLevel(logging.WARNING)\n",
    "#   # logger.warning(\"Optimized hypers\")\n",
    "\n",
    "#   ### optimize acqf\n",
    "  \n",
    "#   best_value = model.train_targets.max()\n",
    "#   len_params = objective_env.policy.len_params\n",
    "#   EI = ExpectedImprovement(model=model, best_f=best_value)\n",
    "  \n",
    "#   new_x, _ = optimize_acqf(\n",
    "#     acq_function=EI,\n",
    "#     bounds=torch.tensor([[0.0] * len_params, [1.0] * len_params]),\n",
    "#     q=1,\n",
    "#     num_restarts=3,\n",
    "#     raw_samples=5,\n",
    "#     options={},\n",
    "#   )\n",
    "  \n",
    "#   logger.setLevel(logging.WARNING)\n",
    "#   logger.warning(\"Acquisition function finished\")\n",
    "\n",
    "#   new_y = objective_env(new_x)\n",
    "\n",
    "#   ### Update training points.\n",
    "#   train_x = torch.cat([model.train_inputs[0], new_x])\n",
    "#   train_y = torch.cat([model.train_targets, new_y])\n",
    "#   model.set_train_data(inputs=train_x, targets=train_y, strict=False)\n",
    "\n",
    "#   if i % 10 == 0:\n",
    "\n",
    "#     best_val = model.train_targets.max()\n",
    "#     curr_val = model.train_targets[-1]\n",
    "#     print(f'curr {curr_val} max {best_val}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
