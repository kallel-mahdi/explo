{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "### local imports \n",
    "from src.environment import EnvironmentObjective\n",
    "from src.vanillagp import step\n",
    "from src.policy import MLP\n",
    "\n",
    "### botorch\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "### general imports\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "import torch\n",
    "import gym\n",
    "\n",
    "### Logging \n",
    "import logging\n",
    "logger = logging.getLogger('__main__')\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Toy kernel for warningging\n",
    "\n",
    "class MyKernel(gpytorch.kernels.RBFKernel):\n",
    "   \n",
    "    def forward(self,x1,x2,**params):\n",
    "        \n",
    "        logger.warning(f'x1 {x1.shape} / x2 {x2.shape}')\n",
    "        kernel = super().forward(x1,x2,**params)\n",
    "        logger.warning(f'pair kernel {kernel.shape}')\n",
    "        return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridKernel(gpytorch.kernels.Kernel):\n",
    "    \n",
    "    def __init__(self,mlp,actions_metric,\n",
    "                 states,states_w=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        if states_w is None:\n",
    "            states_w = torch.ones(states.size(0))\n",
    "            \n",
    "        rbf_module =  gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "        ## save params to instance\n",
    "        self.__dict__.update(locals())\n",
    "    \n",
    "    def compute_actions(self,states,params_batch):\n",
    "        \n",
    "        \n",
    "        logger.warning(f'params_batch {params_batch.shape}')\n",
    "        \n",
    "        rslt = [self.mlp(states,p).squeeze() \n",
    "                for p in params_batch.flatten(end_dim=-2)\n",
    "                #for p in params_batch.squeeze()\n",
    "                ]\n",
    "        \n",
    "        \n",
    "        #### WARNING THIS MIGHT BE A SOURCE OF ERROR\n",
    "        first_dims = params_batch.size()[:-1]\n",
    "        last_dim = rslt[0].size(-1)\n",
    "        rslt = torch.stack(rslt).reshape(*first_dims,last_dim) ## hotfix\n",
    "        ###############################################\"\"\"\"\n",
    "        \n",
    "        return rslt\n",
    "            \n",
    "\n",
    "    def forward(self,x1,x2,**params):\n",
    "        \n",
    "        states,states_w = self.states,self.states_w\n",
    "        \n",
    "        logger.warning(f'x1 {x1.shape} / x2 {x2.shape}')\n",
    "        #Evaluate current parameters\n",
    "        actions1 = self.compute_actions(states,x1)\n",
    "        actions2 = self.compute_actions(states,x2)\n",
    "        logger.warning(f'actions1 {actions1.shape} actions2 {actions2.shape} ')\n",
    "        \n",
    "        # Compute pairwise pairwise kernel \n",
    "        kernel = self.rbf_module(actions1, actions2, **params)\n",
    "        logger.warning(f'pair kernel {kernel.shape}')\n",
    "        \n",
    "        return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "\n",
    "class GridGPModel(ExactGP,GPyTorchModel):\n",
    "    \n",
    "    _num_outputs = 1\n",
    "    \n",
    "    def __init__(self, train_x, train_y, likelihood,\n",
    "                 mlp,actions_metric,states):\n",
    "        \n",
    "        ExactGP.__init__(self, train_x, train_y, likelihood)\n",
    "        self.covar_module = GridKernel(mlp,actions_metric,states)\n",
    "        #self.covar_module = MyKernel()\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLP' object has no attribute 'set_grad_enabled'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/kernel.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39m### initialize policy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=1'>2</a>\u001b[0m mlp \u001b[39m=\u001b[39m MLP(\u001b[39m*\u001b[39m[\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=2'>3</a>\u001b[0m mlp\u001b[39m.\u001b[39;49mset_grad_enabled(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=4'>5</a>\u001b[0m \u001b[39m# Initialize environment\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=6'>7</a>\u001b[0m objective_env \u001b[39m=\u001b[39m EnvironmentObjective(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=7'>8</a>\u001b[0m   env\u001b[39m=\u001b[39mgym\u001b[39m.\u001b[39mmake(\u001b[39m\"\u001b[39m\u001b[39mPendulum-v1\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=8'>9</a>\u001b[0m   policy\u001b[39m=\u001b[39mmlp,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=9'>10</a>\u001b[0m   manipulate_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=10'>11</a>\u001b[0m   manipulate_reward\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000004?line=11'>12</a>\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLP' object has no attribute 'set_grad_enabled'"
     ]
    }
   ],
   "source": [
    "### initialize policy\n",
    "mlp = MLP(*[3,1])\n",
    "mlp.requires_grad = True\n",
    "\n",
    "# Initialize environment\n",
    "\n",
    "objective_env = EnvironmentObjective(\n",
    "  env=gym.make(\"Pendulum-v1\"),\n",
    "  policy=mlp,\n",
    "  manipulate_state=None,\n",
    "  manipulate_reward=None,\n",
    ")\n",
    "\n",
    "### initialize train_x, train_y\n",
    "train_x = torch.rand(100,mlp.len_params) ## [n_trials,n_params]\n",
    "train_y = [objective_env.run(p) for p in train_x]\n",
    "train_y = torch.Tensor(train_y).reshape(-1)  ## [n_trials,1]\n",
    "\n",
    "# initialize likelihood and model\n",
    "\n",
    "states = objective_env.get_grid()\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GridGPModel(train_x, train_y, likelihood,\n",
    "                    mlp,torch.linalg.norm,states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLP' object has no attribute 'grad_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/kernel.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000018?line=0'>1</a>\u001b[0m mlp\u001b[39m.\u001b[39;49mgrad_fn\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLP' object has no attribute 'grad_fn'"
     ]
    }
   ],
   "source": [
    "mlp.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimized hypers\n",
      "x1 torch.Size([5, 1, 3]) / x2 torch.Size([5, 101, 3])\n",
      "params_batch torch.Size([5, 1, 3])\n",
      "params_batch torch.Size([5, 101, 3])\n",
      "actions1 torch.Size([5, 1, 1000]) actions2 torch.Size([5, 101, 1000]) \n",
      "pair kernel torch.Size([5, 1, 101])\n",
      "x1 torch.Size([100, 3]) / x2 torch.Size([100, 3])\n",
      "params_batch torch.Size([100, 3])\n",
      "params_batch torch.Size([100, 3])\n",
      "actions1 torch.Size([100, 1000]) actions2 torch.Size([100, 1000]) \n",
      "pair kernel torch.Size([100, 100])\n",
      "x1 torch.Size([3, 1, 3]) / x2 torch.Size([3, 101, 3])\n",
      "params_batch torch.Size([3, 1, 3])\n",
      "params_batch torch.Size([3, 101, 3])\n",
      "actions1 torch.Size([3, 1, 1000]) actions2 torch.Size([3, 101, 1000]) \n",
      "pair kernel torch.Size([3, 1, 101])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/kernel.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=10'>11</a>\u001b[0m len_params \u001b[39m=\u001b[39m objective_env\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mlen_params\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=11'>12</a>\u001b[0m EI \u001b[39m=\u001b[39m ExpectedImprovement(model\u001b[39m=\u001b[39mmodel, best_f\u001b[39m=\u001b[39mbest_value)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=13'>14</a>\u001b[0m new_x, _ \u001b[39m=\u001b[39m optimize_acqf(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=14'>15</a>\u001b[0m   acq_function\u001b[39m=\u001b[39;49mEI,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=15'>16</a>\u001b[0m   bounds\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m0.0\u001b[39;49m] \u001b[39m*\u001b[39;49m len_params, [\u001b[39m1.0\u001b[39;49m] \u001b[39m*\u001b[39;49m len_params]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=16'>17</a>\u001b[0m   q\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=17'>18</a>\u001b[0m   num_restarts\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=18'>19</a>\u001b[0m   raw_samples\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=19'>20</a>\u001b[0m   options\u001b[39m=\u001b[39;49m{},\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=20'>21</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=23'>24</a>\u001b[0m new_y \u001b[39m=\u001b[39m objective_env(new_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/kernel.ipynb#ch0000010?line=25'>26</a>\u001b[0m \u001b[39m### Update training points.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py:225\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=221'>222</a>\u001b[0m batched_ics \u001b[39m=\u001b[39m batch_initial_conditions\u001b[39m.\u001b[39msplit(batch_limit)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=222'>223</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, batched_ics_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batched_ics):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=223'>224</a>\u001b[0m     \u001b[39m# optimize using random restart optimization\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=224'>225</a>\u001b[0m     batch_candidates_curr, batch_acq_values_curr \u001b[39m=\u001b[39m gen_candidates_scipy(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=225'>226</a>\u001b[0m         initial_conditions\u001b[39m=\u001b[39;49mbatched_ics_,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=226'>227</a>\u001b[0m         acquisition_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=227'>228</a>\u001b[0m         lower_bounds\u001b[39m=\u001b[39;49mbounds[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=228'>229</a>\u001b[0m         upper_bounds\u001b[39m=\u001b[39;49mbounds[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=229'>230</a>\u001b[0m         options\u001b[39m=\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m INIT_OPTION_KEYS},\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=230'>231</a>\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=231'>232</a>\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=232'>233</a>\u001b[0m         nonlinear_inequality_constraints\u001b[39m=\u001b[39;49mnonlinear_inequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=233'>234</a>\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=234'>235</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=235'>236</a>\u001b[0m     batch_candidates_list\u001b[39m.\u001b[39mappend(batch_candidates_curr)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=236'>237</a>\u001b[0m     batch_acq_values_list\u001b[39m.\u001b[39mappend(batch_acq_values_curr)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py:202\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=198'>199</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=199'>200</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39macquisition_function(x)\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=201'>202</a>\u001b[0m res \u001b[39m=\u001b[39m minimize(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=202'>203</a>\u001b[0m     fun\u001b[39m=\u001b[39;49mf_np_wrapper,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=203'>204</a>\u001b[0m     args\u001b[39m=\u001b[39;49m(f,),\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=204'>205</a>\u001b[0m     x0\u001b[39m=\u001b[39;49mx0,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=205'>206</a>\u001b[0m     method\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mSLSQP\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m constraints \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=206'>207</a>\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=207'>208</a>\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=208'>209</a>\u001b[0m     constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=209'>210</a>\u001b[0m     callback\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=210'>211</a>\u001b[0m     options\u001b[39m=\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m]},\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=211'>212</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=212'>213</a>\u001b[0m candidates \u001b[39m=\u001b[39m fix_features(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=213'>214</a>\u001b[0m     X\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfrom_numpy(res\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mto(initial_conditions)\u001b[39m.\u001b[39mreshape(shapeX),\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=214'>215</a>\u001b[0m     fixed_features\u001b[39m=\u001b[39mfixed_features,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=215'>216</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=217'>218</a>\u001b[0m \u001b[39m# SLSQP sometimes fails in the line search or may just fail to find a feasible\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=218'>219</a>\u001b[0m \u001b[39m# candidate in which case we just return the starting point. This happens rarely,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=219'>220</a>\u001b[0m \u001b[39m# so it shouldn't be an issue given enough restarts.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py:681\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=677'>678</a>\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=678'>679</a>\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=679'>680</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=680'>681</a>\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=681'>682</a>\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=682'>683</a>\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=683'>684</a>\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_minimize.py?line=684'>685</a>\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py:308\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=304'>305</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=305'>306</a>\u001b[0m         iprint \u001b[39m=\u001b[39m disp\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=307'>308</a>\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[39m=\u001b[39;49mjac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=308'>309</a>\u001b[0m                               bounds\u001b[39m=\u001b[39;49mnew_bounds,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=309'>310</a>\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=311'>312</a>\u001b[0m func_and_grad \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mfun_and_grad\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py?line=313'>314</a>\u001b[0m fortran_int \u001b[39m=\u001b[39m _lbfgsb\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mintvar\u001b[39m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py:263\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=258'>259</a>\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=260'>261</a>\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=261'>262</a>\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=262'>263</a>\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=263'>264</a>\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=265'>266</a>\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=154'>155</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=156'>157</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl \u001b[39m=\u001b[39m update_fun\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=157'>158</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=159'>160</a>\u001b[0m \u001b[39m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=160'>161</a>\u001b[0m \u001b[39mif\u001b[39;00m callable(grad):\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=248'>249</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=249'>250</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=250'>251</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=251'>252</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=153'>154</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=154'>155</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=132'>133</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=133'>134</a>\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=134'>135</a>\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=135'>136</a>\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=136'>137</a>\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=137'>138</a>\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py?line=138'>139</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=73'>74</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=74'>75</a>\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=75'>76</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=76'>77</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=67'>68</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=68'>69</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=69'>70</a>\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=70'>71</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/scipy/optimize/_optimize.py?line=71'>72</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py:173\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=170'>171</a>\u001b[0m loss \u001b[39m=\u001b[39m f(X_fix)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=171'>172</a>\u001b[0m \u001b[39m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=172'>173</a>\u001b[0m gradf \u001b[39m=\u001b[39m _arrayify(torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(loss, X)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=173'>174</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misnan(gradf)\u001b[39m.\u001b[39many():\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=174'>175</a>\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=175'>176</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39misnan(gradf)\u001b[39m.\u001b[39msum()\u001b[39m}\u001b[39;00m\u001b[39m elements of the \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39msize\u001b[39m}\u001b[39;00m\u001b[39m element \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=176'>177</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgradient array `gradf` are NaN. This often indicates numerical issues.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/generation/gen.py?line=177'>178</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py:226\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=222'>223</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=223'>224</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=225'>226</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=226'>227</a>\u001b[0m     outputs, grad_outputs_, retain_graph, create_graph,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=227'>228</a>\u001b[0m     inputs, allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "### fit hypers of GP\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "fit_gpytorch_model(mll)\n",
    "\n",
    "logger.setLevel(logging.WARNING)\n",
    "logger.warning(\"Optimized hypers\")\n",
    "\n",
    "### optimize acqf\n",
    "\n",
    "best_value = model.train_targets.max()\n",
    "len_params = objective_env.policy.len_params\n",
    "EI = ExpectedImprovement(model=model, best_f=best_value)\n",
    "\n",
    "new_x, _ = optimize_acqf(\n",
    "  acq_function=EI,\n",
    "  bounds=torch.tensor([[0.0] * len_params, [1.0] * len_params]),\n",
    "  q=1,\n",
    "  num_restarts=3,\n",
    "  raw_samples=5,\n",
    "  options={},\n",
    ")\n",
    "\n",
    "\n",
    "new_y = objective_env(new_x)\n",
    "\n",
    "### Update training points.\n",
    "train_x = torch.cat([model.train_inputs[0], new_x])\n",
    "train_y = torch.cat([model.train_targets, new_y])\n",
    "model.set_train_data(inputs=train_x, targets=train_y, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([42849.5586], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-1531.3634], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually fitting GP (maximizing likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_iter = 100 \n",
    "\n",
    "# # Find optimal model hyperparameters\n",
    "# model.train()\n",
    "# likelihood.train()\n",
    "\n",
    "# # Use the adam optimizer\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.25)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# # \"Loss\" for GPs - the marginal log likelihood\n",
    "# mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# for i in range(3):\n",
    "#     # Zero gradients from previous iteration\n",
    "#     optimizer.zero_grad()\n",
    "#     # Output from model\n",
    "#     output = model(train_x)\n",
    "#     # Calc loss and backprop gradients\n",
    "#     loss = -mll(output, train_y)\n",
    "#     logger.warning(f'Loss {loss.shape}')\n",
    "#     loss.backward()\n",
    "#     print('Iter %d/%d - Loss: %.3f noise: %.3f' % \n",
    "#         (\n",
    "#         i + 1, training_iter, loss.item(),\n",
    "#         model.likelihood.noise.item())\n",
    "#         )\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x1 torch.Size([101, 3]) / x2 torch.Size([101, 3])\n",
      "pair kernel torch.Size([101, 101])\n",
      "x1 torch.Size([101, 3]) / x2 torch.Size([101, 3])\n",
      "pair kernel torch.Size([101, 101])\n",
      "x1 torch.Size([5, 1, 3]) / x2 torch.Size([5, 102, 3])\n",
      "pair kernel torch.Size([5, 1, 102])\n",
      "x1 torch.Size([101, 3]) / x2 torch.Size([101, 3])\n",
      "pair kernel torch.Size([101, 101])\n",
      "x1 torch.Size([3, 1, 3]) / x2 torch.Size([3, 102, 3])\n",
      "pair kernel torch.Size([3, 1, 102])\n",
      "x1 torch.Size([3, 1, 3]) / x2 torch.Size([3, 102, 3])\n",
      "pair kernel torch.Size([3, 1, 102])\n",
      "Acquisition function finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr -1590.959228515625 max -768.005859375\n"
     ]
    }
   ],
   "source": [
    "max_iter = 1\n",
    "for i in range(max_iter):\n",
    "      \n",
    "    \n",
    "  ### fit hypers of GP\n",
    "  mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "  fit_gpytorch_model(mll)\n",
    "  \n",
    "  # logger.setLevel(logging.WARNING)\n",
    "  # logger.warning(\"Optimized hypers\")\n",
    "\n",
    "  ### optimize acqf\n",
    "  \n",
    "  best_value = model.train_targets.max()\n",
    "  len_params = objective_env.policy.len_params\n",
    "  EI = ExpectedImprovement(model=model, best_f=best_value)\n",
    "  \n",
    "  new_x, _ = optimize_acqf(\n",
    "    acq_function=EI,\n",
    "    bounds=torch.tensor([[0.0] * len_params, [1.0] * len_params]),\n",
    "    q=1,\n",
    "    num_restarts=3,\n",
    "    raw_samples=5,\n",
    "    options={},\n",
    "  )\n",
    "  \n",
    "  logger.setLevel(logging.WARNING)\n",
    "  logger.warning(\"Acquisition function finished\")\n",
    "\n",
    "  new_y = objective_env(new_x)\n",
    "\n",
    "  ### Update training points.\n",
    "  train_x = torch.cat([model.train_inputs[0], new_x])\n",
    "  train_y = torch.cat([model.train_targets, new_y])\n",
    "  model.set_train_data(inputs=train_x, targets=train_y, strict=False)\n",
    "\n",
    "  if i % 10 == 0:\n",
    "\n",
    "    best_val = model.train_targets.max()\n",
    "    curr_val = model.train_targets[-1]\n",
    "    print(f'curr {curr_val} max {best_val}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
