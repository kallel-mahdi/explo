{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound 59.895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59.895"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bound(n_dim,p):\n",
    "\n",
    "    dx = 0.001\n",
    "    x = np.arange(0, n_dim,dx)\n",
    "\n",
    "    cdf = np.cumsum(chi2.pdf(x, df=n_dim)*dx)\n",
    "    bound = max(x[cdf<=p])\n",
    "\n",
    "    print(\"bound\",bound)\n",
    "    return bound\n",
    "\n",
    "get_bound(100,0.05/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 100\n",
    "mu = np.random.rand(n_dim)\n",
    "A = 0.25 * np.random.rand(n_dim,n_dim) +  0.25 *mu\n",
    "A.dtype = np.float64\n",
    "A = 1e-3* A\n",
    "Corr = np.random.rand(n_dim) \n",
    "Corr = np.diag(Corr)\n",
    "\n",
    "Sigma = A.T @ A \n",
    "Sigma_inv = np.linalg.inv(Sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INVERSE ERR 0.01207757922660294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "m = np.mean(np.abs(Sigma))\n",
    "Sigma_b = Sigma / m\n",
    "Sigma_inv = np.linalg.inv(Sigma_b)/ m\n",
    "Sigma_inv2 = np.linalg.inv(Sigma)\n",
    "\n",
    "P_b = np.linalg.cholesky(Sigma_b)\n",
    "P_b_inv = np.linalg.inv(P_b)\n",
    "P_p = P_b_inv / np.sqrt(m)\n",
    "print(\"INVERSE ERR\",np.mean(np.abs(P_p.T@P_p-Sigma_inv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 0.011926387469739529\n"
     ]
    }
   ],
   "source": [
    "eigvals,P = np.linalg.eigh(Sigma)\n",
    "D = np.diag(eigvals)\n",
    "D_sqrt = np.diag(np.sqrt(eigvals))\n",
    "\n",
    "D_inv = np.diag(1/eigvals)\n",
    "D_inv_sqrt = np.diag(np.sqrt(1/eigvals))\n",
    "#P_p = D_sqrt_inv@(P.T)\n",
    "P_p = (P @ D_inv_sqrt).T\n",
    "#print(\"Error\",np.max(P@D_sqrt@D_sqrt@P.T-Sigma))\n",
    "print(\"Error\",np.mean(np.abs(P_p.T@P_p-Sigma_inv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound 2.1550000000000002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1550000000000002"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.05\n",
    "d = 10\n",
    "get_bound(d,p/d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3720604/1656108993.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Sigma = torch.tensor(Sigma)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0703e+10, -4.9161e+10,  8.3894e+10,  ...,  9.2684e+09,\n",
       "         -4.6628e+09, -2.8921e+10],\n",
       "        [-4.9161e+10,  2.4058e+11, -4.1555e+11,  ..., -6.0521e+10,\n",
       "          1.1987e+10,  1.7468e+11],\n",
       "        [ 8.3894e+10, -4.1555e+11,  7.4478e+11,  ...,  1.0359e+11,\n",
       "         -1.5381e+10, -3.2328e+11],\n",
       "        ...,\n",
       "        [ 9.2684e+09, -6.0521e+10,  1.0359e+11,  ...,  1.9235e+10,\n",
       "         -2.0322e+09, -4.5788e+10],\n",
       "        [-4.6628e+09,  1.1987e+10, -1.5381e+10,  ..., -2.0322e+09,\n",
       "          5.6224e+09,  3.2697e+09],\n",
       "        [-2.8921e+10,  1.7468e+11, -3.2328e+11,  ..., -4.5788e+10,\n",
       "          3.2697e+09,  1.5616e+11]], dtype=torch.float64)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma = torch.tensor(Sigma)\n",
    "L_upper = torch.linalg.cholesky(Sigma,upper=True)\n",
    "Sigma_inv = torch.cholesky_inverse(L_upper,upper=True)\n",
    "Sigma_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err1 tensor(1.3235e-22, dtype=torch.float64)\n",
      "Err2 tensor(0.5590, dtype=torch.float64)\n",
      "Err3 tensor(8.4703e-22, dtype=torch.float64)\n",
      "Err4 tensor(1.7846, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "Sigma = torch.tensor(Sigma)\n",
    "Sigma_b = Sigma / torch.min(torch.abs(Sigma))\n",
    "Sigma_inv = torch.linalg.inv(Sigma)\n",
    "P = torch.linalg.cholesky(Sigma)\n",
    "P_inv = torch.linalg.inv(P)\n",
    "print(\"Err1\",torch.max(torch.abs(P@P.T-Sigma)))\n",
    "print(\"Err2\",torch.max(torch.abs(P_inv.T@P_inv-Sigma_inv)))\n",
    "\n",
    "eigvals,P = torch.linalg.eigh(Sigma)\n",
    "D = torch.diag(eigvals)\n",
    "D_inv = torch.diag(1/eigvals)\n",
    "print(\"Err3\",torch.max(torch.abs(P@D@P.T-Sigma)))\n",
    "print(\"Err4\",torch.max(torch.abs(P@D_inv@P.T-Sigma_inv)))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_grad(mu,Sigma):\n",
    "\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "    n_dim = mu.shape[0]\n",
    "    \n",
    "    eigvals,P = np.linalg.eigh(Sigma)\n",
    "    assert (eigvals >= 0).all()\n",
    "\n",
    "    \n",
    "    ### Square root of Sigma_inv\n",
    "\n",
    "    D = np.diag(1/eigvals)\n",
    "    D_sqrt = np.diag(np.sqrt(1/eigvals))\n",
    "    P_p = P.T@D_sqrt \n",
    "\n",
    "    print(\"One\",np.max(P@eigvals@(P.T)-Sigma))\n",
    "    print(\"Distance\",np.max(P_p@(P_p.T)-Sigma_inv))\n",
    "    print(\"Distance\",np.max((P_p.T)@(P_p)-Sigma_inv))\n",
    "\n",
    "    \n",
    "    ###################\n",
    "\n",
    "    C = get_bound(n_dim,p=0.05)\n",
    "\n",
    "    x = cvx.Variable((n_dim))\n",
    "    objective = cvx.Minimize(cvx.norm(x,1))\n",
    "    pb = cvx.Problem(objective,\n",
    "                    [cvx.sum_squares(P_p@x -P_p@mu) <= C])\n",
    "\n",
    "    pb.solve(verbose=False)\n",
    "\n",
    "    rslt = x.value\n",
    "\n",
    "    assert all(rslt<=mu)\n",
    "\n",
    "    relative_diff = abs(rslt-mu)/mu\n",
    "\n",
    "    plt.hist(relative_diff)\n",
    "\n",
    "    return np.sum(relative_diff>0.9), np.sum(relative_diff<0.1),np.sum(relative_diff<0.5)\n",
    "\n",
    "sparsify_grad(mu,Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkallel/explo\n",
      "tensor([[1.4427, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, 1.4427, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, 1.4427, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, 1.4427, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, 1.4427, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.4427]])\n"
     ]
    }
   ],
   "source": [
    "%cd /home/mkallel/explo/\n",
    "from src.gp.kernels import MyRBFKernel\n",
    "\n",
    "n_dim = 6\n",
    "kernel = MyRBFKernel(6,True)\n",
    "theta = torch.rand(1,6,requires_grad=True)\n",
    "kernel(theta,theta).evaluate()\n",
    "\n",
    "theta_t2 = theta.clone().detach() ## hotfix otherwise 0 hessian\n",
    "## this might be a cause of error, try to find method to compute using k(theta,theta)\n",
    "hessian1 = -torch.autograd.functional.hessian(func=lambda theta : kernel(theta,theta_t2).evaluate(),\n",
    "                                            inputs=(theta))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "print(hessian1.squeeze())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4427, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.4427, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.4427, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.4427, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.4427, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4427]])\n"
     ]
    }
   ],
   "source": [
    "lengthscale = kernel.base_kernel.lengthscale.detach()\n",
    "sigma_f = kernel.outputscale.detach()\n",
    "hessian2 = (torch.eye(n_dim, device=lengthscale.device) / lengthscale ** 2) * sigma_f\n",
    "print(hessian2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkallel/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MLPPPPPPPPP SETUPMLPPPPPPPPP SETUPMathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MLPPPPPPPPP SETUPMLPPPPPPPPP SETUP  MLPPPPPPPPP SETUPMLPPPPPPPPP SETUP  1616 16 \n",
      "16\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "\n",
      "1616MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MLP LEEEEENMLP LEEEEEN\n",
      "MLP LEEEEEN\n",
      "\n",
      "MLPPPPPPPPP SETUPMLPPPPPPPPP SETUP MLP LEEEEENMathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "  MLP LEEEEEN MLP LEEEEENMathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      " 1616MLPPPPPPPPP SETUP 16  1616\n",
      "\n",
      " MLPPPPPPPPP SETUP\n",
      "1616\n",
      "16\n",
      "16\n",
      "MLP LEEEEEN \n",
      "MLP LEEEEEN\n",
      "\n",
      "  16MLP LEEEEEN16 16\n",
      "\n",
      "\n",
      "16MLP LEEEEEN \n",
      "16\n",
      "Using ard_num_dims = 16Using ard_num_dims = 16\n",
      "\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples Gibo will use 32 last points to fit GP and 16 info samples\n",
      "\n",
      " Gibo will use 32 last points to fit GP and 16 info samplesfixing seed to fixing seed to \n",
      "  fixing seed to 787846414 \n",
      "996406378534895718\n",
      "\n",
      "Using ard_num_dims = 16\n",
      "Using ard_num_dims = 16 Gibo will use 32 last points to fit GP and 16 info samples\n",
      "\n",
      "fixing seed to  841095289\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  423734972\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  Using ard_num_dims = 16862061404\n",
      "\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  415968276\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  670094950\n",
      "Using ard_num_dims = 16\n",
      "Using ard_num_dims = 16 Gibo will use 32 last points to fit GP and 16 info samples\n",
      "\n",
      "fixing seed to  199900595\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  127521863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-1p2uvgio</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1p2uvgio\" target=\"_blank\">rbf_lr=0.5_01110_787846414</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-2f8imj09</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2f8imj09\" target=\"_blank\">rbf_lr=0.5_01110_996406378</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-lf249h22</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/lf249h22\" target=\"_blank\">rbf_lr=0.5_01110_534895718</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-wz1xxgtl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/wz1xxgtl\" target=\"_blank\">rbf_lr=0.5_01110_423734972</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-ejifk333</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/ejifk333\" target=\"_blank\">rbf_lr=0.5_01110_841095289</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-31r4ujw1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/31r4ujw1\" target=\"_blank\">rbf_lr=0.5_01110_670094950</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-1y3viv9b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1y3viv9b\" target=\"_blank\">rbf_lr=0.5_01110_127521863</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-2292vang</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2292vang\" target=\"_blank\">rbf_lr=0.5_01110_862061404</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-1k4cuj47</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1k4cuj47\" target=\"_blank\">rbf_lr=0.5_01110_199900595</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_223249-18xhhilx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/18xhhilx\" target=\"_blank\">rbf_lr=0.5_01110_415968276</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 36\n",
      "0.125\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 54\n",
      "0.25\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 54\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 54\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 54\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 54\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 72\n",
      "0.6875\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 72\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 72\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 72\n",
      "0.125\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 72\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 72\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 72\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 72\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 90\n",
      "0.25\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 90\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 90\n",
      "0.25\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 90\n",
      "0.25\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 90\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 90\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 90\n",
      "0.6875\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 90\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 108\n",
      "0.625\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 108\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 108\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 108\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 108\n",
      "0.375\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 108\n",
      "0.4375\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 108\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 108\n",
      "0.25\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 108\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 126\n",
      "0.6875\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 108\n",
      "0.5\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 126\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 126\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 126\n",
      "0.625\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 126\n",
      "0.125\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 144\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 126\n",
      "0.625\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 126\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 126\n",
      "0.8125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 126\n",
      "0.375\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 144\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 126\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 144\n",
      "0.25\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 144\n",
      "0.125\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 162\n",
      "0.375\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 144\n",
      "0.375\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 144\n",
      "0.6875\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 144\n",
      "0.625\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 144\n",
      "0.625\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 144\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 162\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 162\n",
      "0.4375\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 144\n",
      "0.375\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 162\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 180\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 162\n",
      "0.625\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 162\n",
      "0.8125\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 162\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 180\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 180\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 162\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 162\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 162\n",
      "0.625\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 198\n",
      "0.4375\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 180\n",
      "0.5\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 180\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 180\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 180\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 198\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 198\n",
      "0.125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 180\n",
      "0.25\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 180\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 180\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 216\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 216\n",
      "0.5625\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 198\n",
      "0.125\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 198\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 252\n",
      "0.625\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 234\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 270\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 306\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 288\n",
      "0.25\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 324\n",
      "0.125\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 306\n",
      "0.4375\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 306\n",
      "0.25\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 324\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 450\n",
      "0.3125\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 468\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 486\n",
      "0.5\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 504\n",
      "0.1875\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 504\n",
      "0.125\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 522\n",
      "0.25\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_534895718 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_996406378 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 558\n",
      "0.0625\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 576\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▁▁▁▁▃▂▂▃▂▅█▇▄▃▁▁▂▂▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▆█▇▇▂▅▄▁▄▄▂▃▆▅▅█▇█▇█▆▆▇▆▆▇▅▆▆▇▆▄▅▄</td></tr><tr><td>R2</td><td>▆██▇▃▅▄▁▆▅▁▃▅▅▄▇▇▇▆█▅▄▆▆▆▇▆▇▆▆▆▅▅▄</td></tr><tr><td>acq_value (after finish)</td><td>▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▂▄▆▄▄▅▅▇█▆▅▆▃▅▅█▇▅▇█▆▆▄▅▆▅▇▄▆▅▇▆▃</td></tr><tr><td>action_distance_to_local</td><td>▁▁▁▂▃▄▅▄▅▃█▄▅▃▃▄▂▄▄▆▃▃▅▅▄▃▃▃▆▅▆▃▅▄▅▃▅▃▄▆</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇███████████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁█▇▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▁▁▂▁▁▂▂▇█▅▂▁▁▁▁▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▆▃▃▄▃▂▂▂▃▄▆▃▃▁▂▁▃▂▂▂▁▂▁▁▂▂▂▁▂▁▂▁▁</td></tr><tr><td>max_return</td><td>▁▂▃▃▃▃▃▃▄▅▇███████████████████████</td></tr><tr><td>max_std/mean</td><td>▃▄▁▁▂▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▂▁▁▆▁▁▁▁▁▄▂</td></tr><tr><td>mean_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▆▂▂▂▂▂▂▃▅▆▆▄▂▁▂▁▃▃▂▂▁▂▁▁▃▂▁▁▂▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▄▆▂▁▂▂▇▁▁▁▁▁▂▁▂▁▁▁▁▁▁█▂▂▂▁▆▂▂▁▁▂▅▃</td></tr><tr><td>median_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>██▂▂▂▁▂▃▃▆▆▄▅▃▂▂▂▄▃▂▂▂▂▁▁▃▂▂▂▂▂▁▁▂</td></tr><tr><td>median_std/mean</td><td>██▃▄▃▆▃▂▂▁▁▂▂▂▃▂▃▂▂▃▃▃▂▅▅▂▃▃▄▃▄▄▅▄</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▃▄▂▂▆▇▇▇▇▆▇▆█▇▇▆▆▇▆▇▇▆▆▇▇▆▇▇█▆▇▇</td></tr><tr><td>param_distance_to_local</td><td>▁▂▃▆▆▇▇▆█▆▆▅█▅▄▆▅▆▅▇▅▆▆▅▇▆▆▆▆▆▇▅▇▆▅▇▆▆▇█</td></tr><tr><td>policy_return</td><td>▂▁▂▁▁▃▃▃▄▃▅▃▆▄████▇█▇█▇▇██▆███▇▇▇▇▆██▇██</td></tr><tr><td>policy_return_at_grad</td><td>▁▂▂▂▃▃▃▄▄▅▇▇█████▇█▇██████████████</td></tr><tr><td>var_reward</td><td>▁█▄▆▂▂▁▁▁▁▃▂▁▁▁▁▁▁▁▂▁▁▂▂▁▁▂▄▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.05114</td></tr><tr><td>R1</td><td>-0.51321</td></tr><tr><td>R2</td><td>-1.27156</td></tr><tr><td>acq_value (after finish)</td><td>0.72174</td></tr><tr><td>action_distance_grad</td><td>0.07811</td></tr><tr><td>action_distance_to_local</td><td>0.35428</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07324</td></tr><tr><td>max_grad(before hessian)</td><td>0.12007</td></tr><tr><td>max_return</td><td>1.02369</td></tr><tr><td>max_std/mean</td><td>284.34177</td></tr><tr><td>mean_covar</td><td>-0.06173</td></tr><tr><td>mean_grad(before hessian)</td><td>0.05712</td></tr><tr><td>mean_std/mean</td><td>25.26325</td></tr><tr><td>median_covar</td><td>-0.06585</td></tr><tr><td>median_grad(before hessian)</td><td>0.04819</td></tr><tr><td>median_std/mean</td><td>5.18664</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03097</td></tr><tr><td>param_distance_to_local</td><td>0.06752</td></tr><tr><td>policy_return</td><td>1.00386</td></tr><tr><td>policy_return_at_grad</td><td>1.01802</td></tr><tr><td>var_reward</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_534895718</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/lf249h22\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/lf249h22</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-lf249h22/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_787846414 : n_samples : 594\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_127521863 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▁▂▂▄▄▅▆▄█▆▄▅▄▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▇▇▇▆▇▇▅▇▁▆▇▄▅▆▆▇▆▆█▇▇▅▇▆▇▆▇▆▇▇█▆█▆</td></tr><tr><td>R2</td><td>▇█▇▇█▇▅▇▁▆▇▃▄▆▆▇▆▆█▇▇▅▇▆▇▆▇▆▇▇█▇█▆</td></tr><tr><td>acq_value (after finish)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▁▄▃▄█▆▅▄▅▅▅▆█▄▄▇▆▇▄▆▄▇▄▅▇▇▄▃▇▇▇▆▅</td></tr><tr><td>action_distance_to_local</td><td>▁▁▁▂▂▆▄▃▄▅▇▄▆▄█▇▆▅▆▆▇▅▅█▄▃█▄▆▄▅▅▆▇▇▆▅▅▆▆</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇█▇█████████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▇▁█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▁▅▃▅▇▆▅█▃▃▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▇▃▄█▇▇▄▆▄▄▅▃▃▁▁▁▂▃▁▂▁▂▁▁▁▂▁▁▁▂▁▂▁</td></tr><tr><td>max_return</td><td>▁▁▂▂▄▅▅▆▇▇████████████████████████</td></tr><tr><td>max_std/mean</td><td>▃▂▄▁▂▃▅▁▁▁▁▁▂▁▁▃▃▅▁▂▄▄▃▂▄▂▃▁█▂▁▂▅▂</td></tr><tr><td>mean_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>██▂▄▄▅▅▃▄▄▃▃▂▂▁▁▁▁▃▂▂▁▂▂▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▆▄▄▁▂▃▄▁▁▁▁▁▂▁▂▅▅▇▂▂▅▆▃▂▇▃▃▃█▄▂▅▇▄</td></tr><tr><td>median_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>▇█▂▃▄▃▄▃▃▅▃▃▃▂▁▁▁▁▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>▇▆▂▁▁▁▁▁▂▁▁▂▂▂▃▄▄▅▁▃▅▄▂▃▃▄▄▄▄▅▃█▅▄</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▂▆▇▃▅▆▇▆█▇▆▇▇█▇▇▆▇█▆▇▇█▇▇▇█▇▇▆▇▆▇</td></tr><tr><td>param_distance_to_local</td><td>▁▁▂▇█▅▅▇▇▆▇█▇▇▇█▇█▇█▇▆▅▆▆▇▇▆▆▇▇▅▅▇▇█▆▇▆▆</td></tr><tr><td>policy_return</td><td>▂▁▁▁▂▃▃▄▅▅▇▅▆█▇▇█████▆▇█▇██████▇████████</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▁▂▃▄▅▅▇▆▆███████████████████████</td></tr><tr><td>var_reward</td><td>▂█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.03271</td></tr><tr><td>R1</td><td>-0.38775</td></tr><tr><td>R2</td><td>-0.7742</td></tr><tr><td>acq_value (after finish)</td><td>0.74664</td></tr><tr><td>action_distance_grad</td><td>0.1979</td></tr><tr><td>action_distance_to_local</td><td>0.26699</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07083</td></tr><tr><td>max_grad(before hessian)</td><td>0.11002</td></tr><tr><td>max_return</td><td>1.02268</td></tr><tr><td>max_std/mean</td><td>36.29927</td></tr><tr><td>mean_covar</td><td>-0.06033</td></tr><tr><td>mean_grad(before hessian)</td><td>0.03978</td></tr><tr><td>mean_std/mean</td><td>12.49745</td></tr><tr><td>median_covar</td><td>-0.06476</td></tr><tr><td>median_grad(before hessian)</td><td>0.0384</td></tr><tr><td>median_std/mean</td><td>6.40234</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03038</td></tr><tr><td>param_distance_to_local</td><td>0.05161</td></tr><tr><td>policy_return</td><td>0.98854</td></tr><tr><td>policy_return_at_grad</td><td>1.00158</td></tr><tr><td>var_reward</td><td>0.0009</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_996406378</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2f8imj09\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2f8imj09</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-2f8imj09/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01110_841095289 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01110_199900595 : n_samples : 594\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▂▃▃▂▃▃▄▃▂▃▅▇▃▅▅▂▂▂▂▂▃▂▄▄▅▇█▅▃▂▂▁▁▂</td></tr><tr><td>R1</td><td>█▆▇███▇▇▆▃▂▁▆▄▅█▇▇▇▇▆█▅▅▆▆▃▄▅█▄▆▅▅</td></tr><tr><td>R2</td><td>█▇▇███▇▇▇▄▃▁▆▄▄█▇▆▆▇▆█▆▆▆▆▂▄▆█▄▅▅▅</td></tr><tr><td>acq_value (after finish)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▁▄▁▁▂▂█▄▃▅▅▃▄▆▃▇▆▅▇▇▄▃▄▅▆█▆▇▆▆▄▄▄</td></tr><tr><td>action_distance_to_local</td><td>▁▁▂▂▁▁▂▂▂▃▃▆▄▄▅▆▆▆▆▇▅▇▆▅▅▄▅▇█▆▆▆▅▄█▅▅▅▆▃</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁████████████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▆██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▅▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▅▂▁▂▁▂▂▁▁▂▂▁▂▂▁▁▂▁▁▂▁▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>max_return</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▅▅▆▇███████</td></tr><tr><td>max_std/mean</td><td>▁▂▂▅▄▁▄▄▄▇▁▁▂▁▁▁▃▁▁▁▅▃▁▂▃▁▁▁▂▁█▃▁▁</td></tr><tr><td>mean_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▆▂▂▁▂▂▂▁▁▁▂▁▂▂▁▁▂▁▁▂▁▂▂▂▃▃▂▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▂▄▂▅▄▁▄▄▄▆▂▂▂▁▁▂▄▂▁▂▅▃▂▂▃▁▁▁▂▂█▅▃▃</td></tr><tr><td>median_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▇▂▂▁▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂▂▁▂▂▃▂▃▂▁▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>▅▆▂▃▄▂▂▂▃▃▃▂▃▂▃▃▅▃▃▃▃▄▂▂▁▂▁▂▅▄▄█▆█</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▆▇▅█▇▅▆▇▇▇█▇▇▇▆▆█▇▅▆▆▇▇▆█▆▆▇▇▆▇▆</td></tr><tr><td>param_distance_to_local</td><td>▁▁▄▇▇▆▆▆▇█▇▇▇▆█▇▇▆▇█▆▇▇▆▇▆▇▆▇▆▆▇▅▇▇▆▆▆▅▆</td></tr><tr><td>policy_return</td><td>▂▁▂▁▁▂▂▃▂▂▂▃▂▂▂▃▂▂▃▂▂▄▃▃▃▄▅▄▅▅▇▇▇▇▇█████</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▂▃▃▃▃▃▃▃▃▄▄▅▅▆████████</td></tr><tr><td>var_reward</td><td>▂▂▄▁█▃▁▁▂▂▂▁█▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.03226</td></tr><tr><td>R1</td><td>-0.4033</td></tr><tr><td>R2</td><td>-1.16871</td></tr><tr><td>acq_value (after finish)</td><td>0.73369</td></tr><tr><td>action_distance_grad</td><td>0.12642</td></tr><tr><td>action_distance_to_local</td><td>0.11001</td></tr><tr><td>covar_lengthscale mean</td><td>0.29993</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07112</td></tr><tr><td>max_grad(before hessian)</td><td>0.06843</td></tr><tr><td>max_return</td><td>0.69445</td></tr><tr><td>max_std/mean</td><td>40.7334</td></tr><tr><td>mean_covar</td><td>-0.06135</td></tr><tr><td>mean_grad(before hessian)</td><td>0.02664</td></tr><tr><td>mean_std/mean</td><td>16.6184</td></tr><tr><td>median_covar</td><td>-0.06496</td></tr><tr><td>median_grad(before hessian)</td><td>0.01596</td></tr><tr><td>median_std/mean</td><td>13.37237</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.02981</td></tr><tr><td>param_distance_to_local</td><td>0.05339</td></tr><tr><td>policy_return</td><td>0.66965</td></tr><tr><td>policy_return_at_grad</td><td>0.67979</td></tr><tr><td>var_reward</td><td>8e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_787846414</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1p2uvgio\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1p2uvgio</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-1p2uvgio/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_670094950 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▂▁▂▅█▇▆▇▄▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▅█▆▁▁▅▇▅▆▇█▇▇▆▆▇▇▁▆▇▆▅▇▇▇▇▆▆█▆█▅█▆</td></tr><tr><td>R2</td><td>▆█▇▄▁▅▇▅▆▇█▇▇▆▆▇▇▂▇▇▆▅▇▇▇█▇▆█▇█▅█▇</td></tr><tr><td>acq_value (after finish)</td><td>▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▂▂▃▄▅▇▆▆▇▆▅▄▃▇▄▆▄▅▆▂▅▆▅▂▅▇▆▆▇▆█▇▆</td></tr><tr><td>action_distance_to_local</td><td>▁▁▁▃▃▃▅▂▃▅▄▆▅▄▃▅██▃▅▅▃▂▆▆▄▄▄▄▄▅▆▃▄▄▅▄▄▄▆</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇███████████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁█▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▂▄█▅▇▇▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▆▅▄▄▅▆▄▂▃▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>max_return</td><td>▁▁▂▃▄▄▇▇██████████████████████████</td></tr><tr><td>max_std/mean</td><td>▂▂▁▂▁▁▁▂▁▁▁▂▁▂▁▅▁▁▁▃▂▂▂▁▅▃▄▁▁▂▁▁▁█</td></tr><tr><td>mean_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▇▃▃▄▄▆▆▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▂▂▁▂▁▁▁▂▁▁▂▂▁▂▁▆▂▂▁▃▃▃▂▂█▅▄▂▁▃▂▂▁█</td></tr><tr><td>median_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▆▂▂▄▃█▇▃▃▁▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>▄▅▂▁▁▁▁▁▂▂▃▂▂▂▂▅▄▄▃▆▅█▅▃▄█▄▄▃▄▇▅▄▆</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▁▄▆▆▇██▇▅▆▇▇▇▆▇▆█▇▆▆▅▆▅▆▄▆▇▆▅▆▆▆</td></tr><tr><td>param_distance_to_local</td><td>▂▁▂▅▇▇▆▅▅▅▅█▇▆▆█▇▇▆▇▇▅▇▆██▇█▇▇█▇▆█▇▇▇█▇▅</td></tr><tr><td>policy_return</td><td>▂▂▁▃▃▂▅▆█▅██▇█▇▇▆▇███▇██████▇█████████▇█</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▁▃▄▄▅███████████████████████████</td></tr><tr><td>var_reward</td><td>▆█▂▁▁▄▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.03088</td></tr><tr><td>R1</td><td>-0.27979</td></tr><tr><td>R2</td><td>-0.66421</td></tr><tr><td>acq_value (after finish)</td><td>0.74705</td></tr><tr><td>action_distance_grad</td><td>0.23652</td></tr><tr><td>action_distance_to_local</td><td>0.30545</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>0.0</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.06954</td></tr><tr><td>max_grad(before hessian)</td><td>0.09225</td></tr><tr><td>max_return</td><td>1.02668</td></tr><tr><td>max_std/mean</td><td>1324.03894</td></tr><tr><td>mean_covar</td><td>-0.06067</td></tr><tr><td>mean_grad(before hessian)</td><td>0.0321</td></tr><tr><td>mean_std/mean</td><td>100.89969</td></tr><tr><td>median_covar</td><td>-0.06441</td></tr><tr><td>median_grad(before hessian)</td><td>0.02136</td></tr><tr><td>median_std/mean</td><td>11.50247</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.0296</td></tr><tr><td>param_distance_to_local</td><td>0.04208</td></tr><tr><td>policy_return</td><td>0.97901</td></tr><tr><td>policy_return_at_grad</td><td>1.01453</td></tr><tr><td>var_reward</td><td>7e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_127521863</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1y3viv9b\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1y3viv9b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-1y3viv9b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_415968276 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01110_862061404 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 576\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▂▂▂▃▄▃█▅▆▅▄▃▃▃▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▅▆▅▂▄▆▁▅▄▅▅▆█▇█▇▅▅▆▇▆▆▆▅▅▄▆▄▆▅▅▇▇▆</td></tr><tr><td>R2</td><td>▆█▇▄▅█▁▆▆▆▆▆████▇▇▇▇▇▇▇▆▇▅▇▅▆▅▆▇▇▇</td></tr><tr><td>acq_value (after finish)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▃▄▅▆▆▃▅▅▄▃▆▄▄▅▆▃▅▇▆▆▄▃▄▅█▅▄▅▅▄▇▇▅</td></tr><tr><td>action_distance_to_local</td><td>▁▁▃▂▃▆█▄▃▃▇▃▆▇▃▄▄▅▄█▆▇▆▇▄▆▆▅▅▅▄▄▅▇▇▄▇▄▄▂</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇█▇█████▇██▇▇███████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▇▁▅▄▆▄▅▁▆▅▁██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▁▁▃▄▆▄█▅▁▁▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▆▃▂▃▄▆▅▄▄▃▂▃▃▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_return</td><td>▁▂▂▃▃▄▆▆▇█████████████████████████</td></tr><tr><td>max_std/mean</td><td>▁▁▁▁▁█▁▁▁▄▁▁▁▁▁▁▁▁▁▁▂▃▃▆▁▁▁▁▂▂▁▂▁▂</td></tr><tr><td>mean_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▄▂▂▃▃▄▃▄▃▂▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▁▂▁▁▁█▁▁▁▃▁▁▁▁▁▂▁▂▁▁▂▃▃▆▁▂▁▁▂▂▂▃▂▂</td></tr><tr><td>median_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▄▂▂▂▂▂▂▃▂▂▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>▂▄▂▂▁▁▁▁▁▁▂▂▁▂▃▂▂▄▃▃▃▃█▄▅▄▃▄▄▄▄▇▄▅</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▂▁▄▇▅▅▄▅▇▆▄▆▇▅▆▇▇▇▇▆▇▆▇▆█▇▇▇▆▇▇▇█▇</td></tr><tr><td>param_distance_to_local</td><td>▁▁▃▆▇▇▆▅▅▆▇▇▆▇▅▅▄▅▆▆▇▇▇▇▅▆▇▅▆▆▆▇▆▆▇▅▇▆█▆</td></tr><tr><td>policy_return</td><td>▂▁▂▁▂▁▃▂▆▅▇▇█▇▅███▇█████▇█████████▇███▇█</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▂▃▃▃▆▆▇█████████████████████████</td></tr><tr><td>var_reward</td><td>▃▆▁██▃▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.01877</td></tr><tr><td>R1</td><td>-0.16764</td></tr><tr><td>R2</td><td>-0.61845</td></tr><tr><td>acq_value (after finish)</td><td>0.73559</td></tr><tr><td>action_distance_grad</td><td>0.18916</td></tr><tr><td>action_distance_to_local</td><td>0.07484</td></tr><tr><td>covar_lengthscale mean</td><td>0.29998</td></tr><tr><td>covar_lengthscale std</td><td>5e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.06913</td></tr><tr><td>max_grad(before hessian)</td><td>0.05643</td></tr><tr><td>max_return</td><td>1.02183</td></tr><tr><td>max_std/mean</td><td>142.33504</td></tr><tr><td>mean_covar</td><td>-0.06081</td></tr><tr><td>mean_grad(before hessian)</td><td>0.02463</td></tr><tr><td>mean_std/mean</td><td>23.22786</td></tr><tr><td>median_covar</td><td>-0.06474</td></tr><tr><td>median_grad(before hessian)</td><td>0.01746</td></tr><tr><td>median_std/mean</td><td>11.47681</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03117</td></tr><tr><td>param_distance_to_local</td><td>0.05223</td></tr><tr><td>policy_return</td><td>0.98908</td></tr><tr><td>policy_return_at_grad</td><td>1.00487</td></tr><tr><td>var_reward</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_841095289</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/ejifk333\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/ejifk333</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-ejifk333/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▂▃▃▃▃▄▄██▇▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▅▃▄▇█▆▇▂▃▄▆▆▅▃▂▅▅▄▇▆▇▇▁▅▇▇▄▅▆▅▇▄█▆</td></tr><tr><td>R2</td><td>▆▆▆██▇█▄▄▅▆▆▆▅▃▇▆▅▆▆▇▇▁▆▇█▄▅▆▆▇▆█▇</td></tr><tr><td>acq_value (after finish)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▂▂▃▅▄▆▆▆▇▇▆▅▄▆█▆▆▆▅▇█▇▆▇▄▇▆▇▆▃▆▇▆</td></tr><tr><td>action_distance_to_local</td><td>▁▁▂▃▄▇▃▅▄▅▅▃▅▄▅▆▄▃▄▅▇█▄▃▅▆▆▂▆▆▇▅▃▄▆▃▅▆▄▇</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇▇█▇▇███████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁█▆▅▅▅▄▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▂▂▂▄▇█▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>██▅▃▃▃▅▄▄▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>max_return</td><td>▁▁▂▃▃▄▄▇▇█████████████████████████</td></tr><tr><td>max_std/mean</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▂█▁▁▂▁▁▁▁▁▁▁▂▂</td></tr><tr><td>mean_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>▇█▃▂▂▃▅▅▅▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▂█▁▁▂▁▁▁▂▁▂▁▂▂</td></tr><tr><td>median_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>▇█▃▂▃▄▆▇▆▄▃▁▁▁▁▂▂▁▁▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>█▅▂▃▂▁▁▁▁▂▂▃▄▅▄▄▃▅▄▄▇█▅▃▃▅▅▃▆▇▆▅▇▄</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▁▃▅▅▅▆▆▅▇▆▆▇▆▇▇▆▆▆▅▅▆▆▇█▆▇▇▅▅▇▅▆</td></tr><tr><td>param_distance_to_local</td><td>▁▁▄▅▇▇▅▇▇█▆▆▇▅▇█▇▆▇▇▇▇▇▆▆█▇▅▇▇▇▇▆▇█▇▆▇▆█</td></tr><tr><td>policy_return</td><td>▂▁▂▁▁▂▄▃▆▂▅███▇█████▇██████▇██▇█████████</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▂▂▂▃▃▆▇█████████████████████████</td></tr><tr><td>var_reward</td><td>██▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.03544</td></tr><tr><td>R1</td><td>-0.32689</td></tr><tr><td>R2</td><td>-0.90764</td></tr><tr><td>acq_value (after finish)</td><td>0.75837</td></tr><tr><td>action_distance_grad</td><td>0.19417</td></tr><tr><td>action_distance_to_local</td><td>0.40346</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.06759</td></tr><tr><td>max_grad(before hessian)</td><td>0.07653</td></tr><tr><td>max_return</td><td>1.02222</td></tr><tr><td>max_std/mean</td><td>545.44867</td></tr><tr><td>mean_covar</td><td>-0.06013</td></tr><tr><td>mean_grad(before hessian)</td><td>0.03674</td></tr><tr><td>mean_std/mean</td><td>77.22445</td></tr><tr><td>median_covar</td><td>-0.06406</td></tr><tr><td>median_grad(before hessian)</td><td>0.0399</td></tr><tr><td>median_std/mean</td><td>5.79891</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03115</td></tr><tr><td>param_distance_to_local</td><td>0.06081</td></tr><tr><td>policy_return</td><td>1.01043</td></tr><tr><td>policy_return_at_grad</td><td>1.01232</td></tr><tr><td>var_reward</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_199900595</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1k4cuj47\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1k4cuj47</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-1k4cuj47/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▂▂▂▂▄█▆▄▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▆▅▇▇▆▁▄▅▄▇▆▇▄▁▃▂▇▆▇▆▄▄▂█▅█▇▆▇▆▇▇▅▄</td></tr><tr><td>R2</td><td>▇▆██▆▁▄▅▆▇▆▇▄▂▄▅█▆▇▇▅▄▄█▆█▆▆▇▆▇█▆▆</td></tr><tr><td>acq_value (after finish)</td><td>▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▂▅▆▅▅▄▃▅▇▃▃▄▆▆▆▅▇▂▇▅▆▆█▅▅▆▃▆▄▃▅▆▆</td></tr><tr><td>action_distance_to_local</td><td>▁▁▂▂▃▅▃▅▆▆▄▆▄▄▅▅▇▅▆▄▆▆▅▄▇▃▅▇▅▆▇█▇▅▆▂▆▄▅▃</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇█▇█▇▇▇▇▆▆▇███▇█████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▅▁▄▄▅▆▇▅██▅▂▁▂▄▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▄█▄▇▇▄▅▅▁▁▁▁▁▁▅▂▁▁▁▁▁▁▁▆▃▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▅▁▁▁▁▁▁▁▁▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▄▃▂▃█▆▃▄▂▂▂▂▁▂▁▃▂▁▂▁▁▁▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>max_return</td><td>▁▂▂▄▆▆▇▇██████████████████████████</td></tr><tr><td>max_std/mean</td><td>▂▅▂▁▁▁▂▁▁▁▁█▁▆▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▃▁▃</td></tr><tr><td>mean_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▄▂▃▃▅▄▃▃▃▂▂▂▁▂▁▃▂▁▁▂▂▁▂▁▃▂▁▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▃▆▂▁▁▁▂▁▁▁▂█▁█▁▂▁▂▂▂▁▁▂▁▂▁▁▁▂▁▂▄▂▅</td></tr><tr><td>median_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▅▃▄▂▅▄▂▃▃▁▂▂▁▂▁▂▂▁▁▂▂▁▂▁▃▂▂▁▂▁▂▁▁</td></tr><tr><td>median_std/mean</td><td>▅█▂▁▂▁▁▂▁▁▃▄▃▃▂▅▁▂▅▄▂▂▅▂▅▁▂▃▄▃▄▃▇▅</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▄▇▄▂▂▃▂▆▁▂▃▆▇▆▅▇▆▄▇█▇▇▅▇▆█▆▇▇▇▆▆</td></tr><tr><td>param_distance_to_local</td><td>▁▁▁▅▅▆▆▅▆▆▆▇▅▆▆▅█▆▆▆▆▇▄▆▆▅▆▇▇▇▆▆▆▆█▅▇▆▇▆</td></tr><tr><td>policy_return</td><td>▃▁▂▁▁▃▁▇▇▇██▇█▇█▇██▇▇▇█▇▇███▇█▇██▇██████</td></tr><tr><td>policy_return_at_grad</td><td>▁▂▂▂▁▆▇▇█▇██████▇█████████████████</td></tr><tr><td>var_reward</td><td>█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.03399</td></tr><tr><td>R1</td><td>-0.32978</td></tr><tr><td>R2</td><td>-0.70883</td></tr><tr><td>acq_value (after finish)</td><td>0.69073</td></tr><tr><td>action_distance_grad</td><td>0.22312</td></tr><tr><td>action_distance_to_local</td><td>0.15532</td></tr><tr><td>covar_lengthscale mean</td><td>0.29998</td></tr><tr><td>covar_lengthscale std</td><td>3e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07516</td></tr><tr><td>max_grad(before hessian)</td><td>0.08616</td></tr><tr><td>max_return</td><td>1.02051</td></tr><tr><td>max_std/mean</td><td>339.63779</td></tr><tr><td>mean_covar</td><td>-0.0643</td></tr><tr><td>mean_grad(before hessian)</td><td>0.03425</td></tr><tr><td>mean_std/mean</td><td>40.59852</td></tr><tr><td>median_covar</td><td>-0.0687</td></tr><tr><td>median_grad(before hessian)</td><td>0.03133</td></tr><tr><td>median_std/mean</td><td>7.1354</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.02987</td></tr><tr><td>param_distance_to_local</td><td>0.05404</td></tr><tr><td>policy_return</td><td>0.97366</td></tr><tr><td>policy_return_at_grad</td><td>1.00729</td></tr><tr><td>var_reward</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_670094950</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/31r4ujw1\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/31r4ujw1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-31r4ujw1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▂▂▂▂▂▃▄▅█▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▁▆▄▇█▇▄▂▁▆▆▅▆▆▅█▆█▆▆▆▇▇█▄▇▇▇█▇▆▇▄▇</td></tr><tr><td>R2</td><td>▃▅▇███▆▄▁▅▆▆▆▆▅▇▆█▇▇▆▇▇▇▅▆▆▆█▇▆▇▅█</td></tr><tr><td>acq_value (after finish)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▂▄▁▄▃▃▄▇▇▄▆▅▅▆▄▆█▄▅▆▅▄▆▄▄▅▆▇▆▁▅▇█</td></tr><tr><td>action_distance_to_local</td><td>▁▁▂▄▅▄▃▄▆▃▅▅▆▅▅▅▅▇▆▅▇▅▅▇▂▄▅▅▅▅█▆█▄▆▅▅▇▄▄</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁█▇▇▇▇███████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▄█▇▆▇▄▂▃▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▃▂▄▃▅▆██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▇▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▂▂▆▄▇▅▃▄▄▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_return</td><td>▁▁▁▅▅▅▅▆██████████████████████████</td></tr><tr><td>max_std/mean</td><td>▁▂▁▁▁▁▁▁▁▁▁█▂▁▁▁▁▁▁▂▁▁▂▂▁▂▁▁▁█▁▂▃▂</td></tr><tr><td>mean_covar</td><td>▁▂████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▃▃▃▃▄▄▄▅▄▄▂▂▂▂▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▂▄▁▁▁▁▁▁▁▁▁▇▂▁▁▁▂▁▂▂▂▁▂▃▂▂▂▂▂█▂▄▃▂</td></tr><tr><td>median_covar</td><td>▁▁████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▄▄▃▃▃▄▄█▅▅▂▂▃▂▂▁▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>▄█▁▂▁▁▁▁▁▁▁▂▂▁▂▂▂▁▂▂▂▂▂▃▃▃▄▃▃▃▃█▃▃</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▂▃▇▁▃▁▃▇▇▆▇▆▆█▇▇▆▇██▆█▇▇▇█▇██▇█▆▆▇</td></tr><tr><td>param_distance_to_local</td><td>▁▁▁▆▄▄▄▆▇▇▇▇▅▅▇▇▆▇▆▇▇▇█▇▆▆▇▆▇▇▇▇▇▆▇▆▇▇▇▇</td></tr><tr><td>policy_return</td><td>▁▁▂▂▄▃▅▄▆▇▇▅▇█▆██▇▇▇████▆██▇▇██████▇████</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▁▂▂▂▄▅██████████████████████████</td></tr><tr><td>var_reward</td><td>▂▄▂▇▂▅▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.03596</td></tr><tr><td>R1</td><td>-0.0815</td></tr><tr><td>R2</td><td>-0.11355</td></tr><tr><td>acq_value (after finish)</td><td>0.7443</td></tr><tr><td>action_distance_grad</td><td>0.28118</td></tr><tr><td>action_distance_to_local</td><td>0.16158</td></tr><tr><td>covar_lengthscale mean</td><td>0.29998</td></tr><tr><td>covar_lengthscale std</td><td>2e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07257</td></tr><tr><td>max_grad(before hessian)</td><td>0.10993</td></tr><tr><td>max_return</td><td>1.02042</td></tr><tr><td>max_std/mean</td><td>154.07698</td></tr><tr><td>mean_covar</td><td>-0.0604</td></tr><tr><td>mean_grad(before hessian)</td><td>0.04554</td></tr><tr><td>mean_std/mean</td><td>21.70228</td></tr><tr><td>median_covar</td><td>-0.06368</td></tr><tr><td>median_grad(before hessian)</td><td>0.03115</td></tr><tr><td>median_std/mean</td><td>6.21866</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.02914</td></tr><tr><td>param_distance_to_local</td><td>0.05551</td></tr><tr><td>policy_return</td><td>0.94243</td></tr><tr><td>policy_return_at_grad</td><td>0.97469</td></tr><tr><td>var_reward</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_415968276</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/18xhhilx\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/18xhhilx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-18xhhilx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01110_423734972 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▃▁▃▃▃▃▇█▆▇▅▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>R1</td><td>▁▇▆▇▇▇▅▄▆▆▇██▇▇▇▇▇▇▇▇▇▇▇▆▇▇▆█▆▆▇▇▇</td></tr><tr><td>R2</td><td>▁█▇███▅▄▇▆▇██▇██████▇▇█▇▇█▇▆█▇▇▇▇▇</td></tr><tr><td>acq_value (after finish)</td><td>▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▃▃▂▃▆▅▅▇▅▆█▇▄▅▆▆▇▆▃▆▇▆▇▅▇▄▄█▅▃▄▆▄</td></tr><tr><td>action_distance_to_local</td><td>▁▁▂▃▅▄▃▃▆▄▃▄▂▇▄▅▄▅▅▇▇▅▃▆▅▇▆▄▅▅█▅▆▆▇▃▆▇▇▇</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁████████████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁█▇█▃█▅▄▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▂▂▂▅█▅▇▅▇▁▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▄▄▄▂▃▅▄▄▆▆▄▃▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_return</td><td>▁▁▁▃▃▃▅▆▆▇████████████████████████</td></tr><tr><td>max_std/mean</td><td>▁▁▁▁█▁▁▂▁▁▁▆▁▁▁▁▁▂▂▂▁▁▃▁▂▃▂▁▁▂▂▂▁▁</td></tr><tr><td>mean_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▆▃▃▃▄▅▄▅▇▇▄▃▂▁▃▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_std/mean</td><td>▂▂▁▁█▁▁▂▁▁▁▆▁▁▂▁▂▂▂▂▂▁▄▂▃▃▂▂▃▃▄▃▂▂</td></tr><tr><td>median_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▆▃▄▃▃▅▃▄▇█▄▄▂▂▄▂▁▃▂▁▂▁▁▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>median_std/mean</td><td>▄▆▂▁▁▁▁▁▁▁▁▂▂▂▂▁▂▄▂▂▃▂▆▄▅▃▄▃█▅▇▆▅▅</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▄▄▆▆▆▅▇▇▇▆▇▇▇██▆█▇▆▆▆▆▇▆▇█▄▅▅▆▇▇</td></tr><tr><td>param_distance_to_local</td><td>▂▁▂▇▇▆▇▇▇▆▇▆▆▆▆▆▇▇▇▇▆▆▇▅▇▆▇▇▇▇▆▇▆█▆▆▇▆▆█</td></tr><tr><td>policy_return</td><td>▁▁▂▂▃▃▅▅▆▅▇▅▇█▇██████▆███▇████▇▇██████▇█</td></tr><tr><td>policy_return_at_grad</td><td>▂▁▂▂▃▃▅▆▆▇████████████████████████</td></tr><tr><td>var_reward</td><td>▁█▆▁▁▄▄▁▁▁▁▂▂▂▁▂▂▁▁▁▁▃▁▂▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.02648</td></tr><tr><td>R1</td><td>-0.30519</td></tr><tr><td>R2</td><td>-0.89606</td></tr><tr><td>acq_value (after finish)</td><td>0.73269</td></tr><tr><td>action_distance_grad</td><td>0.10167</td></tr><tr><td>action_distance_to_local</td><td>0.31806</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>2e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07218</td></tr><tr><td>max_grad(before hessian)</td><td>0.07036</td></tr><tr><td>max_return</td><td>1.02494</td></tr><tr><td>max_std/mean</td><td>57.45256</td></tr><tr><td>mean_covar</td><td>-0.06125</td></tr><tr><td>mean_grad(before hessian)</td><td>0.027</td></tr><tr><td>mean_std/mean</td><td>16.49996</td></tr><tr><td>median_covar</td><td>-0.06554</td></tr><tr><td>median_grad(before hessian)</td><td>0.02285</td></tr><tr><td>median_std/mean</td><td>10.4657</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03113</td></tr><tr><td>param_distance_to_local</td><td>0.06234</td></tr><tr><td>policy_return</td><td>0.89562</td></tr><tr><td>policy_return_at_grad</td><td>0.99601</td></tr><tr><td>var_reward</td><td>5e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_862061404</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2292vang\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2292vang</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-2292vang/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▁▁▂▄▄▅█▆▆▄▂▂▂▃▂▁▁▂▁▁▁▁▁▁▁▂▂▂▁▂▂▂▁▁</td></tr><tr><td>R1</td><td>▆▇▂▁▆▆▂▄▄▅▄▅▅▄▆▆▇▄▇▅▅▆▆▅▆█▆▇█▇▆▇▆▇</td></tr><tr><td>R2</td><td>██▃▄█▇▁▅▄▄▄▅▆▅▆▆▇▅▇▆▅▇▇▆▇▇▆▇██▆▇▇▇</td></tr><tr><td>acq_value (after finish)</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>action_distance_grad</td><td>▁▂▅▄▅▇▆▄▅▄▇▆▆▇▅▅▅▄▇▅▅█▅▆▆█▆▆▆█▆▇▇▇</td></tr><tr><td>action_distance_to_local</td><td>▁▁▁▅▄▃▅▆▄▄▅▇█▇▅▅▇▇▅▄▅█▃▃▅▅▄▄█▆▅▅█▄▅▄▂▄▆▅</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▇█▇█████████████████████████████</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▆▄█▆▅▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>covar_output_scale</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>episode_length</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁</td></tr><tr><td>fraction_sparse</td><td>▁▁▃▄▄▇█▆▄▂▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▂▁▃▁▂▁▁▁▁</td></tr><tr><td>max_covar</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>█▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_grad(before hessian)</td><td>█▄▂▄▅▆▄▄▂▂▁▂▂▂▂▁▂▁▁▁▁▂▁▂▂▂▁▂▂▂▂▁▁▂</td></tr><tr><td>max_return</td><td>▁▂▂▃▄▅▆▇██████████████████████████</td></tr><tr><td>max_std/mean</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>mean_grad(before hessian)</td><td>█▅▂▃▃▅▅▄▃▂▂▂▃▂▂▁▂▂▁▂▁▂▁▂▁▂▂▃▂▂▂▂▁▂</td></tr><tr><td>mean_std/mean</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>median_covar</td><td>▁▃████████████████████████████████</td></tr><tr><td>median_grad(before hessian)</td><td>█▆▃▂▂▆▇▆▄▃▂▂▄▂▂▁▃▃▁▂▁▃▁▂▁▃▁▂▁▂▂▂▂▂</td></tr><tr><td>median_std/mean</td><td>▄█▂▂▁▁▁▁▁▂▃▂▁▂▃▅▂▂▄▂▄▂▅▃▃▂▃▂▃▂▃▂▃▂</td></tr><tr><td>n_info_points</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>n_samples</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>noise</td><td>██▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_grad</td><td>▁▁▇▄▁▄▆▅▆▆▇▆▇█▆▇█▇██▇▇▇▆▆▇▆▇▆▅▆█▇▆</td></tr><tr><td>param_distance_to_local</td><td>▁▁▂▅▅▃▅▅▅▆▇▆▆▆▆█▇▇▆▆▆▆▇▆▆▆▅▆▆▅▅▆▇▅▆▆▅▆▆▆</td></tr><tr><td>policy_return</td><td>▁▂▂▂▃▄▆▇▇█▇█▇▇██▇█▇█▆██▇█▇██▇█████▇▇█▆█▇</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▂▂▂▄▆▇██████████████████████████</td></tr><tr><td>var_reward</td><td>▂▁▁▂▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.05615</td></tr><tr><td>R1</td><td>0.05148</td></tr><tr><td>R2</td><td>-0.19861</td></tr><tr><td>acq_value (after finish)</td><td>0.68688</td></tr><tr><td>action_distance_grad</td><td>0.26032</td></tr><tr><td>action_distance_to_local</td><td>0.21326</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>3e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07647</td></tr><tr><td>max_grad(before hessian)</td><td>0.3106</td></tr><tr><td>max_return</td><td>1.02808</td></tr><tr><td>max_std/mean</td><td>68.54453</td></tr><tr><td>mean_covar</td><td>-0.06368</td></tr><tr><td>mean_grad(before hessian)</td><td>0.09356</td></tr><tr><td>mean_std/mean</td><td>8.35092</td></tr><tr><td>median_covar</td><td>-0.06772</td></tr><tr><td>median_grad(before hessian)</td><td>0.06276</td></tr><tr><td>median_std/mean</td><td>2.99999</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.02917</td></tr><tr><td>param_distance_to_local</td><td>0.05274</td></tr><tr><td>policy_return</td><td>0.96315</td></tr><tr><td>policy_return_at_grad</td><td>0.97548</td></tr><tr><td>var_reward</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01110_423734972</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/wz1xxgtl\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/wz1xxgtl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_223249-wz1xxgtl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd /home/mkallel/explo/\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from warnings import simplefilter\n",
    "\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "import threading\n",
    "import wandb\n",
    "from src.config import get_configs\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "import itertools\n",
    "\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n",
    "os.environ[\"WANDB_API_KEY\"]=\"28996bd59f1ba2c5a8c3f2cc23d8673c327ae230\"\n",
    "\n",
    "def run(seed,\n",
    "        env_name,\n",
    "        kernel_name,\n",
    "        manipulate_state,\n",
    "        norm_grad,\n",
    "        conf_grad,\n",
    "        advantage_mean,\n",
    "        adaptive_lr,\n",
    "        lr ):\n",
    "\n",
    "        #env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "        #env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "        #env_name = \"Hopper-v2\"\n",
    "        #env_name = \"HalfCheetah-v2\"        \n",
    "        #env_name = \"Walker2d-v3\"\n",
    "\n",
    "        #kernel_name = \"rbfstate\" ## \"rbf\"\n",
    "        #kernel_name = \"rbf\" ## \"rbf\"\n",
    "\n",
    "        project_name = env_name+(\"RBF + Confidence Grad 2\")\n",
    "        run_name =  kernel_name +\"_lr=\"+str(lr) +\"_\"+str(1 *manipulate_state)+ str(1 *norm_grad) + str(1 *conf_grad) + str(1 *advantage_mean)+str(1 *adaptive_lr) +\"_\"+ str(seed)\n",
    "        env_config,policy_config,likelihood_config,kernel_config,mean_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name,\n",
    "        use_ard=True,manipulate_state=manipulate_state,\n",
    "        conf_grad=conf_grad,norm_grad=norm_grad,advantage_mean=advantage_mean,adaptive_lr=adaptive_lr,lr=lr,\n",
    "        wandb_logger=True,project_name=project_name,run_name=run_name)\n",
    "\n",
    "        model,objective_env,optimizer = setup_experiment(env_config,mean_config,kernel_config,likelihood_config,policy_config,optimizer_config,\n",
    "                                        seed=seed)\n",
    "\n",
    "        trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "        trainer.run()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "        \n",
    "        wandb.require(\"service\")\n",
    "        wandb.setup()  \n",
    "\n",
    "        env_name = [\"Swimmer-v4\"]\n",
    "        #env_name = [\"CartPole-v1\"]\n",
    "        kernel_name = [\"rbf\"]\n",
    "        manipulate_state = [False]\n",
    "        conf_grad = [True] ##run this for rbf\n",
    "        norm_grad = [True]\n",
    "        advantage_mean = [True]\n",
    "        adaptive_lr = [False]\n",
    "        lr = [0.5]\n",
    "        \n",
    "        n= 10\n",
    "        np.random.seed(42)\n",
    "        seeds = np.random.randint(low=0,high=2**30,size=(n,))\n",
    "\n",
    "        for config in itertools.product(*[env_name,kernel_name,manipulate_state,norm_grad,conf_grad,advantage_mean,adaptive_lr,lr]):\n",
    "\n",
    "            \n",
    "                seeds = [ int(i) for i in seeds]\n",
    "\n",
    "                with Pool(processes=n) as p:\n",
    "                        args = [(seed,*config) for seed in seeds]\n",
    "                        p.starmap(run, args)\n",
    "\n",
    "                #run(*(0,*config))\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('bopt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c7e76b21fbf8268359659a13a1687ca07cc6ddf0d10c2b26cf47d2a8edd420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
