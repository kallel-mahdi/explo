{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bound(n_dim,p):\n",
    "\n",
    "    dx = 0.001\n",
    "    x = np.arange(0, n_dim,dx)\n",
    "\n",
    "    cdf = np.cumsum(chi2.pdf(x, df=n_dim)*dx)\n",
    "    bound = max(x[cdf<=p])\n",
    "\n",
    "    return bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 100\n",
    "mu = np.random.rand(n_dim)\n",
    "A = 0.25 * np.random.rand(n_dim,n_dim) +  0.25 *mu\n",
    "Corr = np.random.rand(n_dim) \n",
    "Corr = np.diag(Corr)\n",
    "\n",
    "Sigma = A.T @ A \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigvals,P = np.linalg.eigh(Sigma)\n",
    "# D = np.diag(eigvals)\n",
    "# D_inv = np.diag(1/eigvals)\n",
    "\n",
    "# Sigma_inv = P.T @ D_inv @ P\n",
    "\n",
    "# #(P @ D @ P.T) @ (P @ D_inv @ P.T)\n",
    "\n",
    "# np.max(Sigma - (P @ D @ P.T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsify_grad(mu,Sigma):\n",
    "\n",
    "\n",
    "    n_dim = mu.shape[0]\n",
    "    \n",
    "    eigvals,P = np.linalg.eigh(Sigma)\n",
    "    assert (eigvals >= 0).all()\n",
    "\n",
    "    \n",
    "    ### Square root of Sigma_inv\n",
    "\n",
    "    D = np.diag(1/eigvals)\n",
    "    D_sqrt = np.diag(np.sqrt(1/eigvals))\n",
    "    P_p = P.T@D_sqrt \n",
    "\n",
    "    \n",
    "    ###################\n",
    "\n",
    "    C = get_bound(n_dim,p=0.05)\n",
    "\n",
    "    x = cvx.Variable((n_dim))\n",
    "    objective = cvx.Minimize(cvx.norm(x,1))\n",
    "    pb = cvx.Problem(objective,\n",
    "                    [cvx.sum_squares(P_p@x -P_p@mu) <= C])\n",
    "\n",
    "    pb.solve(verbose=False)\n",
    "\n",
    "    rslt = x.value\n",
    "\n",
    "    assert all(rslt<=mu)\n",
    "\n",
    "    relative_diff = abs(rslt-mu)/mu\n",
    "\n",
    "    plt.hist(relative_diff)\n",
    "\n",
    "    return np.sum(relative_diff>0.9), np.sum(relative_diff<0.1),np.sum(relative_diff<0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 9, 21)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sparsify_grad(mu,Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qcl1(A, b):\n",
    "    \"\"\"\n",
    "    Returns the solution u, z of\n",
    "\n",
    "        (primal)  minimize    || u ||_1\n",
    "                  subject to  || A * u - b ||_2  <= 1\n",
    "\n",
    "        (dual)    maximize    b^T z - ||z||_2\n",
    "                  subject to  || A'*z ||_inf <= 1.\n",
    "\n",
    "    Exploits structure, assuming A is m by n with m >= n.\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = A.shape\n",
    "\n",
    "    # Solve equivalent cone LP with variables x = [u; v].\n",
    "    #\n",
    "    #     minimize    [0; 1]' * x\n",
    "    #     subject to  [ I  -I ] * x <=  [  0 ]   (componentwise)\n",
    "    #                 [-I  -I ] * x <=  [  0 ]   (componentwise)\n",
    "    #                 [ 0   0 ] * x <=  [  1 ]   (SOC)\n",
    "    #                 [-A   0 ]         [ -b ]\n",
    "    #\n",
    "    #     maximize    -t + b' * w\n",
    "    #     subject to  z1 - z2 = A'*w\n",
    "    #                 z1 + z2 = 1\n",
    "    #                 z1 >= 0,  z2 >=0,  ||w||_2 <= t.\n",
    "\n",
    "    c = matrix(n*[0.0] + n*[1.0])\n",
    "    h = matrix( 0.0, (2*n + m + 1, 1))\n",
    "    h[2*n] = 1.0\n",
    "    h[2*n+1:] = -b\n",
    "\n",
    "    def G(x, y, alpha = 1.0, beta = 0.0, trans = 'N'):\n",
    "        y *= beta\n",
    "        if trans=='N':\n",
    "            # y += alpha * G * x\n",
    "            y[:n] += alpha * (x[:n] - x[n:2*n])\n",
    "            y[n:2*n] += alpha * (-x[:n] - x[n:2*n])\n",
    "            y[2*n+1:] -= alpha * A*x[:n]\n",
    "\n",
    "        else:\n",
    "            # y += alpha * G'*x\n",
    "            y[:n] += alpha * (x[:n] - x[n:2*n] - A.T * x[-m:])\n",
    "            y[n:] -= alpha * (x[:n] + x[n:2*n])\n",
    "\n",
    "\n",
    "    def Fkkt(W):\n",
    "        \"\"\"\n",
    "        Returns a function f(x, y, z) that solves\n",
    "\n",
    "            [ 0   G'   ] [ x ] = [ bx ]\n",
    "            [ G  -W'*W ] [ z ]   [ bz ].\n",
    "        \"\"\"\n",
    "\n",
    "        # First factor\n",
    "        #\n",
    "        #     S = G' * W**-1 * W**-T * G\n",
    "        #       = [0; -A]' * W3^-2 * [0; -A] + 4 * (W1**2 + W2**2)**-1\n",
    "        #\n",
    "        # where\n",
    "        #\n",
    "        #     W1 = diag(d1) with d1 = W['d'][:n] = 1 ./ W['di'][:n]\n",
    "        #     W2 = diag(d2) with d2 = W['d'][n:] = 1 ./ W['di'][n:]\n",
    "        #     W3 = beta * (2*v*v' - J),  W3^-1 = 1/beta * (2*J*v*v'*J - J)\n",
    "        #        with beta = W['beta'][0], v = W['v'][0], J = [1, 0; 0, -I].\n",
    "\n",
    "        # As = W3^-1 * [ 0 ; -A ] = 1/beta * ( 2*J*v * v' - I ) * [0; A]\n",
    "        beta, v = W['beta'][0], W['v'][0]\n",
    "        As = 2 * v * (v[1:].T * A)\n",
    "        As[1:,:] *= -1.0\n",
    "        As[1:,:] -= A\n",
    "        As /= beta\n",
    "\n",
    "        # S = As'*As + 4 * (W1**2 + W2**2)**-1\n",
    "        S = As.T * As\n",
    "        d1, d2 = W['d'][:n], W['d'][n:]\n",
    "        d = 4.0 * (d1**2 + d2**2)**-1\n",
    "        S[::n+1] += d\n",
    "        lapack.potrf(S)\n",
    "\n",
    "        def f(x, y, z):\n",
    "\n",
    "            # z := - W**-T * z\n",
    "            z[:n] = -div( z[:n], d1 )\n",
    "            z[n:2*n] = -div( z[n:2*n], d2 )\n",
    "            z[2*n:] -= 2.0*v*( v[0]*z[2*n] - blas.dot(v[1:], z[2*n+1:]) )\n",
    "            z[2*n+1:] *= -1.0\n",
    "            z[2*n:] /= beta\n",
    "\n",
    "            # x := x - G' * W**-1 * z\n",
    "            x[:n] -= div(z[:n], d1) - div(z[n:2*n], d2) + As.T * z[-(m+1):]\n",
    "            x[n:] += div(z[:n], d1) + div(z[n:2*n], d2)\n",
    "\n",
    "            # Solve for x[:n]:\n",
    "            #\n",
    "            #    S*x[:n] = x[:n] - (W1**2 - W2**2)(W1**2 + W2**2)^-1 * x[n:]\n",
    "\n",
    "            x[:n] -= mul( div(d1**2 - d2**2, d1**2 + d2**2), x[n:])\n",
    "            lapack.potrs(S, x)\n",
    "\n",
    "            # Solve for x[n:]:\n",
    "            #\n",
    "            #    (d1**-2 + d2**-2) * x[n:] = x[n:] + (d1**-2 - d2**-2)*x[:n]\n",
    "\n",
    "            x[n:] += mul( d1**-2 - d2**-2, x[:n])\n",
    "            x[n:] = div( x[n:], d1**-2 + d2**-2)\n",
    "\n",
    "            # z := z + W^-T * G*x\n",
    "            z[:n] += div( x[:n] - x[n:2*n], d1)\n",
    "            z[n:2*n] += div( -x[:n] - x[n:2*n], d2)\n",
    "            z[2*n:] += As*x[:n]\n",
    "\n",
    "        return f\n",
    "\n",
    "    dims = {'l': 2*n, 'q': [m+1], 's': []}\n",
    "    sol = solvers.conelp(c, G, h, dims, kktsolver = Fkkt)\n",
    "    if sol['status'] == 'optimal':\n",
    "        return sol['x'][:n],  sol['z'][-m:]\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mkallel/explo/experiments/sparsify_grad.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m C \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m A,b \u001b[39m=\u001b[39m A\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39msqrt(C), b\u001b[39m/\u001b[39mnp\u001b[39m.\u001b[39msqrt(C)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m qcl1(A,b)\n",
      "\u001b[1;32m/home/mkallel/explo/experiments/sparsify_grad.ipynb Cell 5\u001b[0m in \u001b[0;36mqcl1\u001b[0;34m(A, b)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m m, n \u001b[39m=\u001b[39m A\u001b[39m.\u001b[39mshape\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Solve equivalent cone LP with variables x = [u; v].\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#     minimize    [0; 1]' * x\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#                 z1 + z2 = 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#                 z1 >= 0,  z2 >=0,  ||w||_2 <= t.\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m c \u001b[39m=\u001b[39m matrix(n\u001b[39m*\u001b[39m[\u001b[39m0.0\u001b[39m] \u001b[39m+\u001b[39m n\u001b[39m*\u001b[39m[\u001b[39m1.0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m h \u001b[39m=\u001b[39m matrix( \u001b[39m0.0\u001b[39m, (\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mn \u001b[39m+\u001b[39m m \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/sparsify_grad.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m h[\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mn] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "n_dim = P.shape\n",
    "mu = np.ones(n_dim)\n",
    "A = P @ D_sqrt\n",
    "b = A@mu\n",
    "C = 10\n",
    "A,b = A/np.sqrt(C), b/np.sqrt(C)\n",
    "\n",
    "\n",
    "qcl1(A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9610, dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_bound(n_dim,p):\n",
    "\n",
    "\n",
    "    dx = 0.001\n",
    "    x = np.arange(0, n_dim,dx)\n",
    "\n",
    "    cdf = np.cumsum(chi2.pdf(x, df=n_dim)*dx)\n",
    "    bound = max(x[cdf<=p])\n",
    "\n",
    "    return torch.tensor(bound)\n",
    "\n",
    "get_bound(16,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkallel/explo\n",
      "tensor([[1.4427, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, 1.4427, -0.0000, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, 1.4427, -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, 1.4427, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, 1.4427, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, 1.4427]])\n"
     ]
    }
   ],
   "source": [
    "%cd /home/mkallel/explo/\n",
    "from src.gp.kernels import MyRBFKernel\n",
    "\n",
    "n_dim = 6\n",
    "kernel = MyRBFKernel(6,True)\n",
    "theta = torch.zeros(1,6,requires_grad=True)\n",
    "kernel(theta,theta).evaluate()\n",
    "\n",
    "theta_t2 = theta.clone().detach() ## hotfix otherwise 0 hessian\n",
    "## this might be a cause of error, try to find method to compute using k(theta,theta)\n",
    "hessian1 = -torch.autograd.functional.hessian(func=lambda theta : kernel(theta,theta_t2).evaluate(),\n",
    "                                            inputs=(theta))\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "print(hessian1.squeeze())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4427, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.4427, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.4427, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.4427, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 1.4427, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.4427]])\n"
     ]
    }
   ],
   "source": [
    "lengthscale = kernel.base_kernel.lengthscale.detach()\n",
    "sigma_f = kernel.outputscale.detach()\n",
    "hessian2 = (torch.eye(n_dim, device=lengthscale.device) / lengthscale ** 2) * sigma_f\n",
    "print(hessian2.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkallel/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MLPPPPPPPPP SETUPMLPPPPPPPPP SETUPMLPPPPPPPPP SETUPMLPPPPPPPPP SETUP MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "   16MLPPPPPPPPP SETUP16MLPPPPPPPPP SETUP1616\n",
      "\n",
      "  MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "\n",
      "MLP LEEEEENMLP LEEEEEN1616MLPPPPPPPPP SETUPMLPPPPPPPPP SETUPMLPPPPPPPPP SETUPMLP LEEEEEN MLP LEEEEENMLPPPPPPPPP SETUP \n",
      "\n",
      "     1616 MLP LEEEEENMLP LEEEEEN1616161616\n",
      "\n",
      "16 \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "16\n",
      "MLP LEEEEENMLP LEEEEENMLP LEEEEENMLP LEEEEEN\n",
      "16    161616\n",
      "\n",
      "\n",
      "\n",
      "16\n",
      "Using ard_num_dims = 16\n",
      "Using ard_num_dims = 16\n",
      "Using ard_num_dims = 16\n",
      "Using ard_num_dims = 16\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samplesUsing ard_num_dims = 16\n",
      "\n",
      " Gibo will use 32 last points to fit GP and 16 info samplesfixing seed to \n",
      " fixing seed to  Gibo will use 32 last points to fit GP and 16 info samples534895718 \n",
      "\n",
      "fixing seed to 862061404 \n",
      " Gibo will use 32 last points to fit GP and 16 info samples787846414\n",
      "\n",
      "fixing seed to   Gibo will use 32 last points to fit GP and 16 info samples Gibo will use 32 last points to fit GP and 16 info samples670094950\n",
      "\n",
      "\n",
      "fixing seed to fixing seed to   127521863423734972\n",
      "\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  199900595\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  996406378\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  841095289\n",
      "Using ard_num_dims = 16\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  415968276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-9xve09uu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/9xve09uu\" target=\"_blank\">rbf_lr=0.5_01100_127521863</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-1xpmqhf7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1xpmqhf7\" target=\"_blank\">rbf_lr=0.5_01100_423734972</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-2cqbzyby</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2cqbzyby\" target=\"_blank\">rbf_lr=0.5_01100_670094950</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-3nwk8ilc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/3nwk8ilc\" target=\"_blank\">rbf_lr=0.5_01100_415968276</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-22bgg9kw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-d51266qf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/22bgg9kw\" target=\"_blank\">rbf_lr=0.5_01100_534895718</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/d51266qf\" target=\"_blank\">rbf_lr=0.5_01100_199900595</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-23ev0609</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/23ev0609\" target=\"_blank\">rbf_lr=0.5_01100_787846414</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-1snw0hq7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1snw0hq7\" target=\"_blank\">rbf_lr=0.5_01100_996406378</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-5s9icjuo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/5s9icjuo\" target=\"_blank\">rbf_lr=0.5_01100_862061404</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mkallel/explo/wandb/run-20220902_222050-39slc1bv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/39slc1bv\" target=\"_blank\">rbf_lr=0.5_01100_841095289</a></strong> to <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/torch/autograd/__init__.py:275: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n",
      "/home/mkallel/explo/src/optimizers/gibo.py:385: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2318.)\n",
      "  a1 = mlp(kernel_states,theta_1).flatten(start_dim=-2).squeeze().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 18\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 36\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 54\n",
      "0.125\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 54\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 72\n",
      "0.125\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 72\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 54\n",
      "0.125\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 72\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 90\n",
      "0.125\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 72\n",
      "0.875\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 72\n",
      "0.625\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 108\n",
      "0.125\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 90\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 90\n",
      "0.25\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 90\n",
      "0.75\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 108\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 108\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 90\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 108\n",
      "0.5\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 108\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 108\n",
      "0.5\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 126\n",
      "1.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 108\n",
      "0.125\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 108\n",
      "0.875\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 126\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 108\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 126\n",
      "0.1875\n",
      "0.0\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 126\n",
      "0.625\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 108\n",
      "0.5\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 126\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 138\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 126\n",
      "0.0\n",
      "0.0\n",
      "0.8125\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 126\n",
      "0.25\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 126\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 150\n",
      "0.5625\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 144\n",
      "0.0\n",
      "0.75\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 144\n",
      "0.0\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 144\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 162\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 126\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 144\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 144\n",
      "0.8125\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 144\n",
      "0.6875\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 162\n",
      "0.6875\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 144\n",
      "0.625\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 126\n",
      "0.5625\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 162\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 162\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 180\n",
      "0.5\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 162\n",
      "0.5625\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 144\n",
      "0.3125\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 162\n",
      "0.5\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 162\n",
      "0.375\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 180\n",
      "0.625\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 162\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 180\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 180\n",
      "0.5\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 144\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 180\n",
      "0.75\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 162\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 180\n",
      "0.125\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 180\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 198\n",
      "0.75\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 180\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 216\n",
      "0.6875\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 180\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 198\n",
      "0.125\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 162\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 198\n",
      "0.3125\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 216\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 216\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 198\n",
      "0.25\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 198\n",
      "0.5625\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 234\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 198\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 216\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 216\n",
      "0.3125\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 180\n",
      "0.25\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 216\n",
      "0.375\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 234rbf_lr=0.5_01100_199900595 : n_samples : 252\n",
      "\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 216\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 216\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 198\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 252\n",
      "0.25\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 234\n",
      "0.125\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 234\n",
      "0.75\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 270\n",
      "0.375\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 234\n",
      "0.3125\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 234\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 216\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 288\n",
      "0.5625\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 270\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 252\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 234\n",
      "0.6875\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 306\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 270\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 252\n",
      "0.375\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 288\n",
      "0.4375\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 288\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 270\n",
      "0.5\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 306\n",
      "0.3125\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 306\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 288\n",
      "0.25\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 360\n",
      "0.5625\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 324\n",
      "0.25\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 342\n",
      "0.0\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 360rbf_lr=0.5_01100_415968276 : n_samples : 324\n",
      "\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 342\n",
      "0.3125\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 306\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 342\n",
      "0.1875\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 324\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 360\n",
      "0.5\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 342\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 378\n",
      "0.625\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 360\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 396\n",
      "0.0\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 432\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 378\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 396\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 432\n",
      "0.0625\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 414\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 432\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 450\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 468\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 486\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 504\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 522\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_199900595 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 540\n",
      "0.0\n",
      "rbf_lr=0.5_01100_996406378 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 558\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 576\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.02843</td></tr><tr><td>R1</td><td>-0.09342</td></tr><tr><td>R2</td><td>-0.61626</td></tr><tr><td>acq_value (after finish)</td><td>0.72383</td></tr><tr><td>action_distance_grad</td><td>0.23259</td></tr><tr><td>action_distance_to_local</td><td>0.44935</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07189</td></tr><tr><td>max_grad(before hessian)</td><td>0.08535</td></tr><tr><td>max_return</td><td>1.02165</td></tr><tr><td>max_std/mean</td><td>42.03719</td></tr><tr><td>mean_covar</td><td>-0.06153</td></tr><tr><td>mean_grad(before hessian)</td><td>0.03724</td></tr><tr><td>mean_std/mean</td><td>9.9742</td></tr><tr><td>median_covar</td><td>-0.06521</td></tr><tr><td>median_grad(before hessian)</td><td>0.03063</td></tr><tr><td>median_std/mean</td><td>8.02096</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03363</td></tr><tr><td>param_distance_to_local</td><td>0.05624</td></tr><tr><td>policy_return</td><td>1.00064</td></tr><tr><td>policy_return_at_grad</td><td>0.99994</td></tr><tr><td>var_reward</td><td>8e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_199900595</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/d51266qf\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/d51266qf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-d51266qf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 558\n",
      "0.0\n",
      "0.0\n",
      "rbf_lr=0.5_01100_534895718 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01100_670094950 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 576\n",
      "0.0\n",
      "rbf_lr=0.5_01100_787846414 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.0227</td></tr><tr><td>R1</td><td>-0.40121</td></tr><tr><td>R2</td><td>-1.18459</td></tr><tr><td>acq_value (after finish)</td><td>0.74348</td></tr><tr><td>action_distance_grad</td><td>0.17252</td></tr><tr><td>action_distance_to_local</td><td>0.28836</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>2e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07236</td></tr><tr><td>max_grad(before hessian)</td><td>0.0545</td></tr><tr><td>max_return</td><td>1.02295</td></tr><tr><td>max_std/mean</td><td>222.13512</td></tr><tr><td>mean_covar</td><td>-0.06031</td></tr><tr><td>mean_grad(before hessian)</td><td>0.02281</td></tr><tr><td>mean_std/mean</td><td>37.95172</td></tr><tr><td>median_covar</td><td>-0.06375</td></tr><tr><td>median_grad(before hessian)</td><td>0.02384</td></tr><tr><td>median_std/mean</td><td>10.13593</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03253</td></tr><tr><td>param_distance_to_local</td><td>0.05612</td></tr><tr><td>policy_return</td><td>0.98326</td></tr><tr><td>policy_return_at_grad</td><td>1.01326</td></tr><tr><td>var_reward</td><td>6e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_996406378</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1snw0hq7\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1snw0hq7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-1snw0hq7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_841095289 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01100_127521863 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01100_862061404 : n_samples : 594\n",
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 576\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_415968276 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.01906</td></tr><tr><td>R1</td><td>-0.17723</td></tr><tr><td>R2</td><td>-0.7805</td></tr><tr><td>acq_value (after finish)</td><td>0.73308</td></tr><tr><td>action_distance_grad</td><td>0.10966</td></tr><tr><td>action_distance_to_local</td><td>0.31021</td></tr><tr><td>covar_lengthscale mean</td><td>0.29998</td></tr><tr><td>covar_lengthscale std</td><td>2e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07279</td></tr><tr><td>max_grad(before hessian)</td><td>0.0497</td></tr><tr><td>max_return</td><td>1.0296</td></tr><tr><td>max_std/mean</td><td>336.28387</td></tr><tr><td>mean_covar</td><td>-0.06134</td></tr><tr><td>mean_grad(before hessian)</td><td>0.01901</td></tr><tr><td>mean_std/mean</td><td>49.04058</td></tr><tr><td>median_covar</td><td>-0.06495</td></tr><tr><td>median_grad(before hessian)</td><td>0.01577</td></tr><tr><td>median_std/mean</td><td>13.89091</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.02937</td></tr><tr><td>param_distance_to_local</td><td>0.04839</td></tr><tr><td>policy_return</td><td>1.01009</td></tr><tr><td>policy_return_at_grad</td><td>1.00972</td></tr><tr><td>var_reward</td><td>9e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_670094950</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2cqbzyby\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/2cqbzyby</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-2cqbzyby/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.01806</td></tr><tr><td>R1</td><td>-0.005</td></tr><tr><td>R2</td><td>-0.1903</td></tr><tr><td>acq_value (after finish)</td><td>0.71819</td></tr><tr><td>action_distance_grad</td><td>0.30322</td></tr><tr><td>action_distance_to_local</td><td>0.31873</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>2e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07057</td></tr><tr><td>max_grad(before hessian)</td><td>0.0524</td></tr><tr><td>max_return</td><td>1.02744</td></tr><tr><td>max_std/mean</td><td>88.28942</td></tr><tr><td>mean_covar</td><td>-0.06177</td></tr><tr><td>mean_grad(before hessian)</td><td>0.02327</td></tr><tr><td>mean_std/mean</td><td>18.52648</td></tr><tr><td>median_covar</td><td>-0.06549</td></tr><tr><td>median_grad(before hessian)</td><td>0.02087</td></tr><tr><td>median_std/mean</td><td>11.00053</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03257</td></tr><tr><td>param_distance_to_local</td><td>0.06133</td></tr><tr><td>policy_return</td><td>0.96433</td></tr><tr><td>policy_return_at_grad</td><td>0.99875</td></tr><tr><td>var_reward</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_534895718</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/22bgg9kw\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/22bgg9kw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-22bgg9kw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.01811</td></tr><tr><td>R1</td><td>-0.24477</td></tr><tr><td>R2</td><td>-0.62119</td></tr><tr><td>acq_value (after finish)</td><td>0.73642</td></tr><tr><td>action_distance_grad</td><td>0.20095</td></tr><tr><td>action_distance_to_local</td><td>0.3333</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>3e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07098</td></tr><tr><td>max_grad(before hessian)</td><td>0.05901</td></tr><tr><td>max_return</td><td>1.02056</td></tr><tr><td>max_std/mean</td><td>290.37244</td></tr><tr><td>mean_covar</td><td>-0.06103</td></tr><tr><td>mean_grad(before hessian)</td><td>0.02378</td></tr><tr><td>mean_std/mean</td><td>56.55844</td></tr><tr><td>median_covar</td><td>-0.06512</td></tr><tr><td>median_grad(before hessian)</td><td>0.01896</td></tr><tr><td>median_std/mean</td><td>10.33024</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03002</td></tr><tr><td>param_distance_to_local</td><td>0.05585</td></tr><tr><td>policy_return</td><td>1.01505</td></tr><tr><td>policy_return_at_grad</td><td>1.00503</td></tr><tr><td>var_reward</td><td>2e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_787846414</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/23ev0609\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/23ev0609</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-23ev0609/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.04887</td></tr><tr><td>R1</td><td>0.01851</td></tr><tr><td>R2</td><td>-0.10788</td></tr><tr><td>acq_value (after finish)</td><td>0.69341</td></tr><tr><td>action_distance_grad</td><td>0.24828</td></tr><tr><td>action_distance_to_local</td><td>0.16985</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07603</td></tr><tr><td>max_grad(before hessian)</td><td>0.12138</td></tr><tr><td>max_return</td><td>1.02859</td></tr><tr><td>max_std/mean</td><td>79.49136</td></tr><tr><td>mean_covar</td><td>-0.0635</td></tr><tr><td>mean_grad(before hessian)</td><td>0.05161</td></tr><tr><td>mean_std/mean</td><td>17.84591</td></tr><tr><td>median_covar</td><td>-0.06752</td></tr><tr><td>median_grad(before hessian)</td><td>0.0432</td></tr><tr><td>median_std/mean</td><td>5.02476</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03059</td></tr><tr><td>param_distance_to_local</td><td>0.06245</td></tr><tr><td>policy_return</td><td>0.92525</td></tr><tr><td>policy_return_at_grad</td><td>0.96156</td></tr><tr><td>var_reward</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_841095289</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/39slc1bv\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/39slc1bv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-39slc1bv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.05079</td></tr><tr><td>R1</td><td>-0.57728</td></tr><tr><td>R2</td><td>-1.38176</td></tr><tr><td>acq_value (after finish)</td><td>0.73246</td></tr><tr><td>action_distance_grad</td><td>0.19183</td></tr><tr><td>action_distance_to_local</td><td>0.28856</td></tr><tr><td>covar_lengthscale mean</td><td>0.29998</td></tr><tr><td>covar_lengthscale std</td><td>5e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07046</td></tr><tr><td>max_grad(before hessian)</td><td>0.13318</td></tr><tr><td>max_return</td><td>1.02129</td></tr><tr><td>max_std/mean</td><td>264.41809</td></tr><tr><td>mean_covar</td><td>-0.06135</td></tr><tr><td>mean_grad(before hessian)</td><td>0.05546</td></tr><tr><td>mean_std/mean</td><td>21.71824</td></tr><tr><td>median_covar</td><td>-0.06593</td></tr><tr><td>median_grad(before hessian)</td><td>0.05305</td></tr><tr><td>median_std/mean</td><td>4.50286</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03288</td></tr><tr><td>param_distance_to_local</td><td>0.04932</td></tr><tr><td>policy_return</td><td>1.01447</td></tr><tr><td>policy_return_at_grad</td><td>1.01022</td></tr><tr><td>var_reward</td><td>9e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_127521863</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/9xve09uu\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/9xve09uu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-9xve09uu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "rbf_lr=0.5_01100_423734972 : n_samples : 594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.0477</td></tr><tr><td>R1</td><td>0.05031</td></tr><tr><td>R2</td><td>-0.02403</td></tr><tr><td>acq_value (after finish)</td><td>0.67492</td></tr><tr><td>action_distance_grad</td><td>0.16376</td></tr><tr><td>action_distance_to_local</td><td>0.27797</td></tr><tr><td>covar_lengthscale mean</td><td>0.29999</td></tr><tr><td>covar_lengthscale std</td><td>1e-05</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.07799</td></tr><tr><td>max_grad(before hessian)</td><td>0.22903</td></tr><tr><td>max_return</td><td>1.02625</td></tr><tr><td>max_std/mean</td><td>165.48886</td></tr><tr><td>mean_covar</td><td>-0.06467</td></tr><tr><td>mean_grad(before hessian)</td><td>0.0738</td></tr><tr><td>mean_std/mean</td><td>20.21396</td></tr><tr><td>median_covar</td><td>-0.06853</td></tr><tr><td>median_grad(before hessian)</td><td>0.02861</td></tr><tr><td>median_std/mean</td><td>5.34797</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.02684</td></tr><tr><td>param_distance_to_local</td><td>0.05498</td></tr><tr><td>policy_return</td><td>0.85936</td></tr><tr><td>policy_return_at_grad</td><td>0.95228</td></tr><tr><td>var_reward</td><td>0.00018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_862061404</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/5s9icjuo\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/5s9icjuo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-5s9icjuo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.04328</td></tr><tr><td>R1</td><td>-0.39117</td></tr><tr><td>R2</td><td>-0.97649</td></tr><tr><td>acq_value (after finish)</td><td>0.75868</td></tr><tr><td>action_distance_grad</td><td>0.20999</td></tr><tr><td>action_distance_to_local</td><td>0.24744</td></tr><tr><td>covar_lengthscale mean</td><td>0.3</td></tr><tr><td>covar_lengthscale std</td><td>0.0</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.06907</td></tr><tr><td>max_grad(before hessian)</td><td>0.0978</td></tr><tr><td>max_return</td><td>1.02502</td></tr><tr><td>max_std/mean</td><td>11.22691</td></tr><tr><td>mean_covar</td><td>-0.05976</td></tr><tr><td>mean_grad(before hessian)</td><td>0.05024</td></tr><tr><td>mean_std/mean</td><td>5.90312</td></tr><tr><td>median_covar</td><td>-0.06403</td></tr><tr><td>median_grad(before hessian)</td><td>0.04322</td></tr><tr><td>median_std/mean</td><td>5.44323</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03458</td></tr><tr><td>param_distance_to_local</td><td>0.05219</td></tr><tr><td>policy_return</td><td>0.94936</td></tr><tr><td>policy_return_at_grad</td><td>1.00359</td></tr><tr><td>var_reward</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_415968276</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/3nwk8ilc\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/3nwk8ilc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-3nwk8ilc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td></td></tr><tr><td>R1</td><td></td></tr><tr><td>R2</td><td></td></tr><tr><td>acq_value (after finish)</td><td></td></tr><tr><td>action_distance_grad</td><td></td></tr><tr><td>action_distance_to_local</td><td></td></tr><tr><td>covar_lengthscale mean</td><td></td></tr><tr><td>covar_lengthscale std</td><td></td></tr><tr><td>covar_output_scale</td><td></td></tr><tr><td>episode_length</td><td></td></tr><tr><td>fraction_sparse</td><td></td></tr><tr><td>max_covar</td><td></td></tr><tr><td>max_covar(before hessian)</td><td></td></tr><tr><td>max_grad(before hessian)</td><td></td></tr><tr><td>max_return</td><td></td></tr><tr><td>max_std/mean</td><td></td></tr><tr><td>mean_covar</td><td></td></tr><tr><td>mean_grad(before hessian)</td><td></td></tr><tr><td>mean_std/mean</td><td></td></tr><tr><td>median_covar</td><td></td></tr><tr><td>median_grad(before hessian)</td><td></td></tr><tr><td>median_std/mean</td><td></td></tr><tr><td>n_info_points</td><td></td></tr><tr><td>n_samples</td><td></td></tr><tr><td>noise</td><td></td></tr><tr><td>param_distance_grad</td><td></td></tr><tr><td>param_distance_to_local</td><td></td></tr><tr><td>policy_return</td><td></td></tr><tr><td>policy_return_at_grad</td><td></td></tr><tr><td>var_reward</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.02277</td></tr><tr><td>R1</td><td>-0.48577</td></tr><tr><td>R2</td><td>-1.3321</td></tr><tr><td>acq_value (after finish)</td><td>0.74658</td></tr><tr><td>action_distance_grad</td><td>0.13799</td></tr><tr><td>action_distance_to_local</td><td>0.09405</td></tr><tr><td>covar_lengthscale mean</td><td>0.3</td></tr><tr><td>covar_lengthscale std</td><td>0.0</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>episode_length</td><td>1000</td></tr><tr><td>fraction_sparse</td><td>0.0</td></tr><tr><td>max_covar</td><td>0.0</td></tr><tr><td>max_covar(before hessian)</td><td>0.06837</td></tr><tr><td>max_grad(before hessian)</td><td>0.04312</td></tr><tr><td>max_return</td><td>1.02318</td></tr><tr><td>max_std/mean</td><td>178.30038</td></tr><tr><td>mean_covar</td><td>-0.06039</td></tr><tr><td>mean_grad(before hessian)</td><td>0.02058</td></tr><tr><td>mean_std/mean</td><td>35.51886</td></tr><tr><td>median_covar</td><td>-0.06405</td></tr><tr><td>median_grad(before hessian)</td><td>0.02021</td></tr><tr><td>median_std/mean</td><td>11.89168</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>612</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_grad</td><td>0.03211</td></tr><tr><td>param_distance_to_local</td><td>0.05515</td></tr><tr><td>policy_return</td><td>1.00756</td></tr><tr><td>policy_return_at_grad</td><td>1.012</td></tr><tr><td>var_reward</td><td>1e-05</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rbf_lr=0.5_01100_423734972</strong>: <a href=\"https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1xpmqhf7\" target=\"_blank\">https://wandb.ai/mahdikallel/Swimmer-v4RBF%20%2B%20Confidence%20Grad/runs/1xpmqhf7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_222050-1xpmqhf7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%cd /home/mkallel/explo/\n",
    "\n",
    "import logging\n",
    "import logging.config\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from warnings import simplefilter\n",
    "\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "import threading\n",
    "import wandb\n",
    "from src.config import get_configs\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "import itertools\n",
    "\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n",
    "os.environ[\"WANDB_API_KEY\"]=\"28996bd59f1ba2c5a8c3f2cc23d8673c327ae230\"\n",
    "\n",
    "def run(seed,\n",
    "        env_name,\n",
    "        kernel_name,\n",
    "        manipulate_state,\n",
    "        norm_grad,\n",
    "        conf_grad,\n",
    "        advantage_mean,\n",
    "        adaptive_lr,\n",
    "        lr ):\n",
    "\n",
    "        #env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "        #env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "        #env_name = \"Hopper-v2\"\n",
    "        #env_name = \"HalfCheetah-v2\"        \n",
    "        #env_name = \"Walker2d-v3\"\n",
    "\n",
    "        #kernel_name = \"rbfstate\" ## \"rbf\"\n",
    "        #kernel_name = \"rbf\" ## \"rbf\"\n",
    "\n",
    "        project_name = env_name+(\"RBF + Confidence Grad\")\n",
    "        run_name =  kernel_name +\"_lr=\"+str(lr) +\"_\"+str(1 *manipulate_state)+ str(1 *norm_grad) + str(1 *conf_grad) + str(1 *advantage_mean)+str(1 *adaptive_lr) +\"_\"+ str(seed)\n",
    "        env_config,policy_config,likelihood_config,kernel_config,mean_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name,\n",
    "        use_ard=True,manipulate_state=manipulate_state,\n",
    "        conf_grad=conf_grad,norm_grad=norm_grad,advantage_mean=advantage_mean,adaptive_lr=adaptive_lr,lr=lr,\n",
    "        wandb_logger=True,project_name=project_name,run_name=run_name)\n",
    "\n",
    "        model,objective_env,optimizer = setup_experiment(env_config,mean_config,kernel_config,likelihood_config,policy_config,optimizer_config,\n",
    "                                        seed=seed)\n",
    "\n",
    "        trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "        trainer.run()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "        \n",
    "        wandb.require(\"service\")\n",
    "        wandb.setup()  \n",
    "\n",
    "        env_name = [\"Swimmer-v4\"]\n",
    "        #env_name = [\"CartPole-v1\"]\n",
    "        kernel_name = [\"rbf\"]\n",
    "        manipulate_state = [False]\n",
    "        conf_grad = [True] ##run this for rbf\n",
    "        norm_grad = [True]\n",
    "        advantage_mean = [True]\n",
    "        adaptive_lr = [False]\n",
    "        lr = [0.5]\n",
    "        \n",
    "        n= 10\n",
    "        np.random.seed(42)\n",
    "        seeds = np.random.randint(low=0,high=2**30,size=(n,))\n",
    "\n",
    "        for config in itertools.product(*[env_name,kernel_name,manipulate_state,norm_grad,conf_grad,advantage_mean,adaptive_lr,lr]):\n",
    "\n",
    "            \n",
    "                seeds = [ int(i) for i in seeds]\n",
    "\n",
    "                with Pool(processes=n) as p:\n",
    "                        args = [(seed,*config) for seed in seeds]\n",
    "                        p.starmap(run, args)\n",
    "\n",
    "                #run(*(0,*config))\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('bopt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c7e76b21fbf8268359659a13a1687ca07cc6ddf0d10c2b26cf47d2a8edd420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
