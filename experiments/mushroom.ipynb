{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkallel/explo\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'formatters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mkallel/explo/experiments/mushroom.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/mushroom.ipynb#ch0000001vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmushroom_rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolicy\u001b[39;00m \u001b[39mimport\u001b[39;00m DeterministicPolicy\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/mushroom.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddpg\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPG\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/mushroom.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m setup_experiment\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/mushroom.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m get_configs\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/mushroom.ipynb#ch0000001vscode-remote?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/explo/src/helpers.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmushroom_rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreplay_memory\u001b[39;00m \u001b[39mimport\u001b[39;00m ReplayMemory\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmushroom_rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspaces\u001b[39;00m \u001b[39mimport\u001b[39;00m Box, Discrete\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapproximators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mactor\u001b[39;00m \u001b[39mimport\u001b[39;00m MLP, ActorNetwork\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapproximators\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcritic\u001b[39;00m \u001b[39mimport\u001b[39;00m CriticNetwork\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mddpg\u001b[39;00m \u001b[39mimport\u001b[39;00m DDPG\n",
      "File \u001b[0;32m~/explo/src/approximators/actor.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mimport\u001b[39;00m path\n\u001b[1;32m      7\u001b[0m log_file_path \u001b[39m=\u001b[39m path\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39m/home/q123/Desktop/explo/logging.conf\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m logging\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mfileConfig(log_file_path)\n\u001b[1;32m      9\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m\"\u001b[39m\u001b[39mShapeLog.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m OrderedDict\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/logging/config.py:72\u001b[0m, in \u001b[0;36mfileConfig\u001b[0;34m(fname, defaults, disable_existing_loggers, encoding)\u001b[0m\n\u001b[1;32m     69\u001b[0m         encoding \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mtext_encoding(encoding)\n\u001b[1;32m     70\u001b[0m         cp\u001b[39m.\u001b[39mread(fname, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[0;32m---> 72\u001b[0m formatters \u001b[39m=\u001b[39m _create_formatters(cp)\n\u001b[1;32m     74\u001b[0m \u001b[39m# critical section\u001b[39;00m\n\u001b[1;32m     75\u001b[0m logging\u001b[39m.\u001b[39m_acquireLock()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/logging/config.py:105\u001b[0m, in \u001b[0;36m_create_formatters\u001b[0;34m(cp)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_formatters\u001b[39m(cp):\n\u001b[1;32m    104\u001b[0m     \u001b[39m\"\"\"Create and return formatters\"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m     flist \u001b[39m=\u001b[39m cp[\u001b[39m\"\u001b[39;49m\u001b[39mformatters\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(flist):\n\u001b[1;32m    107\u001b[0m         \u001b[39mreturn\u001b[39;00m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/configparser.py:964\u001b[0m, in \u001b[0;36mRawConfigParser.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    963\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_section \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_section(key):\n\u001b[0;32m--> 964\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proxies[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'formatters'"
     ]
    }
   ],
   "source": [
    "%cd /home/mkallel/explo/\n",
    "\n",
    "from mushroom_rl.environments.dm_control_env import DMControl\n",
    "from mushroom_rl.policy import DeterministicPolicy\n",
    "from src.ddpg import DDPG\n",
    "from src.helpers import setup_experiment\n",
    "from src.config import get_configs\n",
    "import torch\n",
    "from src.approximators.actor import ActorNetwork\n",
    "from src.approximators.critic import CriticNetwork\n",
    "\n",
    "\n",
    "# MDP\n",
    "horizon = 500\n",
    "gamma = 0.99\n",
    "gamma_eval = 1.\n",
    "#mdp = DMControl('walker', 'stand', horizon, gamma)\n",
    "\n",
    "\n",
    "# Settings\n",
    "initial_replay_size = 500\n",
    "max_replay_size = 10000\n",
    "batch_size = 200\n",
    "n_features = 80\n",
    "tau = .001\n",
    "\n",
    "\n",
    "# from os import path\n",
    "# import logging\n",
    "# #log_file_path = path.join()\n",
    "# logging.config.fileConfig(\"/home/mkallel/explo/logging.conf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mkallel/explo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dm_control\n",
      "  Downloading dm_control-1.0.4.tar.gz (38.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (1.8.1)\n",
      "Collecting dm-tree!=0.1.2\n",
      "  Downloading dm_tree-0.1.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<3.0.0\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.1 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (3.20.1)\n",
      "Requirement already satisfied: pyopengl>=3.1.4 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (3.1.6)\n",
      "Collecting dm-env\n",
      "  Downloading dm_env-1.5-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (1.2.0)\n",
      "Requirement already satisfied: glfw in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (1.22.4)\n",
      "Requirement already satisfied: requests in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (4.64.0)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools!=50.0.0 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from dm_control) (61.2.0)\n",
      "Collecting labmaze\n",
      "  Downloading labmaze-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mujoco>=2.2.1\n",
      "  Using cached mujoco-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->dm_control) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->dm_control) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->dm_control) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mkallel/miniconda3/envs/myenv/lib/python3.10/site-packages (from requests->dm_control) (3.3)\n",
      "Building wheels for collected packages: dm_control\n",
      "  Building wheel for dm_control (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dm_control: filename=dm_control-1.0.4-py3-none-any.whl size=38550813 sha256=f6d6c5750f4c7302a2e3e735be5783d8ab740e0263c307939c478840ddd79927\n",
      "  Stored in directory: /home/mkallel/.cache/pip/wheels/ec/ce/ae/797859ab9476bfa259701f141a2b46d4fad2b84ef7acb38284\n",
      "Successfully built dm_control\n",
      "Installing collected packages: dm-tree, pyparsing, mujoco, lxml, labmaze, dm-env, dm_control\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: mujoco\n",
      "    Found existing installation: mujoco 2.2.0\n",
      "    Uninstalling mujoco-2.2.0:\n",
      "      Successfully uninstalled mujoco-2.2.0\n",
      "Successfully installed dm-env-1.5 dm-tree-0.1.7 dm_control-1.0.4 labmaze-1.0.5 lxml-4.9.1 mujoco-2.2.1 pyparsing-2.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dm_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_critic(agent,transitions,n_epochs=2):\n",
    "    \n",
    "    agent._replay_memory.add(transitions)\n",
    "\n",
    "    state, action, reward, next_state, absorbing, _ =\\\n",
    "        agent._replay_memory.get(agent._batch_size())\n",
    "\n",
    "    q_next = agent._next_q(next_state, absorbing)\n",
    "    q_target = reward + agent.mdp_info.gamma * q_next\n",
    "\n",
    "    agent._critic_approximator.fit(state, action, q_target,n_epochs=n_epochs,\n",
    "                                    **agent._critic_fit_params)\n",
    "    \n",
    "    agent._update_target(agent._critic_approximator,\n",
    "                        agent._target_critic_approximator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo/src\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/mushroom.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=6'>7</a>\u001b[0m kernel_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=10'>11</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=11'>12</a>\u001b[0m     \u001b[39m## Setup environment\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=12'>13</a>\u001b[0m     env_config,likelihood_config,kernel_config,optimizer_config,trainer_config \u001b[39m=\u001b[39m get_configs(env_name,kernel_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=13'>14</a>\u001b[0m     env_config[\u001b[39m\"\u001b[39m\u001b[39mmanipulate_state\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=15'>16</a>\u001b[0m     policy_config \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=16'>17</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39madd_layer\u001b[39m\u001b[39m\"\u001b[39m:[],\u001b[39m### can be empty or [8,7] for adding 2 layers with width 8,7  neurons respectively\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=17'>18</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39madd_bias\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/mushroom.ipynb#ch0000003?line=18'>19</a>\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo/src\n",
    "\n",
    "from src.optimizers.esq_pytorch import ESQOptimizer\n",
    "\n",
    "\n",
    "env_name = \"Swimmer-v4\"\n",
    "kernel_name = \"rbf\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## Setup environment\n",
    "    env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "    env_config[\"manipulate_state\"] = True\n",
    "    \n",
    "    policy_config = {\n",
    "                \"add_layer\":[],### can be empty or [8,7] for adding 2 layers with width 8,7  neurons respectively\n",
    "                \"add_bias\":False,\n",
    "    }\n",
    "    _,env = setup_experiment(env_config,kernel_config,likelihood_config,policy_config)\n",
    "\n",
    "\n",
    "    # Setup DDPG\n",
    "    mdp = env.env\n",
    "\n",
    "    policy_class = DeterministicPolicy\n",
    "    policy_params = dict()\n",
    "\n",
    "    actor_input_shape = mdp.info.observation_space.shape\n",
    "    actor_params = dict(network=ActorNetwork,\n",
    "                        n_features=n_features,\n",
    "                        input_shape=actor_input_shape,\n",
    "                        output_shape=mdp.info.action_space.shape)\n",
    "\n",
    "    actor_optimizer = {'class': torch.optim.Adam,\n",
    "                    'params': {'lr': 1e-4}}\n",
    "\n",
    "    critic_input_shape = (actor_input_shape[0] + mdp.info.action_space.shape[0],)\n",
    "    \n",
    "    critic_params = dict(network=CriticNetwork,\n",
    "                        optimizer={'class': torch.optim.Adam,\n",
    "                                    'params': {'lr': 1e-3}},\n",
    "                        loss=F.mse_loss,\n",
    "                        n_features=n_features,\n",
    "                        input_shape=critic_input_shape,\n",
    "                        output_shape=(1,))\n",
    "\n",
    "    agent = DDPG(mdp.info, policy_class,policy_params,\n",
    "                actor_params, actor_optimizer, \n",
    "                critic_params,\n",
    "                batch_size, initial_replay_size, max_replay_size,\n",
    "                tau)\n",
    "\n",
    "    # esq_optimizer = ESQOptimizer(\n",
    "    #                         critic=agent._critic_approximator.model.network,\n",
    "    #                         actor = agent._actor_approximator.model.network,\n",
    "    #                         sigma=1e-1,\n",
    "    #                         params_per_step=40,\n",
    "    #                         n_workers=8)\n",
    " \n",
    "    # for i in range(100):\n",
    "        \n",
    "    #     avg_reward,states,transitions = env.run_many(agent._actor_approximator,5)\n",
    "    #     print(\"avg_reward\",avg_reward)  \n",
    "            \n",
    "    #     fit_critic(agent,transitions)\n",
    "        \n",
    "    #     states_batch,_,_,_,_,_ = agent._replay_memory.get(agent._batch_size())\n",
    "        \n",
    "    #     print(\"done training critic\")\n",
    "    #     grads = esq_optimizer.step(torch.tensor(states_batch)) ## fit critic\n",
    "    #     #grads = esq_optimizer.step(states) ## fit critic\n",
    "        \n",
    "    #     #print(agent._critic_approximator.model.network.parameters())\n",
    "        \n",
    "    # #     #print(optimizer.actor.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdp.info.action_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mushroom_rl.approximators import Regressor\n",
    "# from mushroom_rl.approximators.parametric import TorchApproximator\n",
    "# from mushroom_rl.utils.replay_memory import ReplayMemory\n",
    "\n",
    "# replay_memory = ReplayMemory(initial_replay_size, max_replay_size)\n",
    "# critic_approximator = Regressor(TorchApproximator,\n",
    "#                                               **critic_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
