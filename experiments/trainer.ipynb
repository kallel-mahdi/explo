{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:69: UserWarning: \u001b[33mWARN: Agent's minimum action space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:73: UserWarning: \u001b[33mWARN: Agent's maximum action space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ard_num_dims = 18\n",
      " Gibo will use 50 last points to fit GP and 16 info samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current 0.07676661759614944 / max 0.21548153460025787 /batch_mean 0.032693587243556976 /batch_max 0.08514556288719177 \n",
      "##############################\n",
      "covar_lengthscale max 77.4983901977539 / min 77.4983901977539                      covar_outputscale 1.0                     noise 0.014999999664723873\n",
      "##############################\n",
      "last parameters tensor([-0.1664,  0.0738,  0.0974, -0.0447,  0.1089, -0.1000,  0.1039, -0.0011,\n",
      "        -0.0070,  0.0725, -0.0243, -0.0255,  0.0815, -0.0634,  0.0096, -0.0182,\n",
      "        -0.1850, -0.1361])\n",
      "MLL : 1.020346760749817\n",
      "grad_mean : max 0.10036879777908325 /  min -0.06237058341503143\n",
      "grad_covar : max 2.2576355934143066 /  min 9.999999717180685e-10\n",
      "current 0.07905768603086472 / max 0.21548153460025787 /batch_mean 0.05467354506254196 /batch_max 0.07905768603086472 \n",
      "##############################\n",
      "covar_lengthscale max 77.4983901977539 / min 77.4983901977539                      covar_outputscale 1.0                     noise 0.014999999664723873\n",
      "##############################\n",
      "last parameters tensor([-0.1883,  0.0071,  0.0410,  0.0411,  0.1094,  0.0416,  0.0591, -0.0306,\n",
      "         0.0464,  0.0034, -0.0130, -0.0462, -0.0863, -0.0154,  0.0541,  0.0290,\n",
      "        -0.1138, -0.0586])\n",
      "MLL : 1.0700812339782715\n",
      "grad_mean : max 0.08451545238494873 /  min -0.042220380157232285\n",
      "grad_covar : max 2.4387800693511963 /  min 9.999999717180685e-10\n",
      "current -0.05990821123123169 / max 0.21548153460025787 /batch_mean 0.03083975613117218 /batch_max 0.07700668275356293 \n",
      "##############################\n",
      "covar_lengthscale max 7218.9501953125 / min 7218.9501953125                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "last parameters tensor([-0.0365,  0.0089,  0.0951, -0.0425, -0.0054, -0.1040,  0.0506, -0.0213,\n",
      "        -0.1354,  0.1555,  0.1226, -0.0559, -0.0801, -0.0443,  0.0764,  0.0177,\n",
      "        -0.0390, -0.1377])\n",
      "MLL : 1.270139455795288\n",
      "grad_mean : max 2.6014404284069315e-05 /  min -3.956650834879838e-05\n",
      "grad_covar : max 1.0056212529363506e-09 /  min 9.999999717180685e-10\n",
      "current -0.056817203760147095 / max 0.21548153460025787 /batch_mean 0.056940335780382156 /batch_max 0.144509956240654 \n",
      "##############################\n",
      "covar_lengthscale max 1659.8592529296875 / min 1659.8592529296875                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "last parameters tensor([-0.1946,  0.1392,  0.0293, -0.0564,  0.1134, -0.0990,  0.0094, -0.0413,\n",
      "         0.0528, -0.0260,  0.0460, -0.0300,  0.0369, -0.0229,  0.0846,  0.1084,\n",
      "        -0.1511, -0.0194])\n",
      "MLL : 1.2649850845336914\n",
      "grad_mean : max 0.00033181862090714276 /  min -0.0005643973127007484\n",
      "grad_covar : max 3.1518320042778214e-07 /  min 9.999999717180685e-10\n",
      "current -0.007548917550593615 / max 0.21548153460025787 /batch_mean 0.030448701232671738 /batch_max 0.07619161158800125 \n",
      "##############################\n",
      "covar_lengthscale max 2026.8961181640625 / min 2026.8961181640625                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "last parameters tensor([-0.1221,  0.1373,  0.0287, -0.0321,  0.1471, -0.0673,  0.0261, -0.1183,\n",
      "         0.0500, -0.0249, -0.0651,  0.0712, -0.0539, -0.0309, -0.0217, -0.0733,\n",
      "        -0.1305, -0.0700])\n",
      "MLL : 1.25986909866333\n",
      "grad_mean : max 0.0004022682551294565 /  min -0.0007214484503492713\n",
      "grad_covar : max 1.8639694587818667e-07 /  min 9.999999717180685e-10\n",
      "current 0.19701768457889557 / max 0.21548153460025787 /batch_mean 0.06174180656671524 /batch_max 0.19701768457889557 \n",
      "##############################\n",
      "covar_lengthscale max 2584.970458984375 / min 2584.970458984375                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "last parameters tensor([-0.0144,  0.0015, -0.0215,  0.0447,  0.0487, -0.0601,  0.1305,  0.0656,\n",
      "        -0.0933,  0.1574,  0.0266, -0.0438,  0.0703, -0.1210,  0.0604,  0.0112,\n",
      "        -0.0141,  0.0073])\n",
      "MLL : 1.258176565170288\n",
      "grad_mean : max 0.0002439489762764424 /  min -0.0004356027056928724\n",
      "grad_covar : max 7.640260690777723e-08 /  min 9.999999717180685e-10\n",
      "current 0.09304874390363693 / max 0.21548153460025787 /batch_mean 0.07408011704683304 /batch_max 0.09452346712350845 \n",
      "##############################\n",
      "covar_lengthscale max 5616.99853515625 / min 5616.99853515625                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "last parameters tensor([-0.0297, -0.0158, -0.0068, -0.1139,  0.0111, -0.1247,  0.0209, -0.0856,\n",
      "         0.0369,  0.0513, -0.0603, -0.0047,  0.0744, -0.0977,  0.0759,  0.0563,\n",
      "        -0.1099,  0.0127])\n",
      "MLL : 1.2765861749649048\n",
      "grad_mean : max 2.1940066289971583e-05 /  min -3.789259790210053e-05\n",
      "grad_covar : max 2.7079587461287247e-09 /  min 9.999999717180685e-10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=45'>46</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GIBOptimizer(model,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=46'>47</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=47'>48</a>\u001b[0m rslt\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> 52\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m report_freq) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     56\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39my_hist\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:219\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo\u001b[39m.\u001b[39mupdate_theta_i(theta_i) \u001b[39m## this also update KxX_dx\u001b[39;00m\n\u001b[1;32m    218\u001b[0m bounds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta]]) \u001b[39m+\u001b[39m theta_i\n\u001b[0;32m--> 219\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_information(objective_env,model,bounds)\n\u001b[1;32m    221\u001b[0m \u001b[39m# # NEEEW : Adjust hyperparameters after information collection \u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m# # for better gradient estimate\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39m# if (model.N >= self.n_max): \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m \u001b[39m# Take one step in direction of the gradient\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_gradient_step(model, theta_i)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:149\u001b[0m, in \u001b[0;36mGIBOptimizer.optimize_information\u001b[0;34m(self, objective_env, model, bounds)\u001b[0m\n\u001b[1;32m    138\u001b[0m new_x, acq_value \u001b[39m=\u001b[39m botorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39moptimize_acqf(\n\u001b[1;32m    139\u001b[0m     acq_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo,\n\u001b[1;32m    140\u001b[0m     bounds\u001b[39m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m     return_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    146\u001b[0m     sequential\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    148\u001b[0m \u001b[39m# Update training points.\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m new_y,new_s \u001b[39m=\u001b[39m objective_env(new_x,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_eval)\n\u001b[1;32m    150\u001b[0m model\u001b[39m.\u001b[39mappend_train_data(new_x,new_y, strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39m## right now we do not add new_s for info\u001b[39;00m\n\u001b[1;32m    151\u001b[0m model\u001b[39m.\u001b[39mposterior(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta_i)  \u001b[39m## hotfix\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/explo/src/environment.py:77\u001b[0m, in \u001b[0;36mEnvironmentObjective.__call__\u001b[0;34m(self, params, n_episodes)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, params,n_episodes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) :\n\u001b[0;32m---> 77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_many(params,n_episodes)\n",
      "File \u001b[0;32m~/Desktop/explo/src/environment.py:138\u001b[0m, in \u001b[0;36mEnvironmentObjective.run_many\u001b[0;34m(self, params, n_episodes)\u001b[0m\n\u001b[1;32m    134\u001b[0m all_states \u001b[39m=\u001b[39m []\n\u001b[1;32m    136\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_episodes):\n\u001b[0;32m--> 138\u001b[0m    reward,states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(params)\n\u001b[1;32m    140\u001b[0m    rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m    141\u001b[0m    all_states\u001b[39m.\u001b[39mappend(states)\n",
      "File \u001b[0;32m~/Desktop/explo/src/environment.py:104\u001b[0m, in \u001b[0;36mEnvironmentObjective.run\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     99\u001b[0m states\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanipulate_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mreset()))\n\u001b[1;32m    101\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps):  \u001b[39m# rollout\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \n\u001b[1;32m    103\u001b[0m     \u001b[39m#### no need for grads here\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39;49mno_grad():\n\u001b[1;32m    106\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(params,states[t]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    108\u001b[0m     \u001b[39m###########################\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/autograd/grad_mode.py:122\u001b[0m, in \u001b[0;36mno_grad.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39;49m_jit_internal\u001b[39m.\u001b[39;49mis_scripting():\n\u001b[1;32m    123\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/_jit_internal.py:957\u001b[0m, in \u001b[0;36mis_scripting\u001b[0;34m()\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m):\n\u001b[1;32m    954\u001b[0m     \u001b[39mglobals\u001b[39m()[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBroadcastingList\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m BroadcastingList1\n\u001b[0;32m--> 957\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_scripting\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \u001b[39m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[1;32m    960\u001b[0m \u001b[39m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[39m              return unsupported_linear_op(x)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    976\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_name = \"Swimmer-v4\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "additional_layers=[] ### can be empty or [8,7] for adding 2 layers with width 8,7 respectively\n",
    "\n",
    "\n",
    "likelihood_config = {\n",
    "                \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.02),\n",
    "                \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.02)\n",
    "                }\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":3, ## 3 for cartpole (very noisy)\n",
    "        ### for GIBO\n",
    "        \"n_max\":50, \n",
    "        \"n_info_samples\":16,\n",
    "        \"delta\":0.1, ## 0.01 for cartpole\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\":True if kernel_name == \"rbf\" else False,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":False,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        # \"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(3.0,6.0),\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        # \"outputscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        }\n",
    "\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\":300, \n",
    "        \"report_freq\":10,\n",
    "        \"save_best\":False,\n",
    "}\n",
    "\n",
    "\n",
    "model,objective_env = setup_experiment(env_config,kernel_config,likelihood_config,additional_layers)\n",
    "\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
