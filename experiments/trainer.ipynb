{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [4, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ard_num_dims = 5\n",
      "Statekernel i have mlp MLP()\n",
      " Gibo will use 20 last points to fit GP and 8 info samples\n",
      "current 0.09200000017881393 / max 0.284000039100647 /batch_mean 0.11020000278949738 /batch_max 0.164000004529953 \n",
      "##############################\n",
      "covar_lengthscale max 7.971510410308838 / min 7.971510410308838                      covar_outputscale 3.3398217169633426e-07                     noise 0.20000067353248596\n",
      "##############################\n",
      "last parameters tensor([ 0.0168, -0.5591,  0.1512,  0.8810,  0.0425])\n",
      "MLL : -0.11691627651453018\n",
      "current 0.07400000840425491 / max 0.284000039100647 /batch_mean 0.1072000041604042 /batch_max 0.1940000206232071 \n",
      "##############################\n",
      "covar_lengthscale max 9.060495376586914 / min 9.060495376586914                      covar_outputscale 2.3877496460045222e-06                     noise 0.2000000774860382\n",
      "##############################\n",
      "last parameters tensor([-0.0149, -0.4880,  0.0107,  0.6922,  0.2350])\n",
      "MLL : -0.12173104286193848\n",
      "current 0.06000000610947609 / max 0.284000039100647 /batch_mean 0.08380000293254852 /batch_max 0.14800001680850983 \n",
      "##############################\n",
      "covar_lengthscale max 0.014289994724094868 / min 0.014289994724094868                      covar_outputscale 1.8417016462990432e-06                     noise 0.2000000774860382\n",
      "##############################\n",
      "last parameters tensor([-0.0847, -0.5205, -0.0022,  0.7604,  0.1435])\n",
      "MLL : -0.1194848045706749\n",
      "current 0.06000000610947609 / max 0.284000039100647 /batch_mean 0.07900000363588333 /batch_max 0.1300000101327896 \n",
      "##############################\n",
      "covar_lengthscale max 0.6925533413887024 / min 0.6925533413887024                      covar_outputscale 4.7370167521876283e-07                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([ 0.0183, -0.4818,  0.0045,  0.7586,  0.2369])\n",
      "MLL : -0.11930336803197861\n",
      "current 0.062000006437301636 / max 0.284000039100647 /batch_mean 0.11499999463558197 /batch_max 0.17600001394748688 \n",
      "##############################\n",
      "covar_lengthscale max 0.01511085033416748 / min 0.01511085033416748                      covar_outputscale 7.322588771785377e-06                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([-0.0402, -0.4894, -0.0030,  0.7788,  0.1352])\n",
      "MLL : -0.12090115249156952\n",
      "current 0.09200000017881393 / max 0.284000039100647 /batch_mean 0.1111999973654747 /batch_max 0.20799997448921204 \n",
      "##############################\n",
      "covar_lengthscale max 14.55260181427002 / min 14.55260181427002                      covar_outputscale 9.114922505659706e-08                     noise 0.20000004768371582\n",
      "##############################\n",
      "last parameters tensor([-1.3129e-01, -5.2878e-01, -1.2485e-04,  8.7920e-01,  4.2156e-02])\n",
      "MLL : -0.12253441661596298\n",
      "current 0.25200000405311584 / max 0.2900000214576721 /batch_mean 0.10819999873638153 /batch_max 0.25200000405311584 \n",
      "##############################\n",
      "covar_lengthscale max 0.20301944017410278 / min 0.20301944017410278                      covar_outputscale 8.423920007771812e-06                     noise 0.20000004768371582\n",
      "##############################\n",
      "last parameters tensor([ 0.0062, -0.4961, -0.0345,  0.8306,  0.1193])\n",
      "MLL : -0.11848344653844833\n",
      "current 0.10000000894069672 / max 0.32600003480911255 /batch_mean 0.09640000760555267 /batch_max 0.16600000858306885 \n",
      "##############################\n",
      "covar_lengthscale max 0.53148353099823 / min 0.53148353099823                      covar_outputscale 1.3093207940073626e-07                     noise 0.20000003278255463\n",
      "##############################\n",
      "last parameters tensor([-0.0892, -0.4385,  0.0454,  0.7469,  0.2247])\n",
      "MLL : -0.11819438636302948\n",
      "current 0.06000000610947609 / max 0.3499999940395355 /batch_mean 0.10380001366138458 /batch_max 0.2279999852180481 \n",
      "##############################\n",
      "covar_lengthscale max 1.3172149658203125 / min 1.3172149658203125                      covar_outputscale 3.845804030788713e-08                     noise 0.20000003278255463\n",
      "##############################\n",
      "last parameters tensor([ 0.0565, -0.5676, -0.0321,  0.7658,  0.2406])\n",
      "MLL : -0.1185276061296463\n",
      "current 0.07200000435113907 / max 0.3499999940395355 /batch_mean 0.09800000488758087 /batch_max 0.16200001537799835 \n",
      "##############################\n",
      "covar_lengthscale max 0.04481455683708191 / min 0.04481455683708191                      covar_outputscale 1.9507401702867355e-06                     noise 0.20000003278255463\n",
      "##############################\n",
      "last parameters tensor([ 0.0342, -0.4891, -0.0055,  0.7742,  0.1390])\n",
      "MLL : -0.12066688388586044\n",
      "current 0.06400000303983688 / max 0.3499999940395355 /batch_mean 0.10600000619888306 /batch_max 0.1900000125169754 \n",
      "##############################\n",
      "covar_lengthscale max 0.01244149636477232 / min 0.01244149636477232                      covar_outputscale 1.9252518086432246e-06                     noise 0.20000003278255463\n",
      "##############################\n",
      "last parameters tensor([-9.4009e-02, -5.1721e-01, -3.8717e-04,  8.4297e-01,  1.8888e-01])\n",
      "MLL : -0.11704321205615997\n",
      "current 0.06800000369548798 / max 0.3499999940395355 /batch_mean 0.0836000069975853 /batch_max 0.15200001001358032 \n",
      "##############################\n",
      "covar_lengthscale max 0.216572567820549 / min 0.216572567820549                      covar_outputscale 8.28755582915619e-06                     noise 0.20000001788139343\n",
      "##############################\n",
      "last parameters tensor([-0.0396, -0.4995, -0.0024,  0.7673,  0.1670])\n",
      "MLL : -0.11637906730175018\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=42'>43</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GIBOptimizer(model,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=43'>44</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=44'>45</a>\u001b[0m rslt\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:33\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> 33\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     35\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m report_freq) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     37\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39my_hist\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:193\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[39m# Adjust hyperparameters\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     mll \u001b[39m=\u001b[39m ExactMarginalLogLikelihood(model\u001b[39m.\u001b[39mlikelihood, model)\n\u001b[0;32m--> 193\u001b[0m     fit_gpytorch_model(mll)\n\u001b[1;32m    197\u001b[0m \u001b[39m# Sample locally to optimize gradient information\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo\u001b[39m.\u001b[39mupdate_theta_i(theta_i) \u001b[39m## this also update KxX_dx\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/fit.py:120\u001b[0m, in \u001b[0;36mfit_gpytorch_model\u001b[0;34m(mll, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39m# retry with random samples from the priors upon failure\u001b[39;00m\n\u001b[1;32m    119\u001b[0m mll\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m--> 120\u001b[0m original_state_dict \u001b[39m=\u001b[39m deepcopy(mll\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mstate_dict())\n\u001b[1;32m    121\u001b[0m retry \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[39mwhile\u001b[39;00m retry \u001b[39m<\u001b[39m max_retries:\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39;49mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/copy.py:297\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m dictiter:\n\u001b[1;32m    296\u001b[0m         key \u001b[39m=\u001b[39m deepcopy(key, memo)\n\u001b[0;32m--> 297\u001b[0m         value \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    298\u001b[0m         y[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m    299\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    151\u001b[0m copier \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39m__deepcopy__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/_tensor.py:98\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     96\u001b[0m     new_tensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone()\n\u001b[1;32m     97\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     new_storage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage()\u001b[39m.\u001b[39;49m__deepcopy__(memo)\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_quantized:\n\u001b[1;32m    100\u001b[0m         \u001b[39m# quantizer_params can be different type based on torch attribute\u001b[39;00m\n\u001b[1;32m    101\u001b[0m         quantizer_params: Union[Tuple[torch\u001b[39m.\u001b[39mqscheme, \u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m], Tuple[torch\u001b[39m.\u001b[39mqscheme, Tensor, Tensor, \u001b[39mint\u001b[39m]]\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/storage.py:450\u001b[0m, in \u001b[0;36m_TypedStorage.__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__deepcopy__\u001b[39m(\u001b[39mself\u001b[39m, memo):\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_wrapped_storage(copy\u001b[39m.\u001b[39;49mdeepcopy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_storage, memo))\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/storage.py:332\u001b[0m, in \u001b[0;36m_TypedStorage._new_wrapped_storage\u001b[0;34m(self, untyped_storage)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[39mreturn\u001b[39;00m _TypedStorage(wrap_storage\u001b[39m=\u001b[39muntyped_storage, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    329\u001b[0m     \u001b[39m# NOTE: We need to use the module of untyped_storage in case self's\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     \u001b[39m# module is different, e.g. if self is on CPU and untyped_storage\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     \u001b[39m# is on CUDA, and vice versa\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(module, \u001b[39mtype\u001b[39;49m(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)(wrap_storage\u001b[39m=\u001b[39;49muntyped_storage)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/storage.py:262\u001b[0m, in \u001b[0;36m_TypedStorage.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(storage, (torch\u001b[39m.\u001b[39m_UntypedStorage, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_UntypedStorage)):\n\u001b[1;32m    261\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(arg_error_msg)\n\u001b[0;32m--> 262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m!=\u001b[39m _TypedStorage \u001b[39mand\u001b[39;00m storage\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m((\n\u001b[1;32m    264\u001b[0m         arg_error_msg \u001b[39m+\u001b[39m\n\u001b[1;32m    265\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m`storage` `module \u001b[39m\u001b[39m{\u001b[39;00mstorage\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` does not match \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    266\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodule of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m))\n\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_storage \u001b[39m=\u001b[39m storage\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "additional_layers=[] ### can be empty or [8,7] for adding 2 layers with width 8,7 respectively\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":False,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        # \"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(3.0,6.0),\n",
    "        # \"lengthscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.001),\n",
    "        # \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        # \"outputscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        }\n",
    "\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":1,\n",
    "        ### for GIBO\n",
    "        \"n_max\":20, \n",
    "        \"n_info_samples\":8,\n",
    "        \"delta\":0.1, ## 0.01 better for linear\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\":True if kernel_name == \"rbf\" else False,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\" :200,\n",
    "        \"report_freq\":10,\n",
    "        \"save_best\":False,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model,objective_env = setup_experiment(env_config,kernel_config,likelihood_config,additional_layers)\n",
    "\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
