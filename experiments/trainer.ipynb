{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/envs/registration.py:415: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 23 2022 12:25:14\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla_bo import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [4, 1]\n",
      "discritizing action space\n",
      "MyRBF received 40 use_ard True\n",
      " Gibo will use 20 last points to fit GP and 8 info samples\n",
      "theta_i tensor([[0., 0., 0., 0.]])\n",
      "MyRBF received 10 use_ard True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_i tensor([[-0.0144, -0.2373,  0.0181,  0.3701]])\n",
      "MyRBF received 84 use_ard True\n",
      "breaking info gathering after 1 steps\n",
      "current 0.39600005745887756 / max 0.39600005745887756 /batch_mean 0.39600005745887756 /batch_max 0.39600005745887756 \n",
      "##############################\n",
      "covar_lengthscale max 9.165151596069336 / min 9.165151596069336                      covar_outputscale 1.0                     noise 0.05550000071525574\n",
      "##############################\n",
      "MLL : 0.36817580461502075\n",
      "grad_mean : max 0.16364161670207977 /  min -0.05580538883805275\n",
      "grad_covar : max 0.0008672068361192942 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[-0.0053, -0.2652,  0.0240,  0.4519]])\n",
      "MyRBF received 145 use_ard True\n",
      "breaking info gathering after 1 steps\n",
      "current 0.0860000029206276 / max 0.39600005745887756 /batch_mean 0.0860000029206276 /batch_max 0.0860000029206276 \n",
      "##############################\n",
      "covar_lengthscale max 12.041594505310059 / min 12.041594505310059                      covar_outputscale 1.0                     noise 0.05550000071525574\n",
      "##############################\n",
      "MLL : 0.3597755432128906\n",
      "grad_mean : max 0.1272418200969696 /  min -0.044263847172260284\n",
      "grad_covar : max 0.007657336536794901 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.0026, -0.2874,  0.0292,  0.5155]])\n",
      "MyRBF received 68 use_ard True\n",
      "breaking info gathering after 1 steps\n",
      "current 0.11800000071525574 / max 0.39600005745887756 /batch_mean 0.11800000071525574 /batch_max 0.11800000071525574 \n",
      "##############################\n",
      "covar_lengthscale max 8.246211051940918 / min 8.246211051940918                      covar_outputscale 1.0                     noise 0.05550000071525574\n",
      "##############################\n",
      "MLL : 0.36739400029182434\n",
      "grad_mean : max 0.1093740463256836 /  min -0.015653200447559357\n",
      "grad_covar : max 9.999999717180685e-10 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.0127, -0.2952,  0.0353,  0.5702]])\n",
      "MyRBF received 91 use_ard True\n",
      "current 0.2279999852180481 / max 0.39600005745887756 /batch_mean 0.2279999852180481 /batch_max 0.2279999852180481 \n",
      "##############################\n",
      "covar_lengthscale max 91.6103515625 / min 0.01769489422440529                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.183778166770935\n",
      "grad_mean : max 0.034591615200042725 /  min -0.2698848247528076\n",
      "grad_covar : max 0.36152970790863037 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.0009, -0.2779,  0.0154,  0.4353]])\n",
      "MyRBF received 69 use_ard True\n",
      "breaking info gathering after 1 steps\n",
      "current 0.09000000357627869 / max 0.39600005745887756 /batch_mean 0.09000000357627869 /batch_max 0.09000000357627869 \n",
      "##############################\n",
      "covar_lengthscale max 200.0 / min 0.10662440955638885                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.1504912376403809\n",
      "grad_mean : max 0.597041666507721 /  min -0.01619734987616539\n",
      "grad_covar : max 0.0042066252790391445 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[0.0447, 0.0206, 0.0894, 0.4272]])\n",
      "MyRBF received 168 use_ard True\n",
      "breaking info gathering after 2 steps\n",
      "current 1.0 / max 1.0 /batch_mean 1.0 /batch_max 1.0 \n",
      "##############################\n",
      "covar_lengthscale max 22.225730895996094 / min 0.5336810946464539                      covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 0.7372457981109619\n",
      "grad_mean : max 1.317712664604187 /  min -0.6267688274383545\n",
      "grad_covar : max 0.05497171729803085 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[-0.2687,  0.6795,  0.1910,  0.4123]])\n",
      "MyRBF received 11 use_ard True\n",
      "current 0.9580001831054688 / max 1.0 /batch_mean 0.9580001831054688 /batch_max 0.9580001831054688 \n",
      "##############################\n",
      "covar_lengthscale max 200.0 / min 0.036476537585258484                      covar_outputscale 0.12150458246469498                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 0.534855842590332\n",
      "grad_mean : max 4.787050724029541 /  min -3.9154460430145264\n",
      "grad_covar : max 4.235163688659668 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.0797, -1.2782, -0.2330,  2.8058]])\n",
      "MyRBF received 115 use_ard True\n",
      "current 0.1420000195503235 / max 1.0 /batch_mean 0.1420000195503235 /batch_max 0.1420000195503235 \n",
      "##############################\n",
      "covar_lengthscale max 16.307207107543945 / min 0.026122458279132843                      covar_outputscale 0.11124210059642792                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.1400846242904663\n",
      "grad_mean : max 1.1316115856170654 /  min 0.05298374593257904\n",
      "grad_covar : max 9.999999717180685e-10 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.2334, -0.7124, -0.1109,  2.8323]])\n",
      "MyRBF received 172 use_ard True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=52'>53</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GIBOptimizer(model,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=53'>54</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=54'>55</a>\u001b[0m rslt\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:52\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     50\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> 52\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m report_freq) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     56\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39my_hist\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:247\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo\u001b[39m.\u001b[39mupdate_theta_i(theta_i) \u001b[39m## this also update KxX_dx\u001b[39;00m\n\u001b[1;32m    246\u001b[0m bounds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta]]) \u001b[39m+\u001b[39m theta_i\n\u001b[0;32m--> 247\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_information(objective_env,model,bounds)\n\u001b[1;32m    249\u001b[0m \u001b[39m# # NEEEW : Adjust hyperparameters after information collection \u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# # for better gradient estimate\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[39m# if (model.N >= self.n_max): \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \n\u001b[1;32m    264\u001b[0m \u001b[39m# Take one step in direction of the gradient\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_gradient_step(model, theta_i)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:151\u001b[0m, in \u001b[0;36mGIBOptimizer.optimize_information\u001b[0;34m(self, objective_env, model, bounds)\u001b[0m\n\u001b[1;32m    148\u001b[0m model\u001b[39m.\u001b[39mposterior(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta_i)  \u001b[39m## hotfix\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m# Optimize acquistion function and get new observation.\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m new_x, acq_value \u001b[39m=\u001b[39m botorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49moptimize_acqf(\n\u001b[1;32m    152\u001b[0m     acq_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradInfo,\n\u001b[1;32m    153\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    154\u001b[0m     q\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,  \u001b[39m# Analytic acquisition function.\u001b[39;49;00m\n\u001b[1;32m    155\u001b[0m     num_restarts\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m    156\u001b[0m     raw_samples\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mnonnegative\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mbatch_limit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m5\u001b[39;49m},\n\u001b[1;32m    158\u001b[0m     return_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    159\u001b[0m     sequential\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    161\u001b[0m \u001b[39m# noise = 1e-5 *torch.rand_like(self.theta_i) \u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39m# new_x = self.theta_i + noise\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[39m# #Update training points.\u001b[39;00m\n\u001b[1;32m    164\u001b[0m new_y,new_s,_ \u001b[39m=\u001b[39m objective_env(new_x,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_eval)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/optim/optimize.py:205\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMust specify `raw_samples` when `batch_initial_conditions` is `None`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    200\u001b[0m     ic_gen \u001b[39m=\u001b[39m (\n\u001b[1;32m    201\u001b[0m         gen_one_shot_kg_initial_conditions\n\u001b[1;32m    202\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(acq_function, qKnowledgeGradient)\n\u001b[1;32m    203\u001b[0m         \u001b[39melse\u001b[39;00m gen_batch_initial_conditions\n\u001b[1;32m    204\u001b[0m     )\n\u001b[0;32m--> 205\u001b[0m     batch_initial_conditions \u001b[39m=\u001b[39m ic_gen(\n\u001b[1;32m    206\u001b[0m         acq_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    207\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    208\u001b[0m         q\u001b[39m=\u001b[39;49mq,\n\u001b[1;32m    209\u001b[0m         num_restarts\u001b[39m=\u001b[39;49mnum_restarts,\n\u001b[1;32m    210\u001b[0m         raw_samples\u001b[39m=\u001b[39;49mraw_samples,\n\u001b[1;32m    211\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    212\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    213\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    214\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    215\u001b[0m     )\n\u001b[1;32m    217\u001b[0m batch_limit: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\n\u001b[1;32m    218\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbatch_limit\u001b[39m\u001b[39m\"\u001b[39m, num_restarts \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nonlinear_inequality_constraints \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    220\u001b[0m batch_candidates_list: List[Tensor] \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/optim/initializers.py:183\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mwhile\u001b[39;00m start_idx \u001b[39m<\u001b[39m X_rnd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    182\u001b[0m     end_idx \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start_idx \u001b[39m+\u001b[39m batch_limit, X_rnd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 183\u001b[0m     Y_rnd_curr \u001b[39m=\u001b[39m acq_function(\n\u001b[1;32m    184\u001b[0m         X_rnd[start_idx:end_idx]\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    185\u001b[0m     )\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    186\u001b[0m     Y_rnd_list\u001b[39m.\u001b[39mappend(Y_rnd_curr)\n\u001b[1;32m    187\u001b[0m     start_idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_limit\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/utils/transforms.py:258\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    257\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 258\u001b[0m output \u001b[39m=\u001b[39m method(acqf, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(acqf, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m is_fully_bayesian(acqf\u001b[39m.\u001b[39mmodel):\n\u001b[1;32m    260\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:99\u001b[0m, in \u001b[0;36mGradientInformation.forward\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     96\u001b[0m K_XX_inv \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(K_XX)\n\u001b[1;32m     98\u001b[0m \u001b[39m# get K_xX_dx\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m K_xθ_dx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_KxX_dx(x, theta)\n\u001b[1;32m    100\u001b[0m K_xX_dx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK_xX_dx_part, K_xθ_dx], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    102\u001b[0m \u001b[39m# Compute_variance.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:68\u001b[0m, in \u001b[0;36mGradientInformation._get_KxX_dx\u001b[0;34m(self, theta_t, X_hat)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_KxX_dx\u001b[39m(\u001b[39mself\u001b[39m, theta_t, X_hat) :\n\u001b[1;32m     59\u001b[0m     \u001b[39m'''Computes the analytic derivative of the kernel K(x,X) w.r.t. x.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m        (n x D) The derivative of K(x,X) w.r.t. x.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     jacobs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mjacobian(func\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m theta : \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mK_xX(theta,X_hat),inputs\u001b[39m=\u001b[39;49m(theta_t))\n\u001b[1;32m     69\u001b[0m     K_xX_dx \u001b[39m=\u001b[39m jacobs\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     71\u001b[0m     \u001b[39mreturn\u001b[39;00m K_xX_dx\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/autograd/functional.py:669\u001b[0m, in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize, strategy)\u001b[0m\n\u001b[1;32m    667\u001b[0m jac_i: Tuple[List[torch\u001b[39m.\u001b[39mTensor]] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(inputs)))  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(out\u001b[39m.\u001b[39mnelement()):\n\u001b[0;32m--> 669\u001b[0m     vj \u001b[39m=\u001b[39m _autograd_grad((out\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)[j],), inputs,\n\u001b[1;32m    670\u001b[0m                         retain_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, create_graph\u001b[39m=\u001b[39;49mcreate_graph)\n\u001b[1;32m    672\u001b[0m     \u001b[39mfor\u001b[39;00m el_idx, (jac_i_el, vj_el, inp_el) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(jac_i, vj, inputs)):\n\u001b[1;32m    673\u001b[0m         \u001b[39mif\u001b[39;00m vj_el \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/autograd/functional.py:159\u001b[0m, in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph, is_grads_batched)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m,) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(inputs)\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(new_outputs, inputs, new_grad_outputs, allow_unused\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    160\u001b[0m                                create_graph\u001b[39m=\u001b[39;49mcreate_graph, retain_graph\u001b[39m=\u001b[39;49mretain_graph,\n\u001b[1;32m    161\u001b[0m                                is_grads_batched\u001b[39m=\u001b[39;49mis_grads_batched)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/autograd/__init__.py:275\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs)\n\u001b[1;32m    274\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    276\u001b[0m         outputs, grad_outputs_, retain_graph, create_graph, inputs,\n\u001b[1;32m    277\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "#env_name = \"Swimmer-v4\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "additional_layers=[] ### can be empty or [8,7] for adding 2 layers with width 8,7 respectively\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":1, ## 3 for cartpole (very noisy)\n",
    "        ### for GIBO\n",
    "        \"n_max\":20, \n",
    "        \"n_info_samples\":8,\n",
    "        \"delta\":0.1, ## 0.01 for cartpole\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\":True if kernel_name == \"rbf\" else False,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "likelihood_config = {\n",
    "                \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.101),\n",
    "                \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.101)\n",
    "                }\n",
    "\n",
    "# kernel_config = {\n",
    "#         \"use_ard\":False,\n",
    "#         \"kernel_name\":kernel_name,\n",
    "#         #lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(5,0.9),\n",
    "#         #\"lengthscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.1),\n",
    "#         #\"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.1),\n",
    "#          \"outputscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.4),\n",
    "#         }\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":True,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        # \"lengthscale_hyperprior\":None,\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.Interval(0.01,200),\n",
    "        # \"outputscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        }\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\":20, \n",
    "        \"report_freq\":1,\n",
    "        \"save_best\":False,\n",
    "}\n",
    "\n",
    "model,objective_env = setup_experiment(env_config,kernel_config,likelihood_config,additional_layers)\n",
    "\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()\n",
    "\n",
    "### ADD LR SCHEDULAR  / FIX DISCRETIZATION ===> ENJOY WEEKEND :DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7085ba32b0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = 2\n",
    "beta = 0.4\n",
    "x = np.linspace (0, 20, 200) \n",
    "y1 = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n",
    "plt.plot(x,y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
