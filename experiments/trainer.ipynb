{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/envs/registration.py:415: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 23 2022 12:25:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "print(\"hello\")\n",
    "\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1b0ozoch) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>▁▁▂▂▁▂▃▅█▇▂▂▃▂</td></tr><tr><td>acq_diff</td><td>▁▁▁▁▁▁▁▂▂▁▁▁█▃▂▁▅▂▁▁▁▂▁▁▁▁▅▂▁▁▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>acq_value (after finish)</td><td>▁▁▁▂▁▁▁▆▇█▇█▇▇</td></tr><tr><td>action_distance_to_local</td><td>▂▁▁▆▆▅▆▁▆▅▅▄▅█▇▅▆▇▅▆▆▅▆▇▆▇▅█▅▆▅█▅▆▅▇▆▆▅▅</td></tr><tr><td>covar_lengthscale mean</td><td>▁▁▁▁▁▁▃████▁██</td></tr><tr><td>covar_lengthscale std</td><td>▁▁▁▁▁▁█▅▃▃▄▂▃▃</td></tr><tr><td>covar_output_scale</td><td>████▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>max_covar(before hessian)</td><td>▁▁▁█▁▁▂▂▂▃▁▂▂▁</td></tr><tr><td>max_grad(before hessian)</td><td>▂▁▂▂▁▁▅▇▅▅▆█▄▁</td></tr><tr><td>max_return</td><td>▁▁▂▂▃▃▃▄▆██████</td></tr><tr><td>max_var/mean</td><td>▁▁▁█▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mean_grad(before hessian)</td><td>▁▁▁▁▁▁▃█▃▂▄▄▂▁</td></tr><tr><td>n_info_points</td><td>▃▁▁▇▁▁▁███████</td></tr><tr><td>n_samples</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>noise</td><td>████▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>param_distance_to_local</td><td>▂▇▃█▇▆█▄▄▅▃▄▅▄▂▅▅▂▃▅▃▁▅▂▂▅▄▄▁▁▆▄▃▂▂▆▄▂▆▃</td></tr><tr><td>policy_return</td><td>▂▂▁▁▂▁▁▃▁▂▄▂▃▄▃▆▅▆▅████▇▆▆▆▇▇█▆█▇█▇██▇██</td></tr><tr><td>policy_return_at_grad</td><td>▁▁▂▂▁▁▂▃▆█▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Mean MAE</td><td>0.05842</td></tr><tr><td>acq_diff</td><td>0.01524</td></tr><tr><td>acq_value (after finish)</td><td>24.85475</td></tr><tr><td>action_distance_to_local</td><td>18.16029</td></tr><tr><td>covar_lengthscale mean</td><td>9.7893</td></tr><tr><td>covar_lengthscale std</td><td>1.27754</td></tr><tr><td>covar_output_scale</td><td>0.01</td></tr><tr><td>max_covar(before hessian)</td><td>0.03521</td></tr><tr><td>max_grad(before hessian)</td><td>0.03499</td></tr><tr><td>max_return</td><td>1.02028</td></tr><tr><td>max_var/mean</td><td>1.00615</td></tr><tr><td>mean_grad(before hessian)</td><td>0.00945</td></tr><tr><td>n_info_points</td><td>16</td></tr><tr><td>n_samples</td><td>177</td></tr><tr><td>noise</td><td>0.01</td></tr><tr><td>param_distance_to_local</td><td>0.2422</td></tr><tr><td>policy_return</td><td>1.01507</td></tr><tr><td>policy_return_at_grad</td><td>1.01507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">Swimmer-v4rbfstate1</strong>: <a href=\"https://wandb.ai/mahdikallel/explo/runs/1b0ozoch\" target=\"_blank\">https://wandb.ai/mahdikallel/explo/runs/1b0ozoch</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220726_135352-1b0ozoch/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1b0ozoch). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/q123/Desktop/explo/wandb/run-20220726_135900-1fsljsts</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/explo/runs/1fsljsts\" target=\"_blank\">Swimmer-v4rbfstate1</a></strong> to <a href=\"https://wandb.ai/mahdikallel/explo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "seed = 1\n",
    "#env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "#env_name = \"Hopper-v2\"\n",
    "#env_name = \"Walker2d-v3\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,mean_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "env_config[\"manipulate_state\"] = False\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":2, ## 3 for cartpole (very noisy)\n",
    "        ### for GIBO\n",
    "        \"n_max\":32, \n",
    "        \"n_info_samples\":16,\n",
    "        \"delta\":0.1, ## 0.01 for cartpole\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\": True,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "\n",
    "likelihood_config = {\n",
    "                \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.05),\n",
    "                \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.05)\n",
    "                }\n",
    "\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":True,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.2),\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(1,0,),\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.Interval(0.1,10),\n",
    "        #\"outputscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.4),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        }\n",
    "\n",
    "mean_config = {\n",
    "                \"advantage\":False,\n",
    "        }\n",
    "\n",
    "\n",
    "policy_config = {\n",
    "        \"add_layer\":[],### can be empty or [8,7] for adding 2 layers with width 8,7  neurons respectively\n",
    "        \"add_bias\":False,\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\":1000, \n",
    "        \"report_freq\":100,\n",
    "        \"save_best\":False,\n",
    "        \"wandb_logger\":True,\n",
    "        \"run_name\" : env_name+kernel_name+str(seed),\n",
    "        \"wandb_config\": {**env_config,**optimizer_config,**likelihood_config,**kernel_config,**policy_config}\n",
    "}\n",
    "\n",
    "\n",
    "model,objective_env,optimizer = setup_experiment(env_config,mean_config,kernel_config,likelihood_config,policy_config,optimizer_config,\n",
    "                                seed=seed)\n",
    "\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()\n",
    "\n",
    "### ADD LR SCHEDULAR  / FIX DISCRETIZATION ===> ENJOY WEEKEND :DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as stats \n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# alpha = 2\n",
    "# beta = 0.3\n",
    "# x = np.linspace (0, 10, 200) \n",
    "# y1 = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n",
    "# plt.plot(x,y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
