{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mkallel/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkallel/miniconda3/envs/bopt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%cd /home/mkallel/explo/\n",
    "\n",
    "import torch \n",
    "import numpy as np\n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.config import get_configs\n",
    "\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "print(\"hello\")\n",
    "\n",
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(seed):\n",
    "\n",
    "        \n",
    "\n",
    "        torch.set_num_threads(1)\n",
    "                \n",
    "        #env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "        env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "        #env_name = \"Hopper-v2\"\n",
    "        #env_name = \"Walker2d-v3\"\n",
    "        kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "        env_config,likelihood_config,kernel_config,mean_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "        env_config[\"manipulate_state\"] = False\n",
    "\n",
    "        optimizer_config = {\n",
    "                \"n_eval\":2, ## 3 for cartpole (very noisy)\n",
    "                ### for GIBO\n",
    "                \"n_max\":32, \n",
    "                \"n_info_samples\":16,\n",
    "                \"delta\":0.1, ## 0.01 for cartpole\n",
    "                ### hessian normalisation applies only for rbf\n",
    "                \"normalize_gradient\": False,\n",
    "                \"standard_deviation_scaling\":False,\n",
    "        }\n",
    "\n",
    "\n",
    "        likelihood_config = {\n",
    "                        \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.05),\n",
    "                        \"noise_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "                        }\n",
    "\n",
    "\n",
    "        kernel_config = {\n",
    "                \"use_ard\":False,\n",
    "                \"kernel_name\":kernel_name,\n",
    "                #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.2),\n",
    "                #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(1,0,),\n",
    "                \"lengthscale_constraint\":gpytorch.constraints.constraints.Interval(0.1,10),\n",
    "                #\"outputscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.4),\n",
    "                \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "                }\n",
    "\n",
    "        mean_config = {\n",
    "                        \"advantage\":False,\n",
    "                }\n",
    "\n",
    "\n",
    "        policy_config = {\n",
    "                \"add_layer\":[],### can be empty or [8,7] for adding 2 layers with width 8,7  neurons respectively\n",
    "                \"add_bias\":False,\n",
    "        }\n",
    "\n",
    "        trainer_config = {\n",
    "                \"n_steps\":1000, \n",
    "                \"report_freq\":100,\n",
    "                \"save_best\":False,\n",
    "                \"wandb_logger\":True,\n",
    "                \"project_name\":env_name,\n",
    "                \"run_name\" : kernel_name+\"_use_ard_\"*kernel_config[\"use_ard\"]+\"_normalize_gradient_\"*optimizer_config[\"normalize_gradient\"]+str(seed),\n",
    "                \"wandb_config\": {**env_config,**optimizer_config,**likelihood_config,**kernel_config,**policy_config}\n",
    "        }\n",
    "\n",
    "\n",
    "        model,objective_env,optimizer = setup_experiment(env_config,mean_config,kernel_config,likelihood_config,policy_config,optimizer_config,\n",
    "                                        seed=seed)\n",
    "\n",
    "        trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "        rslt= trainer.run()\n",
    "\n",
    "        ### ADD LR SCHEDULAR  / FIX DISCRETIZATION ===> ENJOY WEEKEND :DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "fixing seed to  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mkallel/explo/experiments/trainer.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/trainer.ipynb#ch0000002vscode-remote?line=10'>11</a>\u001b[0m wandb\u001b[39m.\u001b[39mrequire(\u001b[39m\"\u001b[39m\u001b[39mservice\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/trainer.ipynb#ch0000002vscode-remote?line=12'>13</a>\u001b[0m \u001b[39mwith\u001b[39;00m Pool(processes\u001b[39m=\u001b[39mn) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsmithers.lille.inria.fr/home/mkallel/explo/experiments/trainer.ipynb#ch0000002vscode-remote?line=13'>14</a>\u001b[0m     p\u001b[39m.\u001b[39;49mmap(f, seeds)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    766\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 600\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import wandb\n",
    "\n",
    "n = \n",
    "seeds = np.random.randint(low=0,high=2**30,size=(n,))\n",
    "seeds = [ int(i) for i in seeds]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    wandb.require(\"service\")\n",
    "    \n",
    "    with Pool(processes=n) as p:\n",
    "        p.map(f, seeds)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(seeds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as stats \n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# alpha = 2\n",
    "# beta = 0.3\n",
    "# x = np.linspace (0, 10, 200) \n",
    "# y1 = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n",
    "# plt.plot(x,y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('bopt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6c7e76b21fbf8268359659a13a1687ca07cc6ddf0d10c2b26cf47d2a8edd420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
