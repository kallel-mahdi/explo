{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/envs/registration.py:415: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 23 2022 12:25:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla_bo import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [11, 3]\n",
      "Using state normalization\n",
      "MyRBF received 4851 use_ard True\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n",
      "theta_i tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "MyRBF received 780 use_ard True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq_diff 0.11988714337348938\n",
      "acq_diff 0.1099603921175003\n",
      "acq_diff 0.09670820832252502\n",
      "acq_diff 0.13605353236198425\n",
      "acq_diff 0.09397852420806885\n",
      "acq_diff 0.08780789375305176\n",
      "acq_diff 0.0709066390991211\n",
      "acq_diff 0.07632046937942505\n",
      "acq_diff 0.048949599266052246\n",
      "acq_diff 0.03609776496887207\n",
      "acq_diff 0.0365675687789917\n",
      "acq_diff 0.03170585632324219\n",
      "acq_diff 0.02892172336578369\n",
      "acq_diff 0.035480499267578125\n",
      "acq_diff 0.019053339958190918\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.2494], requires_grad=True)\n",
      "inv hessian mean 8.872930526733398 gradient mean 0.12291020900011063 \n",
      "theta_i tensor([[ 0.2669, -0.0218, -0.0070, -0.0179,  0.0041, -0.0295,  0.0162, -0.0677,\n",
      "         -0.0194, -0.0592,  0.0146,  0.1946, -0.0368, -0.0127, -0.0283,  0.0048,\n",
      "         -0.0493,  0.0045, -0.1101, -0.0311, -0.0938,  0.0115,  0.4166, -0.0458,\n",
      "         -0.0180, -0.0304,  0.0044, -0.0614,  0.0608, -0.1357, -0.0442, -0.1029,\n",
      "          0.0062]])\n",
      "MyRBF received 174 use_ard True\n",
      "acq_diff 0.5661087036132812\n",
      "acq_diff 0.6044254302978516\n",
      "acq_diff 0.2662315368652344\n",
      "acq_diff 0.1545696258544922\n",
      "acq_diff 0.21356201171875\n",
      "acq_diff 0.17714500427246094\n",
      "acq_diff 0.13189697265625\n",
      "acq_diff 0.17353248596191406\n",
      "acq_diff 0.10488128662109375\n",
      "acq_diff 0.10771942138671875\n",
      "acq_diff 0.09481239318847656\n",
      "acq_diff 0.079315185546875\n",
      "acq_diff 0.07883834838867188\n",
      "acq_diff 0.06548690795898438\n",
      "acq_diff 0.056636810302734375\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0785], requires_grad=True)\n",
      "inv hessian mean 9.195619583129883 gradient mean 0.06085245683789253 \n",
      "current 0.14706069231033325 / max 0.2860715687274933 /batch_mean 0.14706069231033325 /batch_max 0.14706069231033325 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.137283593416214                      mean9.895674705505371                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2727304697036743\n",
      "grad_mean : max 0.04167133942246437 /  min -0.0011534199584275484\n",
      "grad_covar : max 5.7840061344904825e-06 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.2870, -0.0212, -0.0069, -0.0178,  0.0091, -0.0216,  0.0172, -0.0572,\n",
      "         -0.0196, -0.0592,  0.0784,  0.1855, -0.0375, -0.0128, -0.0283, -0.0011,\n",
      "         -0.0595, -0.0023, -0.1241, -0.0312, -0.0936, -0.0549,  1.0221, -0.0498,\n",
      "         -0.0165, -0.0311, -0.0111, -0.0818,  0.0532, -0.1622, -0.0431, -0.1023,\n",
      "         -0.0923]])\n",
      "MyRBF received 246 use_ard True\n",
      "acq_diff 2.549881173763424e-06\n",
      "acq_diff 2.1498199203051627e-06\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0763], requires_grad=True)\n",
      "inv hessian mean 9.335236549377441 gradient mean 0.4581543803215027 \n",
      "current 0.06447738409042358 / max 0.2860715687274933 /batch_mean 0.06447738409042358 /batch_max 0.06447738409042358 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 1.8263410329818726                      mean9.614727020263672                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2886780500411987\n",
      "grad_mean : max 0.001989056123420596 /  min -0.0006753435591235757\n",
      "grad_covar : max 3.895895588357234e-06 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.4839, -0.0212, -0.0065, -0.0340,  0.0856,  0.0506,  0.0917, -0.0499,\n",
      "         -0.0202, -0.3052,  0.6629,  0.9581, -0.0360, -0.0111, -0.0700,  0.1860,\n",
      "          0.1262,  0.1997, -0.0984, -0.0319, -0.7104,  1.3404,  1.3632, -0.0537,\n",
      "         -0.0156, -0.0600,  0.1340,  0.0579,  0.2502, -0.1830, -0.0433, -0.7012,\n",
      "          1.2845]])\n",
      "MyRBF received 147 use_ard True\n",
      "acq_diff 5.615263944491744e-05\n",
      "acq_diff 3.745732828974724e-05\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0739], requires_grad=True)\n",
      "inv hessian mean 9.258726119995117 gradient mean 0.28751489520072937 \n",
      "current 0.07400260120630264 / max 0.2860715687274933 /batch_mean 0.07400260120630264 /batch_max 0.07400260120630264 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 5.434563636779785                      mean9.926060676574707                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2972928285598755\n",
      "grad_mean : max 2.7804769615613623e-06 /  min -0.002104116603732109\n",
      "grad_covar : max 2.0067014361302427e-07 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.3643, -0.0329, -0.0066, -0.0340, -0.0037, -0.0942, -0.0317, -0.2744,\n",
      "         -0.0151, -0.3148, -0.0656,  0.9170, -0.0362, -0.0116, -0.0705,  0.1576,\n",
      "          0.0521,  0.1692, -0.2542, -0.0542, -0.7478,  0.3353,  1.1913, -0.0638,\n",
      "         -0.0160, -0.0602,  0.0481, -0.0896,  0.1533, -0.4302, -0.0527, -0.7259,\n",
      "          0.1873]])\n",
      "MyRBF received 219 use_ard True\n",
      "acq_diff 9.639712516218424e-06\n",
      "acq_diff 7.875845767557621e-06\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0815], requires_grad=True)\n",
      "inv hessian mean 9.266870498657227 gradient mean 0.4899795353412628 \n",
      "current 0.18480195105075836 / max 0.2860715687274933 /batch_mean 0.18480195105075836 /batch_max 0.18480195105075836 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 4.609499454498291                      mean9.317395210266113                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2924867868423462\n",
      "grad_mean : max 0.0007333234534598887 /  min -0.003937056288123131\n",
      "grad_covar : max 4.068424823344685e-05 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[-0.0532, -0.0515,  0.0325, -0.0350, -0.2117, -0.3728, -0.1478, -0.5134,\n",
      "          0.1841, -0.3149, -0.9210,  0.5533, -0.0513,  0.0150, -0.0715,  0.0043,\n",
      "         -0.1612,  0.1121, -0.4419,  0.0986, -0.7490, -0.7410,  0.5799, -0.0866,\n",
      "          0.0328, -0.0618, -0.2215, -0.4510,  0.0173, -0.7371,  0.2144, -0.7311,\n",
      "         -1.2460]])\n",
      "MyRBF received 69 use_ard True\n",
      "acq_diff 5.60424814466387e-06\n",
      "acq_diff 5.972804501652718e-06\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0723], requires_grad=True)\n",
      "inv hessian mean 9.510368347167969 gradient mean 0.48159775137901306 \n",
      "current 0.018181990832090378 / max 0.2860715687274933 /batch_mean 0.018181990832090378 /batch_max 0.018181990832090378 \n",
      "##############################\n",
      "covar_lengthscale max 9.999939918518066                     min 7.089892864227295                      mean9.82354736328125                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2688592672348022\n",
      "grad_mean : max 0.0018246856052428484 /  min -0.0033203589264303446\n",
      "grad_covar : max 1.461669944546884e-05 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 0.7923, -0.0965, -0.0195, -0.0344, -0.1846, -0.4295, -0.4742, -1.8021,\n",
      "         -1.4061, -0.2616,  0.1935,  0.6026, -0.0662, -0.0026, -0.0715,  0.0130,\n",
      "         -0.1656,  0.0260, -0.6944, -0.2374, -0.7066, -0.3536,  0.6685, -0.1023,\n",
      "          0.0144, -0.0618, -0.2121, -0.4446, -0.0820, -0.9103, -0.0522, -0.6611,\n",
      "         -0.6468]])\n",
      "MyRBF received 429 use_ard True\n",
      "acq_diff 0.00013904750812798738\n",
      "acq_diff 0.00010103557724505663\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0950], requires_grad=True)\n",
      "inv hessian mean 9.589789390563965 gradient mean 0.11141274869441986 \n",
      "current 0.16893231868743896 / max 0.2860715687274933 /batch_mean 0.16893231868743896 /batch_max 0.16893231868743896 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.13188904523849487                      mean9.965968132019043                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2953208684921265\n",
      "grad_mean : max 0.029899220913648605 /  min -0.026515498757362366\n",
      "grad_covar : max 0.0009239687351509929 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 1.1733e+00, -3.9327e-02, -7.1442e-02, -3.8911e-02, -7.3500e-02,\n",
      "         -1.3858e-01, -5.4118e-01, -1.8827e+00, -1.7712e+00, -3.0750e-01,\n",
      "          2.1060e-01,  5.5560e-01, -6.9191e-02, -2.5942e-04, -7.1382e-02,\n",
      "          6.5035e-03, -1.9250e-01,  3.4579e-02, -7.2176e-01, -2.3864e-01,\n",
      "         -7.1240e-01, -3.9219e-01,  6.0606e-01, -1.0602e-01,  1.7256e-02,\n",
      "         -6.1666e-02, -2.2040e-01, -4.7819e-01, -7.1312e-02, -9.3579e-01,\n",
      "         -4.5526e-02, -6.6401e-01, -6.8812e-01]])\n",
      "MyRBF received 450 use_ard True\n",
      "acq_diff 0.00023379968479275703\n",
      "acq_diff 0.00016784993931651115\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.1016], requires_grad=True)\n",
      "inv hessian mean 9.504374504089355 gradient mean 0.08865312486886978 \n",
      "current 0.16102522611618042 / max 0.2860715687274933 /batch_mean 0.16102522611618042 /batch_max 0.16102522611618042 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000010579824448                      mean9.92202377319336                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.294129490852356\n",
      "grad_mean : max 0.0266750305891037 /  min -0.005091305822134018\n",
      "grad_covar : max 0.00043703755363821983 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 1.5176e+00, -3.7463e-02, -7.0839e-02, -3.8498e-02, -7.1760e-02,\n",
      "         -1.7520e-01, -5.9825e-01, -2.2096e+00, -2.0765e+00, -4.3959e-01,\n",
      "          8.5125e-02,  5.2728e-01, -7.1433e-02, -3.2246e-04, -7.1404e-02,\n",
      "          4.0665e-03, -2.0153e-01,  3.6904e-02, -7.2991e-01, -2.3896e-01,\n",
      "         -7.1253e-01, -3.9972e-01,  5.7308e-01, -1.0856e-01,  1.7182e-02,\n",
      "         -6.1691e-02, -2.2318e-01, -4.8831e-01, -6.8337e-02, -9.4482e-01,\n",
      "         -4.5773e-02, -6.6409e-01, -6.9708e-01]])\n",
      "MyRBF received 477 use_ard True\n",
      "acq_diff 0.00017098919488489628\n",
      "acq_diff 0.00011047185398638248\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.1101], requires_grad=True)\n",
      "inv hessian mean 9.662493705749512 gradient mean 0.07900528609752655 \n",
      "current 0.22098824381828308 / max 0.2860715687274933 /batch_mean 0.22098824381828308 /batch_max 0.22098824381828308 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.1000412255525589                      mean9.964262008666992                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2918730974197388\n",
      "grad_mean : max 0.046216800808906555 /  min -0.02787935733795166\n",
      "grad_covar : max 0.0010433029383420944 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 1.8838e+00, -3.7200e-02, -6.9692e-02, -3.8282e-02, -5.2035e-02,\n",
      "         -1.7422e-01, -8.3789e-01, -2.2012e+00, -2.0777e+00, -4.3994e-01,\n",
      "          3.5649e-01,  4.5422e-01, -7.7256e-02, -5.2638e-04, -7.1456e-02,\n",
      "         -2.1047e-03, -2.2065e-01,  4.5137e-02, -7.4752e-01, -2.3940e-01,\n",
      "         -7.1353e-01, -4.2416e-01,  4.6071e-01, -1.1758e-01,  1.6869e-02,\n",
      "         -6.1771e-02, -2.3274e-01, -5.1886e-01, -5.6759e-02, -9.7263e-01,\n",
      "         -4.6354e-02, -6.6537e-01, -7.3174e-01]])\n",
      "MyRBF received 618 use_ard True\n",
      "acq_diff 0.00020567304454743862\n",
      "acq_diff 0.00014373334124684334\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.1250], requires_grad=True)\n",
      "inv hessian mean 9.678051948547363 gradient mean 0.08833406865596771 \n",
      "current 0.25209739804267883 / max 0.2860715687274933 /batch_mean 0.25209739804267883 /batch_max 0.25209739804267883 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.1000436320900917                      mean9.971328735351562                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2969082593917847\n",
      "grad_mean : max 0.021455617621541023 /  min -0.01271647959947586\n",
      "grad_covar : max 0.000798180524725467 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 2.3687e+00, -3.8371e-02, -6.7736e-02, -3.8000e-02, -3.3987e-02,\n",
      "         -1.7573e-01, -1.1410e+00, -2.2100e+00, -2.0946e+00, -4.3857e-01,\n",
      "          6.9119e-01,  3.8900e-01, -8.2556e-02, -7.3350e-04, -7.1504e-02,\n",
      "         -7.4625e-03, -2.3468e-01,  5.0351e-02, -7.6001e-01, -2.3961e-01,\n",
      "         -7.1368e-01, -4.3919e-01,  3.7492e-01, -1.2456e-01,  1.6598e-02,\n",
      "         -6.1833e-02, -2.3980e-01, -5.3765e-01, -5.0272e-02, -9.8928e-01,\n",
      "         -4.6585e-02, -6.6555e-01, -7.5073e-01]])\n",
      "MyRBF received 783 use_ard True\n",
      "acq_diff 0.00013197818771004677\n",
      "acq_diff 0.00010107806883752346\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.1475], requires_grad=True)\n",
      "inv hessian mean 9.693843841552734 gradient mean 0.0897359699010849 \n",
      "current 0.2404969483613968 / max 0.32324472069740295 /batch_mean 0.2404969483613968 /batch_max 0.2404969483613968 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10006933659315109                      mean9.947187423706055                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2981935739517212\n",
      "grad_mean : max 0.011428744532167912 /  min -0.007404927164316177\n",
      "grad_covar : max 0.000713525980245322 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.0194e+00, -3.5151e-02, -6.5824e-02, -3.7601e-02, -1.3205e-02,\n",
      "         -1.7155e-01, -1.5744e+00, -2.2061e+00, -2.0922e+00, -4.4133e-01,\n",
      "          1.0299e+00,  3.8836e-01, -8.2610e-02, -7.3581e-04, -7.1504e-02,\n",
      "         -7.5237e-03, -2.3503e-01,  5.0054e-02, -7.6026e-01, -2.3960e-01,\n",
      "         -7.1363e-01, -4.3860e-01,  3.6515e-01, -1.2527e-01,  1.6568e-02,\n",
      "         -6.1838e-02, -2.4052e-01, -5.3959e-01, -4.9940e-02, -9.9093e-01,\n",
      "         -4.6592e-02, -6.6549e-01, -7.5147e-01]])\n",
      "MyRBF received 807 use_ard True\n",
      "acq_diff 0.0001255889656022191\n",
      "acq_diff 8.366699330508709e-05\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.1871], requires_grad=True)\n",
      "inv hessian mean 9.047839164733887 gradient mean 0.14189957082271576 \n",
      "current 0.3271026611328125 / max 0.3750782907009125 /batch_mean 0.3271026611328125 /batch_max 0.3271026611328125 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean9.94330883026123                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.3024917840957642\n",
      "grad_mean : max 0.008756216615438461 /  min -0.008107700385153294\n",
      "grad_covar : max 0.00021758770162705332 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5109e+00, -3.3065e-02, -6.3103e-02, -3.7649e-02, -9.9875e-03,\n",
      "         -1.6145e-01, -1.6760e+00, -2.1575e+00, -2.0649e+00, -4.0552e-01,\n",
      "          1.4196e+00,  3.3423e-01, -8.3386e-02, -9.7719e-04, -7.1540e-02,\n",
      "         -8.3696e-03, -2.3575e-01,  5.9281e-02, -7.6038e-01, -2.4462e-01,\n",
      "         -7.0200e-01, -4.3592e-01, -1.4160e-01, -1.2720e-01,  1.4385e-02,\n",
      "         -6.1907e-02, -2.4288e-01, -5.2552e-01,  5.8589e-03, -9.7818e-01,\n",
      "         -1.4201e-01, -4.7478e-01, -4.9037e-01]])\n",
      "MyRBF received 1818 use_ard True\n",
      "acq_diff 0.0017686374485492706\n",
      "acq_diff 0.001077793538570404\n",
      "breaking info gathering after 3 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.3757], requires_grad=True)\n",
      "inv hessian mean 8.718646049499512 gradient mean 0.003837884869426489 \n",
      "current 1.9555320739746094 / max 1.9555320739746094 /batch_mean 1.9555320739746094 /batch_max 1.9555320739746094 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean8.878314971923828                     covar_outputscale 0.009999999776482582                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : -0.38519978523254395\n",
      "grad_mean : max 2.008012533187866 /  min -0.22362862527370453\n",
      "grad_covar : max 0.005787893198430538 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.4985e+00, -3.2984e-02, -6.3141e-02, -3.7666e-02, -9.8901e-03,\n",
      "         -1.5931e-01, -1.6769e+00, -2.1557e+00, -2.0649e+00, -4.0549e-01,\n",
      "          1.4180e+00,  3.3455e-01, -8.3409e-02, -9.7622e-04, -7.1539e-02,\n",
      "         -8.3922e-03, -2.3578e-01,  5.9270e-02, -7.6040e-01, -2.4462e-01,\n",
      "         -7.0200e-01, -4.3594e-01, -1.2150e-01, -1.2935e-01,  1.4440e-02,\n",
      "         -6.1856e-02, -2.4530e-01, -5.2554e-01, -9.7722e-04, -9.7745e-01,\n",
      "         -1.4178e-01, -4.7297e-01, -4.9983e-01]])\n",
      "MyRBF received 2115 use_ard True\n",
      "acq_diff 0.2924461364746094\n",
      "acq_diff 0.15059280395507812\n",
      "acq_diff 0.116119384765625\n",
      "acq_diff 0.10881805419921875\n",
      "acq_diff 0.10504531860351562\n",
      "acq_diff 0.06595039367675781\n",
      "acq_diff 0.05833244323730469\n",
      "acq_diff 0.04970741271972656\n",
      "acq_diff 0.03948783874511719\n",
      "acq_diff 0.039478302001953125\n",
      "acq_diff 0.03806114196777344\n",
      "acq_diff 0.028215408325195312\n",
      "acq_diff 0.027667999267578125\n",
      "acq_diff 0.026082992553710938\n",
      "acq_diff 0.021450042724609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/fit.py:155: RuntimeWarning: Fitting failed on all retries.\n",
      "  warnings.warn(\"Fitting failed on all retries.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mean constant Parameter containing:\n",
      "tensor([0.7247], requires_grad=True)\n",
      "inv hessian mean 8.79073429107666 gradient mean 0.005166653078049421 \n",
      "current 0.4667786955833435 / max 1.9555320739746094 /batch_mean 0.4667786955833435 /batch_max 0.4667786955833435 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean6.775431156158447                     covar_outputscale 0.737937331199646                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.0884758234024048\n",
      "grad_mean : max 8.455249786376953 /  min -0.5887863039970398\n",
      "grad_covar : max 2.865081787109375 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.4943e+00, -3.2636e-02, -6.3154e-02, -3.7671e-02, -9.5578e-03,\n",
      "         -1.5900e-01, -1.6768e+00, -2.1555e+00, -2.0649e+00, -4.0548e-01,\n",
      "          1.4181e+00,  3.3496e-01, -8.3517e-02, -9.7486e-04, -7.1539e-02,\n",
      "         -8.4331e-03, -2.3689e-01,  6.0852e-02, -7.6127e-01, -2.4460e-01,\n",
      "         -7.0185e-01, -4.3041e-01, -1.1029e-01, -1.0291e-01,  1.4482e-02,\n",
      "         -6.1800e-02, -2.2087e-01, -5.2591e-01, -5.0303e-03, -9.7836e-01,\n",
      "         -1.4260e-01, -4.7337e-01, -5.0082e-01]])\n",
      "MyRBF received 2262 use_ard True\n",
      "acq_diff 0.0403900146484375\n",
      "acq_diff 0.038578033447265625\n",
      "acq_diff 0.026485443115234375\n",
      "acq_diff 0.019207000732421875\n",
      "acq_diff 0.025699615478515625\n",
      "acq_diff 0.0183868408203125\n",
      "acq_diff 0.018062591552734375\n",
      "acq_diff 0.01605224609375\n",
      "acq_diff 0.01554107666015625\n",
      "acq_diff 0.012176513671875\n",
      "acq_diff 0.014644622802734375\n",
      "acq_diff 0.01172637939453125\n",
      "acq_diff 0.0128936767578125\n",
      "acq_diff 0.01180267333984375\n",
      "breaking info gathering after 15 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([1.8595], requires_grad=True)\n",
      "inv hessian mean 8.769959449768066 gradient mean 0.006148593034595251 \n",
      "current 0.45211321115493774 / max 1.9555320739746094 /batch_mean 0.45211321115493774 /batch_max 0.45211321115493774 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean6.774403095245361                     covar_outputscale 1.1193647384643555                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.106099247932434\n",
      "grad_mean : max 8.952655792236328 /  min -0.6502304077148438\n",
      "grad_covar : max 4.28867769241333 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5066e+00, -3.2673e-02, -6.3105e-02, -3.7654e-02, -9.7809e-03,\n",
      "         -1.5917e-01, -1.6796e+00, -2.1550e+00, -2.0634e+00, -4.0627e-01,\n",
      "          1.4083e+00,  3.3821e-01, -8.3791e-02, -9.6479e-04, -7.1534e-02,\n",
      "         -8.6949e-03, -2.3709e-01,  6.0809e-02, -7.6144e-01, -2.4459e-01,\n",
      "         -7.0185e-01, -4.3062e-01, -1.0039e-01, -9.0146e-02,  1.4396e-02,\n",
      "         -6.1803e-02, -2.0887e-01, -5.3027e-01, -9.2008e-05, -9.8117e-01,\n",
      "         -1.4243e-01, -4.7348e-01, -4.7918e-01]])\n",
      "MyRBF received 2364 use_ard True\n",
      "acq_diff 0.0178680419921875\n",
      "acq_diff 0.01813507080078125\n",
      "acq_diff 0.019561767578125\n",
      "acq_diff 0.01305389404296875\n",
      "acq_diff 0.01129150390625\n",
      "acq_diff 0.0118865966796875\n",
      "acq_diff 0.01132965087890625\n",
      "acq_diff 0.01148223876953125\n",
      "acq_diff 0.01328277587890625\n",
      "breaking info gathering after 10 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([1.8377], requires_grad=True)\n",
      "inv hessian mean 9.047988891601562 gradient mean 0.011022723279893398 \n",
      "current 0.6029272079467773 / max 1.9611318111419678 /batch_mean 0.6029272079467773 /batch_max 0.6029272079467773 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean7.337801456451416                     covar_outputscale 3.4029998779296875                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.1712039709091187\n",
      "grad_mean : max 9.315669059753418 /  min -0.6607157588005066\n",
      "grad_covar : max 9.653153419494629 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5406e+00, -3.2868e-02, -6.3003e-02, -3.7606e-02, -1.0515e-02,\n",
      "         -1.6089e-01, -1.6995e+00, -2.1565e+00, -2.0632e+00, -4.0617e-01,\n",
      "          1.4110e+00,  3.5105e-01, -8.4916e-02, -9.2542e-04, -7.1516e-02,\n",
      "         -9.7673e-03, -2.3786e-01,  6.0629e-02, -7.6211e-01, -2.4459e-01,\n",
      "         -7.0183e-01, -4.3134e-01, -9.1547e-02, -8.8626e-02,  1.4406e-02,\n",
      "         -6.1987e-02, -2.0637e-01, -5.4253e-01,  4.8197e-02, -9.8933e-01,\n",
      "         -1.4258e-01, -4.7375e-01, -4.5834e-01]])\n",
      "MyRBF received 2589 use_ard True\n",
      "acq_diff 0.04006195068359375\n",
      "acq_diff 0.047576904296875\n",
      "acq_diff 0.01821136474609375\n",
      "acq_diff 0.02584075927734375\n",
      "acq_diff 0.02223968505859375\n",
      "acq_diff 0.025543212890625\n",
      "acq_diff 0.0153961181640625\n",
      "acq_diff 0.01866912841796875\n",
      "acq_diff 0.0116729736328125\n",
      "breaking info gathering after 10 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([1.7861], requires_grad=True)\n",
      "inv hessian mean 8.94097900390625 gradient mean 0.006933426018804312 \n",
      "current 0.5171958804130554 / max 1.9611318111419678 /batch_mean 0.5171958804130554 /batch_max 0.5171958804130554 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean7.250158309936523                     covar_outputscale 2.6076033115386963                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.2064517736434937\n",
      "grad_mean : max 10.610483169555664 /  min -0.755001425743103\n",
      "grad_covar : max 7.414711952209473 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5433e+00, -3.2776e-02, -6.2989e-02, -3.7603e-02, -1.0545e-02,\n",
      "         -1.6068e-01, -1.7024e+00, -2.1565e+00, -2.0634e+00, -4.0606e-01,\n",
      "          1.4116e+00,  3.5954e-01, -8.5622e-02, -8.9916e-04, -7.1504e-02,\n",
      "         -1.0444e-02, -2.3835e-01,  6.0505e-02, -7.6253e-01, -2.4459e-01,\n",
      "         -7.0182e-01, -4.3172e-01, -8.2130e-02, -8.9701e-02,  1.4369e-02,\n",
      "         -6.1949e-02, -2.0794e-01, -5.5379e-01,  5.3172e-02, -9.7856e-01,\n",
      "         -1.1891e-01, -4.7506e-01, -4.2621e-01]])\n",
      "MyRBF received 2799 use_ard True\n",
      "acq_diff 0.02149200439453125\n",
      "acq_diff 0.025299072265625\n",
      "acq_diff 0.01863861083984375\n",
      "acq_diff 0.01815032958984375\n",
      "acq_diff 0.01152801513671875\n",
      "acq_diff 0.0117950439453125\n",
      "acq_diff 0.01226043701171875\n",
      "breaking info gathering after 8 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([2.5006], requires_grad=True)\n",
      "inv hessian mean 8.981417655944824 gradient mean 0.0016338344430550933 \n",
      "current 0.505897045135498 / max 1.9642837047576904 /batch_mean 0.505897045135498 /batch_max 0.505897045135498 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean6.832468032836914                     covar_outputscale 1.7824187278747559                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.095615267753601\n",
      "grad_mean : max 13.381956100463867 /  min -1.1260169744491577\n",
      "grad_covar : max 6.420583248138428 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5384e+00, -3.2783e-02, -6.3012e-02, -3.7608e-02, -1.0443e-02,\n",
      "         -1.6051e-01, -1.7009e+00, -2.1565e+00, -2.0642e+00, -4.0517e-01,\n",
      "          1.4141e+00,  3.5897e-01, -8.5604e-02, -9.0090e-04, -7.1504e-02,\n",
      "         -1.0427e-02, -2.3832e-01,  6.0495e-02, -7.6250e-01, -2.4459e-01,\n",
      "         -7.0182e-01, -4.3168e-01, -7.5198e-02, -9.3340e-02,  1.4319e-02,\n",
      "         -6.1963e-02, -2.1129e-01, -5.5321e-01,  5.3485e-02, -9.7814e-01,\n",
      "         -1.1886e-01, -4.7504e-01, -4.2627e-01]])\n",
      "MyRBF received 3135 use_ard True\n",
      "acq_diff 0.018646240234375\n",
      "acq_diff 0.01345062255859375\n",
      "acq_diff 0.01305389404296875\n",
      "acq_diff 0.01216888427734375\n",
      "breaking info gathering after 5 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/fit.py:155: RuntimeWarning: Fitting failed on all retries.\n",
      "  warnings.warn(\"Fitting failed on all retries.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model mean constant Parameter containing:\n",
      "tensor([1.8170], requires_grad=True)\n",
      "inv hessian mean 9.295382499694824 gradient mean 0.003788116853684187 \n",
      "current 1.9618176221847534 / max 1.9671247005462646 /batch_mean 1.9618176221847534 /batch_max 1.9618176221847534 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean6.829844951629639                     covar_outputscale 2.5547869205474854                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 1.0449236631393433\n",
      "grad_mean : max 14.107845306396484 /  min -1.2165617942810059\n",
      "grad_covar : max 9.594395637512207 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5375e+00, -3.2662e-02, -6.3015e-02, -3.7609e-02, -1.0328e-02,\n",
      "         -1.6046e-01, -1.7009e+00, -2.1565e+00, -2.0641e+00, -4.0517e-01,\n",
      "          1.4141e+00,  3.6862e-01, -8.6386e-02, -8.7123e-04, -7.1490e-02,\n",
      "         -1.1175e-02, -2.3878e-01,  6.0346e-02, -7.6290e-01, -2.4458e-01,\n",
      "         -7.0182e-01, -4.3203e-01, -6.8713e-02, -9.8536e-02,  1.4301e-02,\n",
      "         -6.1935e-02, -2.1545e-01, -5.5254e-01,  7.9669e-02, -9.7765e-01,\n",
      "         -1.1915e-01, -4.7491e-01, -4.3121e-01]])\n",
      "MyRBF received 3354 use_ard True\n",
      "acq_diff 0.0294952392578125\n",
      "acq_diff 0.02294921875\n",
      "acq_diff 0.019927978515625\n",
      "acq_diff 0.01904296875\n",
      "acq_diff 0.021881103515625\n",
      "acq_diff 0.014801025390625\n",
      "acq_diff 0.010833740234375\n",
      "acq_diff 0.017547607421875\n",
      "breaking info gathering after 9 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([1.6239], requires_grad=True)\n",
      "inv hessian mean 9.173185348510742 gradient mean 0.010959256440401077 \n",
      "current 1.9632270336151123 / max 1.969209909439087 /batch_mean 1.9632270336151123 /batch_max 1.9632270336151123 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean7.036848068237305                     covar_outputscale 1.7814428806304932                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 0.9584058523178101\n",
      "grad_mean : max 14.783052444458008 /  min -1.3653135299682617\n",
      "grad_covar : max 6.786676406860352 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.5426e+00, -3.3076e-02, -6.2999e-02, -3.7602e-02, -1.0722e-02,\n",
      "         -1.6069e-01, -1.7009e+00, -2.1567e+00, -2.0641e+00, -4.0517e-01,\n",
      "          1.4139e+00,  3.3219e-01, -8.6735e-02, -9.3431e-04, -7.1585e-02,\n",
      "         -1.1501e-02, -2.4006e-01,  6.2684e-02, -7.8484e-01, -2.7081e-01,\n",
      "         -7.0106e-01, -4.2798e-01, -6.1124e-02, -1.0412e-01,  1.4278e-02,\n",
      "         -6.1878e-02, -2.2073e-01, -5.5016e-01,  7.6796e-02, -9.5344e-01,\n",
      "         -9.1203e-02, -4.7572e-01, -4.3479e-01]])\n",
      "MyRBF received 3720 use_ard True\n",
      "acq_diff 0.0383453369140625\n",
      "acq_diff 0.0306396484375\n",
      "acq_diff 0.0323028564453125\n",
      "acq_diff 0.0216064453125\n",
      "acq_diff 0.02325439453125\n",
      "breaking info gathering after 6 steps\n",
      "model mean constant Parameter containing:\n",
      "tensor([1.1064], requires_grad=True)\n",
      "inv hessian mean 8.978546142578125 gradient mean 0.023170433938503265 \n",
      "current 1.974410057067871 / max 1.985865831375122 /batch_mean 1.974410057067871 /batch_max 1.974410057067871 \n",
      "##############################\n",
      "covar_lengthscale max 10.0                     min 0.10000000149011612                      mean7.960759162902832                     covar_outputscale 3.499596118927002                     noise 0.009999999776482582\n",
      "##############################\n",
      "MLL : 0.7983715534210205\n",
      "grad_mean : max 13.926169395446777 /  min -1.0177979469299316\n",
      "grad_covar : max 9.0374116897583 /  min 9.999999717180685e-10\n",
      "theta_i tensor([[ 3.6166e+00, -3.2676e-02, -6.2721e-02, -3.7767e-02, -1.0628e-02,\n",
      "         -1.5768e-01, -1.7057e+00, -2.1415e+00, -2.0651e+00, -3.7116e-01,\n",
      "          1.4054e+00,  3.3613e-01, -8.7026e-02, -9.2200e-04, -7.1580e-02,\n",
      "         -1.1783e-02, -2.4022e-01,  6.2579e-02, -7.8498e-01, -2.7082e-01,\n",
      "         -7.0104e-01, -4.2807e-01, -4.3927e-02, -6.9602e-02,  1.4332e-02,\n",
      "         -6.1705e-02, -1.9018e-01, -5.5539e-01,  4.6194e-02, -9.1746e-01,\n",
      "         -3.4129e-02, -4.9038e-01, -4.4451e-01]])\n",
      "MyRBF received 4569 use_ard True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=47'>48</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GIBOptimizer(model,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=48'>49</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=49'>50</a>\u001b[0m rslt\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:58\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> 58\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m report_freq) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     62\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39my_hist\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:330\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo\u001b[39m.\u001b[39mupdate_theta_i(theta_i) \u001b[39m## this also update KxX_dx\u001b[39;00m\n\u001b[1;32m    329\u001b[0m bounds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta]]) \u001b[39m+\u001b[39m theta_i\n\u001b[0;32m--> 330\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_information(objective_env,model,bounds)\n\u001b[1;32m    332\u001b[0m \u001b[39m## NEEEW : Adjust hyperparameters after information collection for better gradient estimate\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_model_hypers(model)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:185\u001b[0m, in \u001b[0;36mGIBOptimizer.optimize_information\u001b[0;34m(self, objective_env, model, bounds)\u001b[0m\n\u001b[1;32m    173\u001b[0m model\u001b[39m.\u001b[39mposterior(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta_i)  \u001b[39m## hotfix\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[39m# new_x1,new_x2 = self.sample_noise(self.theta_i,seed=i)\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[39m# new_y1,new_s1,_ = objective_env(new_x1,self.n_eval)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39m# new_y2,new_s2,_ = objective_env(new_x2,self.n_eval)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39m# model.append_train_data(new_x2,new_y2, strict=False) ## right now we do not add new_s for info\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m# Update training points.\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m new_x,acq_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_acqf(bounds)\n\u001b[1;32m    186\u001b[0m new_y,new_s,_ \u001b[39m=\u001b[39m objective_env(new_x,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_eval)\n\u001b[1;32m    187\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mpolicy_return\u001b[39m\u001b[39m\"\u001b[39m:new_y})\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:151\u001b[0m, in \u001b[0;36mGIBOptimizer.sample_acqf\u001b[0;34m(self, bounds)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_acqf\u001b[39m(\u001b[39mself\u001b[39m,bounds):\n\u001b[1;32m    149\u001b[0m     \n\u001b[1;32m    150\u001b[0m     \u001b[39m# Optimize acquistion function and get new observation.\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     new_x, acq_value \u001b[39m=\u001b[39m botorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49moptimize_acqf(\n\u001b[1;32m    152\u001b[0m         acq_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradInfo,\n\u001b[1;32m    153\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    154\u001b[0m         q\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,  \u001b[39m# Analytic acquisition function.\u001b[39;49;00m\n\u001b[1;32m    155\u001b[0m         num_restarts\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m    156\u001b[0m         raw_samples\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m    157\u001b[0m         options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mnonnegative\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mbatch_limit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m5\u001b[39;49m},\n\u001b[1;32m    158\u001b[0m         return_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    159\u001b[0m         sequential\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    161\u001b[0m     \u001b[39mreturn\u001b[39;00m new_x,acq_value\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/optim/optimize.py:225\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m batched_ics \u001b[39m=\u001b[39m batch_initial_conditions\u001b[39m.\u001b[39msplit(batch_limit)\n\u001b[1;32m    223\u001b[0m \u001b[39mfor\u001b[39;00m i, batched_ics_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batched_ics):\n\u001b[1;32m    224\u001b[0m     \u001b[39m# optimize using random restart optimization\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m     batch_candidates_curr, batch_acq_values_curr \u001b[39m=\u001b[39m gen_candidates_scipy(\n\u001b[1;32m    226\u001b[0m         initial_conditions\u001b[39m=\u001b[39;49mbatched_ics_,\n\u001b[1;32m    227\u001b[0m         acquisition_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    228\u001b[0m         lower_bounds\u001b[39m=\u001b[39;49mbounds[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    229\u001b[0m         upper_bounds\u001b[39m=\u001b[39;49mbounds[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    230\u001b[0m         options\u001b[39m=\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m INIT_OPTION_KEYS},\n\u001b[1;32m    231\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    232\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    233\u001b[0m         nonlinear_inequality_constraints\u001b[39m=\u001b[39;49mnonlinear_inequality_constraints,\n\u001b[1;32m    234\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m     batch_candidates_list\u001b[39m.\u001b[39mappend(batch_candidates_curr)\n\u001b[1;32m    237\u001b[0m     batch_acq_values_list\u001b[39m.\u001b[39mappend(batch_acq_values_curr)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/generation/gen.py:202\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[1;32m    200\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39macquisition_function(x)\n\u001b[0;32m--> 202\u001b[0m res \u001b[39m=\u001b[39m minimize(\n\u001b[1;32m    203\u001b[0m     fun\u001b[39m=\u001b[39;49mf_np_wrapper,\n\u001b[1;32m    204\u001b[0m     args\u001b[39m=\u001b[39;49m(f,),\n\u001b[1;32m    205\u001b[0m     x0\u001b[39m=\u001b[39;49mx0,\n\u001b[1;32m    206\u001b[0m     method\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mSLSQP\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m constraints \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    207\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    208\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    209\u001b[0m     constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[1;32m    210\u001b[0m     callback\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    211\u001b[0m     options\u001b[39m=\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m]},\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    213\u001b[0m candidates \u001b[39m=\u001b[39m fix_features(\n\u001b[1;32m    214\u001b[0m     X\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfrom_numpy(res\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mto(initial_conditions)\u001b[39m.\u001b[39mreshape(shapeX),\n\u001b[1;32m    215\u001b[0m     fixed_features\u001b[39m=\u001b[39mfixed_features,\n\u001b[1;32m    216\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39m# SLSQP sometimes fails in the line search or may just fail to find a feasible\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[39m# candidate in which case we just return the starting point. This happens rarely,\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# so it shouldn't be an issue given enough restarts.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_minimize.py:692\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    689\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    690\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 692\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    693\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    694\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    695\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    696\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[1;32m    363\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    286\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/generation/gen.py:171\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f_np_wrapper\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    163\u001b[0m X \u001b[39m=\u001b[39m (\n\u001b[1;32m    164\u001b[0m     torch\u001b[39m.\u001b[39mfrom_numpy(x)\n\u001b[1;32m    165\u001b[0m     \u001b[39m.\u001b[39mto(initial_conditions)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    169\u001b[0m )\n\u001b[1;32m    170\u001b[0m X_fix \u001b[39m=\u001b[39m fix_features(X, fixed_features\u001b[39m=\u001b[39mfixed_features)\n\u001b[0;32m--> 171\u001b[0m loss \u001b[39m=\u001b[39m f(X_fix)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    172\u001b[0m \u001b[39m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m gradf \u001b[39m=\u001b[39m _arrayify(torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(loss, X)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/generation/gen.py:200\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf\u001b[39m(x):\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39macquisition_function(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/botorch/utils/transforms.py:258\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    257\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 258\u001b[0m output \u001b[39m=\u001b[39m method(acqf, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(acqf, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m is_fully_bayesian(acqf\u001b[39m.\u001b[39mmodel):\n\u001b[1;32m    260\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:98\u001b[0m, in \u001b[0;36mGradientInformation.forward\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     95\u001b[0m theta \u001b[39m=\u001b[39m theta\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, D)\n\u001b[1;32m     97\u001b[0m X_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([X,theta])\n\u001b[0;32m---> 98\u001b[0m K_XX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mcovar_module(X_hat,X_hat)\u001b[39m.\u001b[39;49mevaluate() \u001b[39m+\u001b[39m sigma_n \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39meye(X_hat\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     99\u001b[0m K_XX_inv \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(K_XX)\n\u001b[1;32m    101\u001b[0m \u001b[39m# get K_xX_dx\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:353\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m@cached\u001b[39m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate_kernel()\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/utils/memoize.py:59\u001b[0m, in \u001b[0;36m_cached.<locals>.g\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m kwargs_pkl \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mdumps(kwargs)\n\u001b[1;32m     58\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_in_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl):\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m _add_to_cache(\u001b[39mself\u001b[39m, cache_name, method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m _get_from_cache(\u001b[39mself\u001b[39m, cache_name, \u001b[39m*\u001b[39margs, kwargs_pkl\u001b[39m=\u001b[39mkwargs_pkl)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py:332\u001b[0m, in \u001b[0;36mLazyEvaluatedKernelTensor.evaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m     temp_active_dims \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims\n\u001b[1;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel(\n\u001b[1;32m    333\u001b[0m         x1,\n\u001b[1;32m    334\u001b[0m         x2,\n\u001b[1;32m    335\u001b[0m         diag\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    336\u001b[0m         last_dim_is_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_dim_is_batch,\n\u001b[1;32m    337\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams,\n\u001b[1;32m    338\u001b[0m     )\n\u001b[1;32m    339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel\u001b[39m.\u001b[39mactive_dims \u001b[39m=\u001b[39m temp_active_dims\n\u001b[1;32m    341\u001b[0m \u001b[39m# Check the size of the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/kernels/kernel.py:402\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    400\u001b[0m     res \u001b[39m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, last_dim_is_batch\u001b[39m=\u001b[39mlast_dim_is_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    401\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m     res \u001b[39m=\u001b[39m lazify(\u001b[39msuper\u001b[39;49m(Kernel, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(x1_, x2_, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams))\n\u001b[1;32m    403\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/module.py:30\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 30\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m outputs]\n",
      "File \u001b[0;32m~/Desktop/explo/src/kernels.py:215\u001b[0m, in \u001b[0;36mRBFStateKernel.forward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m    213\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma1 \u001b[39m\u001b[39m{\u001b[39;00ma1\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m a2 \u001b[39m\u001b[39m{\u001b[39;00ma2\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    214\u001b[0m \u001b[39m# Compute pairwise kernel \u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m kernel \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(a1\u001b[39m/\u001b[39;49mnorm, a2\u001b[39m/\u001b[39;49mnorm, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    216\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpair kernel \u001b[39m\u001b[39m{\u001b[39;00mkernel\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m kernel\n",
      "File \u001b[0;32m~/Desktop/explo/src/kernels.py:61\u001b[0m, in \u001b[0;36mMyRBFKernel.forward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x1,x2,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m     60\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mx1 \u001b[39m\u001b[39m{\u001b[39;00mx1\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m / x2 \u001b[39m\u001b[39m{\u001b[39;00mx2\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     rslt \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(x1,x2,\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m     62\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpair rslt \u001b[39m\u001b[39m{\u001b[39;00mrslt\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     63\u001b[0m     \u001b[39mreturn\u001b[39;00m rslt\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/kernels/scale_kernel.py:103\u001b[0m, in \u001b[0;36mScaleKernel.forward\u001b[0;34m(self, x1, x2, last_dim_is_batch, diag, **params)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x1, x2, last_dim_is_batch\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, diag\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 103\u001b[0m     orig_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_kernel\u001b[39m.\u001b[39;49mforward(x1, x2, diag\u001b[39m=\u001b[39;49mdiag, last_dim_is_batch\u001b[39m=\u001b[39;49mlast_dim_is_batch, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    104\u001b[0m     outputscales \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputscale\n\u001b[1;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m last_dim_is_batch:\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/kernels/rbf_kernel.py:82\u001b[0m, in \u001b[0;36mRBFKernel.forward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     74\u001b[0m     x1\u001b[39m.\u001b[39mrequires_grad\n\u001b[1;32m     75\u001b[0m     \u001b[39mor\u001b[39;00m x2\u001b[39m.\u001b[39mrequires_grad\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mor\u001b[39;00m trace_mode\u001b[39m.\u001b[39mon()\n\u001b[1;32m     80\u001b[0m ):\n\u001b[1;32m     81\u001b[0m     x1_ \u001b[39m=\u001b[39m x1\u001b[39m.\u001b[39mdiv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlengthscale)\n\u001b[0;32m---> 82\u001b[0m     x2_ \u001b[39m=\u001b[39m x2\u001b[39m.\u001b[39;49mdiv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlengthscale)\n\u001b[1;32m     83\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovar_dist(\n\u001b[1;32m     84\u001b[0m         x1_, x2_, square_dist\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, diag\u001b[39m=\u001b[39mdiag, dist_postprocess_func\u001b[39m=\u001b[39mpostprocess_rbf, postprocess\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m RBFCovariance\u001b[39m.\u001b[39mapply(\n\u001b[1;32m     87\u001b[0m     x1,\n\u001b[1;32m     88\u001b[0m     x2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m     ),\n\u001b[1;32m     93\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "#env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "env_name = \"Hopper-v2\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "additional_layers=[] ### can be empty or [8,7] for adding 2 layers with width 8,7 respectively\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":2, ## 3 for cartpole (very noisy)\n",
    "        ### for GIBO\n",
    "        \"n_max\":32, \n",
    "        \"n_info_samples\":16,\n",
    "        \"delta\":0.1, ## 0.01 for cartpole\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\": True,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "likelihood_config = {\n",
    "                \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.05),\n",
    "                \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.05)\n",
    "                }\n",
    "\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":True,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.2),\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(1,0,),\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.Interval(0.1,10),\n",
    "        #\"outputscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.4),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        }\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\":40, \n",
    "        \"report_freq\":1,\n",
    "        \"save_best\":False,\n",
    "        \"wandb_logger\":False,\n",
    "}\n",
    "\n",
    "model,objective_env = setup_experiment(env_config,kernel_config,likelihood_config,additional_layers)\n",
    "\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()\n",
    "\n",
    "### ADD LR SCHEDULAR  / FIX DISCRETIZATION ===> ENJOY WEEKEND :DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6e309fb2e0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = 2\n",
    "beta = 0.3\n",
    "x = np.linspace (0, 10, 200) \n",
    "y1 = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n",
    "plt.plot(x,y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
