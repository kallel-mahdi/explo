{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/envs/registration.py:415: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 23 2022 12:25:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla_bo import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "Using state normalization\n",
      "MyRBF received 16000 use_ard True\n",
      "fixing seed to  110\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/notebook/utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmahdikallel\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/wandb/sdk/lib/ipython.py:47: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/q123/Desktop/explo/wandb/run-20220716_123650-16yi21cw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mahdikallel/explo/runs/16yi21cw\" target=\"_blank\">Swimmer-v4rbfstate110a</a></strong> to <a href=\"https://wandb.ai/mahdikallel/explo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyRBF received 4000 use_ard True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gpytorch/lazy/lazy_tensor.py:1741: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acq_diff tensor(0.0075) n_info 4\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0569], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "acq_diff tensor(0.0002) n_info 3\n",
      "model mean constant Parameter containing:\n",
      "tensor([-0.0589], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0065], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0096], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "acq_diff tensor(3.1734e-05) n_info 3\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0590], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "acq_diff tensor(2.8298e-05) n_info 3\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.1135], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "acq_diff tensor(3.5030e-05) n_info 3\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0977], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "acq_diff tensor(0.0016) n_info 3\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0903], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n",
      "acq_diff tensor(0.0016) n_info 3\n",
      "model mean constant Parameter containing:\n",
      "tensor([0.0861], requires_grad=True)\n",
      "MyRBF received 4000 use_ard True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=58'>59</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GIBOptimizer(model,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=59'>60</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=60'>61</a>\u001b[0m rslt\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:60\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> 60\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m report_freq) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     64\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39my_hist\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:345\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo\u001b[39m.\u001b[39mupdate_theta_i(theta_i) \u001b[39m## this also update KxX_dx\u001b[39;00m\n\u001b[1;32m    344\u001b[0m bounds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta]]) \u001b[39m+\u001b[39m theta_i\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_information(objective_env,model,bounds)\n\u001b[1;32m    347\u001b[0m \u001b[39m## NEEEW : Adjust hyperparameters after information collection for better gradient estimate\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_model_hypers(model)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:189\u001b[0m, in \u001b[0;36mGIBOptimizer.optimize_information\u001b[0;34m(self, objective_env, model, bounds)\u001b[0m\n\u001b[1;32m    186\u001b[0m new_y,new_s,_ \u001b[39m=\u001b[39m objective_env(new_x,\u001b[39m1\u001b[39m)\n\u001b[1;32m    188\u001b[0m \u001b[39m### log the real return (not noisy)\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m j,_,_ \u001b[39m=\u001b[39m objective_env(new_x,\u001b[39m5\u001b[39;49m)\n\u001b[1;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples,{\u001b[39m\"\u001b[39m\u001b[39mpolicy_return\u001b[39m\u001b[39m\"\u001b[39m:j})\n\u001b[1;32m    191\u001b[0m \u001b[39m##############################\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/explo/src/environments/objective.py:63\u001b[0m, in \u001b[0;36mEnvironmentObjective.__call__\u001b[0;34m(self, params, n_episodes)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, params,n_episodes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) :\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_many(params,n_episodes)\n",
      "File \u001b[0;32m~/Desktop/explo/src/environments/objective.py:151\u001b[0m, in \u001b[0;36mEnvironmentObjective.run_many\u001b[0;34m(self, params, n_episodes)\u001b[0m\n\u001b[1;32m    147\u001b[0m all_states,all_transitions \u001b[39m=\u001b[39m [],[]\n\u001b[1;32m    149\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_episodes):\n\u001b[0;32m--> 151\u001b[0m    reward,states,transitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(params)\n\u001b[1;32m    153\u001b[0m    rewards \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m    154\u001b[0m    all_states\u001b[39m.\u001b[39mappend(states)\n",
      "File \u001b[0;32m~/Desktop/explo/src/environments/objective.py:132\u001b[0m, in \u001b[0;36mEnvironmentObjective.run\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    129\u001b[0m dones \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(dones)\n\u001b[1;32m    130\u001b[0m lasts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(lasts)\n\u001b[0;32m--> 132\u001b[0m transitions \u001b[39m=\u001b[39m [\n\u001b[1;32m    133\u001b[0m                 (s1\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    134\u001b[0m                 a\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    135\u001b[0m                 r\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    136\u001b[0m                 s2\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    137\u001b[0m                 d\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    138\u001b[0m                 l\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),) \n\u001b[1;32m    139\u001b[0m                \u001b[39mfor\u001b[39;00m s1,a,r,s2,d,l \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(states,actions,rewards,next_states,dones,lasts)\n\u001b[1;32m    140\u001b[0m                ] \n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msum(rewards),states,transitions\n",
      "File \u001b[0;32m~/Desktop/explo/src/environments/objective.py:138\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m dones \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(dones)\n\u001b[1;32m    130\u001b[0m lasts \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(lasts)\n\u001b[1;32m    132\u001b[0m transitions \u001b[39m=\u001b[39m [\n\u001b[1;32m    133\u001b[0m                 (s1\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    134\u001b[0m                 a\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    135\u001b[0m                 r\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    136\u001b[0m                 s2\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[1;32m    137\u001b[0m                 d\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy(),\n\u001b[0;32m--> 138\u001b[0m                 l\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39mnumpy(),) \n\u001b[1;32m    139\u001b[0m                \u001b[39mfor\u001b[39;00m s1,a,r,s2,d,l \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(states,actions,rewards,next_states,dones,lasts)\n\u001b[1;32m    140\u001b[0m                ] \n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39msum(rewards),states,transitions\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = 110\n",
    "\n",
    "#env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "#env_name = \"Hopper-v2\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":2, ## 3 for cartpole (very noisy)\n",
    "        ### for GIBO\n",
    "        \"n_max\":32, \n",
    "        \"n_info_samples\":16,\n",
    "        \"delta\":0.1, ## 0.01 for cartpole\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\": True,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "\n",
    "likelihood_config = {\n",
    "                \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.05),\n",
    "                \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.05)\n",
    "                }\n",
    "\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":True,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.2),\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(1,0,),\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.Interval(0.1,10),\n",
    "        #\"outputscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.4),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        }\n",
    "\n",
    "policy_config = {\n",
    "        \"add_layer\":[],### can be empty or [8,7] for adding 2 layers with width 8,7  neurons respectively\n",
    "        \"add_bias\":False,\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\":100, \n",
    "        \"report_freq\":10,\n",
    "        \"save_best\":False,\n",
    "        \"wandb_logger\":True,\n",
    "        \"run_name\" : env_name+kernel_name+str(seed)+\"a\",\n",
    "        \"wandb_config\": {**optimizer_config,**likelihood_config,**kernel_config,**policy_config}\n",
    "}\n",
    "\n",
    "\n",
    "model,objective_env = setup_experiment(env_config,kernel_config,likelihood_config,policy_config,\n",
    "                                       seed=seed)\n",
    "\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()\n",
    "\n",
    "### ADD LR SCHEDULAR  / FIX DISCRETIZATION ===> ENJOY WEEKEND :DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alpha = 2\n",
    "beta = 0.3\n",
    "x = np.linspace (0, 10, 200) \n",
    "y1 = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n",
    "plt.plot(x,y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
