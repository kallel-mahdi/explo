{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/envs/registration.py:415: UserWarning: \u001b[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001b[0m\n",
      "  logger.warn(\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "pybullet build time: Jun 23 2022 12:25:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla_bo import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()\n",
    "print(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [11, 3]\n",
      "Using state normalization\n",
      "fixing seed to  21\n",
      " Gibo will use 32 last points to fit GP and 16 info samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 21\n",
    "#env_name = \"CartPole-v1\" ## Action kernel + State_norm looks very well for cartpole\n",
    "#env_name = \"Swimmer-v4\" ##  State_norm stabilizes training \n",
    "env_name = \"Hopper-v2\"\n",
    "#env_name = \"Walker2d-v3\"\n",
    "kernel_name = \"rbfstate\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,mean_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "env_config[\"manipulate_state\"] = True\n",
    "\n",
    "optimizer_config = {\n",
    "        \"n_eval\":2, ## 3 for cartpole (very noisy)\n",
    "        ### for GIBO\n",
    "        \"n_max\":32, \n",
    "        \"n_info_samples\":16,\n",
    "        \"delta\":0.1, ## 0.01 for cartpole\n",
    "        ### hessian normalisation applies only for rbf\n",
    "        \"normalize_gradient\": True,\n",
    "        \"standard_deviation_scaling\":False,\n",
    "}\n",
    "\n",
    "\n",
    "likelihood_config = {\n",
    "                \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.05),\n",
    "                \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.05)\n",
    "                }\n",
    "\n",
    "\n",
    "kernel_config = {\n",
    "        \"use_ard\":True,\n",
    "        \"kernel_name\":kernel_name,\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.2),\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(1,0,),\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.Interval(0.1,10),\n",
    "        #\"outputscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(2,0.4),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.01),\n",
    "        }\n",
    "\n",
    "mean_config = {\n",
    "                \"advantage\":True,\n",
    "        }\n",
    "\n",
    "\n",
    "policy_config = {\n",
    "        \"add_layer\":[],### can be empty or [8,7] for adding 2 layers with width 8,7  neurons respectively\n",
    "        \"add_bias\":False,\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\":1000, \n",
    "        \"report_freq\":100,\n",
    "        \"save_best\":False,\n",
    "        \"wandb_logger\":False,\n",
    "        \"run_name\" : env_name+kernel_name+str(seed),\n",
    "        \"wandb_config\": {**env_config,**optimizer_config,**likelihood_config,**kernel_config,**policy_config}\n",
    "}\n",
    "\n",
    "\n",
    "model,objective_env = setup_experiment(env_config,mean_config,kernel_config,likelihood_config,policy_config,\n",
    "                                seed=seed)\n",
    "\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "#rslt= trainer.run()\n",
    "\n",
    "### ADD LR SCHEDULAR  / FIX DISCRETIZATION ===> ENJOY WEEKEND :DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in objective_env.mlp.parameters():\n",
    "#     print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000002?line=0'>1</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39m133\u001b[39m),requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000002?line=1'>2</a>\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mmean_module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000002?line=3'>4</a>\u001b[0m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(output,\u001b[39minput\u001b[39m,allow_unused\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/explo/src/means.py:72\u001b[0m, in \u001b[0;36mAdvantageMean.__call__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m,params):\n\u001b[1;32m     68\u001b[0m     agent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic_agent \n\u001b[0;32m---> 72\u001b[0m     local_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactor_mlp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_params,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocal_states)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mT\n\u001b[1;32m     73\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactor_mlp(params,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_states)\u001b[39m.\u001b[39msqueeze()\u001b[39m.\u001b[39mT\n\u001b[1;32m     75\u001b[0m     local_q \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39m_critic_approximator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_states, local_actions, output_tensor\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39magent\u001b[39m.\u001b[39m_critic_predict_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/boptim/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/explo/src/approximators/actor.py:94\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, params, states)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,params,states):\n\u001b[1;32m     91\u001b[0m     \n\u001b[1;32m     92\u001b[0m     \u001b[39m#logger.debug(f'params {params.shape} states {states.shape}')\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     weights,biases \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_weights(params)\n\u001b[1;32m     95\u001b[0m     outputs \u001b[39m=\u001b[39m states\u001b[39m.\u001b[39mT\n\u001b[1;32m     97\u001b[0m     \u001b[39mfor\u001b[39;00m i,(w,b) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m     98\u001b[0m                         \u001b[39mzip\u001b[39m(weights,biases)\n\u001b[1;32m     99\u001b[0m                         ):\n",
      "File \u001b[0;32m~/Desktop/explo/src/approximators/actor.py:71\u001b[0m, in \u001b[0;36mMLP.create_weights\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     69\u001b[0m start \u001b[39m=\u001b[39m deepcopy(end)\n\u001b[1;32m     70\u001b[0m end   \u001b[39m=\u001b[39m deepcopy(start)  \u001b[39m+\u001b[39m (in_size \u001b[39m*\u001b[39m out_size)\n\u001b[0;32m---> 71\u001b[0m weight \u001b[39m=\u001b[39m params[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m,start:end]\u001b[39m.\u001b[39mreshape(\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],out_size,in_size)\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_bias:\n\u001b[1;32m     75\u001b[0m     bias \u001b[39m=\u001b[39m params[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,end:end\u001b[39m+\u001b[39mout_size]\u001b[39m.\u001b[39mreshape(\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],out_size)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "input = torch.zeros((133),requires_grad=True)\n",
    "output = model.mean_module(input)\n",
    "\n",
    "torch.autograd.grad(output,input,allow_unused=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0179])\n",
      "local_q torch.Size([94]) q torch.Size([94])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/mushroom_rl/approximators/parametric/torch_approximator.py:166: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0179], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent = create_agent(objective_env)\n",
    "Adv_mean = AdvantageMean(agent,objective_env.mlp)\n",
    "\n",
    "\n",
    "local_params = torch.rand(1,33)\n",
    "local_mean,local_states,local_transitions = objective_env.run_many(agent._actor_approximator,5)\n",
    "print(local_mean)\n",
    "Adv_mean.set_train_data(local_mean,local_states,local_transitions,local_params)\n",
    "Adv_mean(local_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Object' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmushroom_rl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparameters\u001b[39;00m \u001b[39mimport\u001b[39;00m Parameter, to_parameter\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=12'>13</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCritic\u001b[39;00m(Object):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=15'>16</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,state_size,action_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=17'>18</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_critic_fit_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Object' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mushroom_rl.algorithms.actor_critic.deep_actor_critic import DeepAC\n",
    "from mushroom_rl.policy import Policy\n",
    "from mushroom_rl.approximators import Regressor\n",
    "from mushroom_rl.approximators.parametric import TorchApproximator\n",
    "from mushroom_rl.utils.replay_memory import ReplayMemory\n",
    "from mushroom_rl.utils.parameters import Parameter, to_parameter\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Critic(Object):\n",
    "    \n",
    "    \n",
    "    def __init__(self,state_size,action_size):\n",
    "\n",
    "        self._critic_fit_params = dict()\n",
    "        self._critic_predict_params = dict()\n",
    "        self._replay_memory = ReplayMemory(initial_replay_size, max_replay_size)\n",
    "\n",
    "        target_critic_params = deepcopy(critic_params)\n",
    "        self._critic_approximator = Regressor(TorchApproximator,\n",
    "                                                **critic_params)\n",
    "        self._target_critic_approximator = Regressor(TorchApproximator,\n",
    "                                                        **target_critic_params)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "        self._init_target(self._critic_approximator,\n",
    "                          self._target_critic_approximator)\n",
    "        self._init_target(self._actor_approximator,\n",
    "                          self._target_actor_approximator)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=2'>3</a>\u001b[0m weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m4\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=4'>5</a>\u001b[0m rslt \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, weight\u001b[39m=\u001b[39;49mweight)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000005?line=5'>6</a>\u001b[0m rslt\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "weight = torch.rand(4,4,4)\n",
    "input = torch.rand(4)\n",
    "rslt = F.linear(input=input, weight=weight)\n",
    "rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as stats \n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# alpha = 2\n",
    "# beta = 0.3\n",
    "# x = np.linspace (0, 10, 200) \n",
    "# y1 = stats.gamma.pdf(x, a=alpha, scale=1/beta)\n",
    "# plt.plot(x,y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
