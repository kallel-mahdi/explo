{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import gpytorch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.optimizers.gibo import GIBOptimizer\n",
    "from src.optimizers.vanilla import BOptimizer\n",
    "from src.config import get_configs\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [4, 1]\n",
      "Using ard_num_dims = 5\n",
      " Gibo will use 20 last points to fit GP and 8 info samples\n",
      "current 0.4500005543231964 / max 0.9999942183494568 /batch_mean 0.28920021653175354 /batch_max 0.5400001406669617 \n",
      "##############################\n",
      "covar_lengthscale max 0.3203306496143341 / min 0.3203306496143341                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([-0.0349,  0.1669, -0.0599,  0.5277, -0.0721])\n",
      "MLL : -0.3369414210319519\n",
      "current 0.7619972825050354 / max 0.9999942183494568 /batch_mean 0.887995719909668 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.29277071356773376 / min 0.29277071356773376                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([0.1404, 0.3328, 0.3607, 0.4391, 0.0841])\n",
      "MLL : -0.3768572509288788\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.9353950619697571 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.30298933386802673 / min 0.30298933386802673                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([-0.0013,  0.5152,  0.6976,  0.4958,  0.0790])\n",
      "MLL : -0.34970909357070923\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.9867943525314331 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.3541630804538727 / min 0.3541630804538727                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([-0.0336,  0.5347,  0.4691,  0.5757, -0.0504])\n",
      "MLL : -0.2159709930419922\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.9487948417663574 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.34796130657196045 / min 0.34796130657196045                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([0.0220, 0.5112, 0.5695, 0.6560, 0.1291])\n",
      "MLL : -0.24311400949954987\n",
      "current 0.48800063133239746 / max 0.9999942183494568 /batch_mean 0.893995463848114 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.3411375880241394 / min 0.3411375880241394                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([-0.0361,  0.2650,  0.7857,  0.5131, -0.1122])\n",
      "MLL : -0.3448990285396576\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.9865943789482117 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.3330928087234497 / min 0.3330928087234497                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([ 0.2171,  0.4497,  0.6388,  0.6811, -0.1425])\n",
      "MLL : -0.30784282088279724\n",
      "current 0.8919956088066101 / max 0.9999942183494568 /batch_mean 0.8539959788322449 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.3452456593513489 / min 0.3452456593513489                      covar_outputscale 0.010000034235417843                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([-0.0511,  0.4219,  0.7281,  0.7174,  0.0800])\n",
      "MLL : -0.28864726424217224\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.999994158744812 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.3455601632595062 / min 0.3455601632595062                      covar_outputscale 0.01000017300248146                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([ 0.0744,  0.2705,  0.9070,  0.5662, -0.0781])\n",
      "MLL : -0.29160332679748535\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.9749945402145386 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.35419994592666626 / min 0.35419994592666626                      covar_outputscale 0.01000017300248146                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([ 0.0476,  0.2858,  0.9318,  0.6616, -0.0879])\n",
      "MLL : -0.21982911229133606\n",
      "current 0.9999942183494568 / max 0.9999942183494568 /batch_mean 0.9051947593688965 /batch_max 0.9999942183494568 \n",
      "##############################\n",
      "covar_lengthscale max 0.2652176320552826 / min 0.2652176320552826                      covar_outputscale 0.01000017300248146                     noise 0.20000006258487701\n",
      "##############################\n",
      "last parameters tensor([ 0.2892,  0.3286,  0.9311,  0.5408, -0.1340])\n",
      "MLL : -0.44847798347473145\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/trainer.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=15'>16</a>\u001b[0m optimizer \u001b[39m=\u001b[39m GIBOptimizer(model,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_config)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrainer_config)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/trainer.ipynb#ch0000001?line=17'>18</a>\u001b[0m rslt\u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:33\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=28'>29</a>\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=30'>31</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=32'>33</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=34'>35</a>\u001b[0m     \u001b[39mif\u001b[39;00m (i \u001b[39m%\u001b[39m report_freq) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=36'>37</a>\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39my_hist\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:193\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=190'>191</a>\u001b[0m \u001b[39m# Sample locally to optimize gradient information\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=191'>192</a>\u001b[0m bounds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta]]) \u001b[39m+\u001b[39m theta_i\n\u001b[0;32m--> <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=192'>193</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_information(objective_env,model,bounds)\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=194'>195</a>\u001b[0m \u001b[39m##############################################\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=195'>196</a>\u001b[0m \u001b[39m### NEW Second step of fitting hyperparameters\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=196'>197</a>\u001b[0m mll \u001b[39m=\u001b[39m ExactMarginalLogLikelihood(model\u001b[39m.\u001b[39mlikelihood, model)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:133\u001b[0m, in \u001b[0;36mGIBOptimizer.optimize_information\u001b[0;34m(self, objective_env, model, bounds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=129'>130</a>\u001b[0m model\u001b[39m.\u001b[39mposterior(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta_i)  \u001b[39m## hotfix\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=131'>132</a>\u001b[0m \u001b[39m# Optimize acquistion function and get new observation.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=132'>133</a>\u001b[0m new_x, _ \u001b[39m=\u001b[39m botorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49moptimize_acqf(\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=133'>134</a>\u001b[0m     acq_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradInfo,\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=134'>135</a>\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=135'>136</a>\u001b[0m     q\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,  \u001b[39m# Analytic acquisition function.\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=136'>137</a>\u001b[0m     num_restarts\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=137'>138</a>\u001b[0m     raw_samples\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m,\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=138'>139</a>\u001b[0m     options\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mnonnegative\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m, \u001b[39m'\u001b[39;49m\u001b[39mbatch_limit\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m5\u001b[39;49m},\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=139'>140</a>\u001b[0m     return_best_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=140'>141</a>\u001b[0m     sequential\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=142'>143</a>\u001b[0m \u001b[39m# Update training points.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=143'>144</a>\u001b[0m new_y,new_s \u001b[39m=\u001b[39m objective_env(new_x,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_eval)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py:205\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=195'>196</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=196'>197</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMust specify `raw_samples` when `batch_initial_conditions` is `None`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=197'>198</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=199'>200</a>\u001b[0m     ic_gen \u001b[39m=\u001b[39m (\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=200'>201</a>\u001b[0m         gen_one_shot_kg_initial_conditions\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=201'>202</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(acq_function, qKnowledgeGradient)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=202'>203</a>\u001b[0m         \u001b[39melse\u001b[39;00m gen_batch_initial_conditions\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=203'>204</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=204'>205</a>\u001b[0m     batch_initial_conditions \u001b[39m=\u001b[39m ic_gen(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=205'>206</a>\u001b[0m         acq_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=206'>207</a>\u001b[0m         bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=207'>208</a>\u001b[0m         q\u001b[39m=\u001b[39;49mq,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=208'>209</a>\u001b[0m         num_restarts\u001b[39m=\u001b[39;49mnum_restarts,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=209'>210</a>\u001b[0m         raw_samples\u001b[39m=\u001b[39;49mraw_samples,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=210'>211</a>\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=211'>212</a>\u001b[0m         options\u001b[39m=\u001b[39;49moptions,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=212'>213</a>\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=213'>214</a>\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=214'>215</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=216'>217</a>\u001b[0m batch_limit: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mget(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=217'>218</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbatch_limit\u001b[39m\u001b[39m\"\u001b[39m, num_restarts \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nonlinear_inequality_constraints \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=218'>219</a>\u001b[0m )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/optimize.py?line=219'>220</a>\u001b[0m batch_candidates_list: List[Tensor] \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py:183\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=180'>181</a>\u001b[0m \u001b[39mwhile\u001b[39;00m start_idx \u001b[39m<\u001b[39m X_rnd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=181'>182</a>\u001b[0m     end_idx \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start_idx \u001b[39m+\u001b[39m batch_limit, X_rnd\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=182'>183</a>\u001b[0m     Y_rnd_curr \u001b[39m=\u001b[39m acq_function(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=183'>184</a>\u001b[0m         X_rnd[start_idx:end_idx]\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=184'>185</a>\u001b[0m     )\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=185'>186</a>\u001b[0m     Y_rnd_list\u001b[39m.\u001b[39mappend(Y_rnd_curr)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/initializers.py?line=186'>187</a>\u001b[0m     start_idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_limit\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py:258\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=255'>256</a>\u001b[0m \u001b[39m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=256'>257</a>\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=257'>258</a>\u001b[0m output \u001b[39m=\u001b[39m method(acqf, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=258'>259</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(acqf, \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m is_fully_bayesian(acqf\u001b[39m.\u001b[39mmodel):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/utils/transforms.py?line=259'>260</a>\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/explo/src/optimizers/gibo.py:92\u001b[0m, in \u001b[0;36mGradientInformation.forward\u001b[0;34m(self, thetas)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=88'>89</a>\u001b[0m theta \u001b[39m=\u001b[39m theta\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, D)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=90'>91</a>\u001b[0m X_hat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([X,theta])\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=91'>92</a>\u001b[0m K_XX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mcovar_module(X_hat,X_hat)\u001b[39m.\u001b[39mevaluate() \u001b[39m+\u001b[39m sigma_n \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39meye(X_hat\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=92'>93</a>\u001b[0m K_XX_inv \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(K_XX)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/optimizers/gibo.py?line=94'>95</a>\u001b[0m \u001b[39m# get K_xX_dx\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:399\u001b[0m, in \u001b[0;36mKernel.__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=395'>396</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=397'>398</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=398'>399</a>\u001b[0m     \u001b[39mif\u001b[39;00m settings\u001b[39m.\u001b[39;49mlazily_evaluate_kernels\u001b[39m.\u001b[39;49mon():\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=399'>400</a>\u001b[0m         res \u001b[39m=\u001b[39m LazyEvaluatedKernelTensor(x1_, x2_, kernel\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, last_dim_is_batch\u001b[39m=\u001b[39mlast_dim_is_batch, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=400'>401</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/settings.py:23\u001b[0m, in \u001b[0;36m_feature_flag.on\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/settings.py?line=20'>21</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/settings.py?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/settings.py?line=22'>23</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mis_default():\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/settings.py?line=23'>24</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_default\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/settings.py?line=24'>25</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_state\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "kernel_name = \"rbf\" ## \"linearstate\" /\"rbfstate\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "additional_layers=[] ### can be empty or [8,7] for adding 2 layers with width 8,7 respectively\n",
    "model,objective_env = setup_experiment(env_config,kernel_config,likelihood_config,additional_layers)\n",
    "\n",
    "trainer_config = {\n",
    "        \"n_steps\" :200,\n",
    "        \"report_freq\":10,\n",
    "        \"save_best\":False,\n",
    "}\n",
    "\n",
    "### Chose optimizer \n",
    "#optimizer = BOptimizer(**optimizer_config)\n",
    "optimizer = GIBOptimizer(model,**optimizer_config)\n",
    "trainer = Trainer(model,objective_env,optimizer,**trainer_config)\n",
    "rslt= trainer.run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
