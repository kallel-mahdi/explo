{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.config import insertion_config,insert\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.gibo.optim import GIBOptimizer\n",
    "from src.optim import BOptimizer\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Swimmer-v2\"\n",
    "kernel_name = \"rbf\"\n",
    "n_init = 2\n",
    "n_steps = 200\n",
    "\n",
    "\n",
    "import gpytorch \n",
    "\n",
    "model_config = {\n",
    "        \"prior_mean\":0,\n",
    "        \"ard_num_dims\":18,\n",
    "        \"N_max\":32,\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=1,b=5),\n",
    "        \"lengthscale_hyperprior\":gpytorch.priors.torch_priors.GammaPrior(3.0,6.0),\n",
    "        \"lengthscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.001),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.001),\n",
    "        \"outputscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        \"noise_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.3),\n",
    "        \"noise_constraint\":gpytorch.constraints.constraints.Interval(0.01,0.3),\n",
    "        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment Swimmer-v2 is out of date. You should consider upgrading to version `v3` with the environment ID `Swimmer-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "         0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 2.0                 noise 0.1550000160932541\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3750, 0.2560, 0.2695, 0.3779, 0.3430, 0.3626, 0.3143, 0.3766, 0.3659,\n",
      "         0.2776, 0.3389, 0.3452, 0.3818, 0.3636, 0.2714, 0.3586, 0.3661, 0.3581]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.00952508207410574                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3764, 0.3330, 0.3355, 0.3908, 0.2994, 0.4135, 0.2215, 0.3445, 0.4160,\n",
      "         0.2563, 0.4061, 0.4204, 0.4533, 0.4137, 0.1493, 0.4329, 0.4365, 0.3403]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.013473019003868103                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3147, 0.2714, 0.2855, 0.3927, 0.3348, 0.4263, 0.3104, 0.3097, 0.4233,\n",
      "         0.3661, 0.3992, 0.4249, 0.4143, 0.4332, 0.3890, 0.4811, 0.3232, 0.0834]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.01623740792274475                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.2436, 0.4190, 0.4373, 0.4123, 0.3684, 0.4566, 0.4278, 0.3711, 0.4897,\n",
      "         0.3601, 0.4852, 0.5324, 0.4940, 0.2648, 0.1890, 0.4477, 0.3480, 0.0619]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.035292766988277435                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4198, 0.2235, 0.3905, 0.5094, 0.1828, 0.4191, 0.3892, 0.4751, 0.5045,\n",
      "         0.4440, 0.5195, 0.4123, 0.4054, 0.1316, 0.1667, 0.1643, 0.3392, 0.3999]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.05218547582626343                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4269, 0.2634, 0.4183, 0.5173, 0.1970, 0.4637, 0.3285, 0.2854, 0.4146,\n",
      "         0.4026, 0.5041, 0.3587, 0.4446, 0.2711, 0.1477, 0.1004, 0.4137, 0.3920]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.04575513303279877                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4134, 0.3043, 0.1445, 0.4777, 0.3770, 0.1959, 0.0812, 0.0962, 0.4419,\n",
      "         0.3795, 0.4369, 0.3732, 0.4304, 0.3721, 0.3753, 0.3514, 0.4490, 0.3636]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.030610809102654457                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3829, 0.4239, 0.1575, 0.4738, 0.3350, 0.2346, 0.1822, 0.2454, 0.4762,\n",
      "         0.4729, 0.3881, 0.1727, 0.4650, 0.3936, 0.3720, 0.3724, 0.4508, 0.2585]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.031760476529598236                 noise 0.010000010021030903\n",
      "##############################\n",
      "current 0.8077019453048706 / max 1.0158069133758545 /batch_mean 0.8602601289749146 /batch_max 1.009911298751831 \n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4753, 0.4064, 0.3522, 0.2330, 0.4248, 0.2538, 0.3862, 0.2596, 0.4622,\n",
      "         0.4425, 0.4587, 0.3460, 0.4410, 0.1440, 0.3327, 0.3808, 0.1513, 0.1211]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.05996720492839813                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4753, 0.4064, 0.3522, 0.2330, 0.4248, 0.2538, 0.3862, 0.2596, 0.4622,\n",
      "         0.4425, 0.4587, 0.3460, 0.4410, 0.1440, 0.3327, 0.3808, 0.1513, 0.1211]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.05996720492839813                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3475, 0.4425, 0.3906, 0.4873, 0.4474, 0.4000, 0.2922, 0.1913, 0.5215,\n",
      "         0.4461, 0.4860, 0.4688, 0.1590, 0.1760, 0.2393, 0.1232, 0.2922, 0.3772]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.06043408811092377                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.2939, 0.4862, 0.4598, 0.4822, 0.4839, 0.4051, 0.3981, 0.3507, 0.5017,\n",
      "         0.3998, 0.4839, 0.4833, 0.1554, 0.1397, 0.3820, 0.1647, 0.1671, 0.4184]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.052606455981731415                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4021, 0.5006, 0.2248, 0.4754, 0.2321, 0.1665, 0.4164, 0.4522, 0.3037,\n",
      "         0.3619, 0.4427, 0.5137, 0.1034, 0.3719, 0.2027, 0.2751, 0.3909, 0.4839]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.04482611268758774                 noise 0.010000010021030903\n",
      "##############################\n",
      "root : DEBUG : Fitting failed on try 1.\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4033, 0.4404, 0.1990, 0.4906, 0.1936, 0.1231, 0.4035, 0.2227, 0.3219,\n",
      "         0.4270, 0.4171, 0.5077, 0.3596, 0.4341, 0.1409, 0.3071, 0.4336, 0.4992]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.03025086782872677                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.4013, 0.3608, 0.3691, 0.4098, 0.1113, 0.3264, 0.3305, 0.1024, 0.3201,\n",
      "         0.4148, 0.4060, 0.4140, 0.3631, 0.4264, 0.2174, 0.1381, 0.4479, 0.4200]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.020319916307926178                 noise 0.010000010021030903\n",
      "##############################\n",
      "root : DEBUG : Fitting failed on try 1.\n",
      "root : DEBUG : Fitting failed on try 2.\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3944, 0.2690, 0.3862, 0.3943, 0.3282, 0.3518, 0.3770, 0.0838, 0.3863,\n",
      "         0.4051, 0.3975, 0.4138, 0.3743, 0.4113, 0.3552, 0.1274, 0.4111, 0.3739]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.005928860045969486                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3726, 0.2848, 0.3701, 0.3686, 0.3111, 0.3502, 0.3473, 0.3378, 0.3608,\n",
      "         0.3498, 0.3580, 0.3528, 0.3788, 0.3692, 0.2208, 0.1141, 0.3450, 0.3551]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.003208579495549202                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3367, 0.3347, 0.3386, 0.3386, 0.3175, 0.3257, 0.3347, 0.2826, 0.3396,\n",
      "         0.3263, 0.3406, 0.3255, 0.3262, 0.3394, 0.2799, 0.3333, 0.3361, 0.3345]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3435, 0.3302, 0.3423, 0.3359, 0.3337, 0.3168, 0.3319, 0.2841, 0.3442,\n",
      "         0.3198, 0.3421, 0.3339, 0.3349, 0.3435, 0.2735, 0.3365, 0.3360, 0.3330]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "current 0.8895798921585083 / max 1.0300089120864868 /batch_mean 0.865129292011261 /batch_max 1.0016765594482422 \n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3534, 0.3080, 0.2682, 0.2441, 0.2907, 0.2810, 0.3212, 0.3206, 0.3394,\n",
      "         0.3469, 0.3417, 0.3467, 0.3328, 0.2998, 0.3499, 0.3440, 0.3488, 0.3383]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3534, 0.3080, 0.2682, 0.2441, 0.2907, 0.2810, 0.3212, 0.3206, 0.3394,\n",
      "         0.3469, 0.3417, 0.3467, 0.3328, 0.2998, 0.3499, 0.3440, 0.3488, 0.3383]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3468, 0.3163, 0.2641, 0.2360, 0.2266, 0.3326, 0.2840, 0.3305, 0.3380,\n",
      "         0.3468, 0.3596, 0.3567, 0.3471, 0.3228, 0.3553, 0.3473, 0.3474, 0.3401]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3356, 0.2982, 0.2972, 0.3339, 0.3289, 0.3551, 0.0876, 0.3403, 0.3233,\n",
      "         0.3300, 0.3605, 0.3621, 0.3471, 0.3133, 0.3668, 0.3414, 0.3286, 0.3598]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3284, 0.3330, 0.3279, 0.3325, 0.3367, 0.3310, 0.3218, 0.2870, 0.3152,\n",
      "         0.3293, 0.3407, 0.3308, 0.3370, 0.3303, 0.3123, 0.2864, 0.3085, 0.3248]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3421, 0.3424, 0.3233, 0.3408, 0.3406, 0.3402, 0.3410, 0.3308, 0.2796,\n",
      "         0.3423, 0.3406, 0.3257, 0.3418, 0.3057, 0.3168, 0.3213, 0.2755, 0.3402]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3522, 0.3473, 0.3591, 0.3475, 0.2043, 0.3570, 0.3527, 0.3412, 0.3488,\n",
      "         0.2972, 0.3553, 0.3389, 0.3270, 0.3061, 0.3042, 0.2921, 0.3000, 0.3504]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3471, 0.3227, 0.3560, 0.3574, 0.2543, 0.3570, 0.3542, 0.3450, 0.3442,\n",
      "         0.3028, 0.3548, 0.3306, 0.3389, 0.3031, 0.3377, 0.2935, 0.2733, 0.3445]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3327, 0.3460, 0.3375, 0.3430, 0.2617, 0.3539, 0.3521, 0.3477, 0.3404,\n",
      "         0.2980, 0.3479, 0.3408, 0.3389, 0.3118, 0.3181, 0.2855, 0.3095, 0.3382]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3741, 0.4022, 0.3413, 0.2857, 0.3425, 0.3457, 0.3692, 0.4052, 0.2513,\n",
      "         0.3354, 0.3902, 0.0686, 0.3668, 0.3348, 0.2910, 0.3284, 0.3322, 0.3056]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3723, 0.4094, 0.3371, 0.2771, 0.3441, 0.3469, 0.3733, 0.4013, 0.2025,\n",
      "         0.3563, 0.3855, 0.0647, 0.3609, 0.3426, 0.3224, 0.2967, 0.3382, 0.3196]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "current 0.999377965927124 / max 1.027773380279541 /batch_mean 0.934921383857727 /batch_max 1.0132970809936523 \n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3942, 0.4286, 0.3626, 0.3111, 0.3618, 0.3501, 0.3953, 0.4197, 0.2059,\n",
      "         0.3661, 0.3960, 0.0561, 0.3567, 0.3631, 0.3244, 0.3118, 0.3703, 0.3679]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3942, 0.4286, 0.3626, 0.3111, 0.3618, 0.3501, 0.3953, 0.4197, 0.2059,\n",
      "         0.3661, 0.3960, 0.0561, 0.3567, 0.3631, 0.3244, 0.3118, 0.3703, 0.3679]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3448, 0.3424, 0.3154, 0.3459, 0.3007, 0.3275, 0.3380, 0.3353, 0.3372,\n",
      "         0.3387, 0.3312, 0.3320, 0.3223, 0.3387, 0.3165, 0.3350, 0.3457, 0.3318]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3339, 0.3472, 0.2746, 0.3405, 0.3288, 0.3359, 0.3407, 0.3212, 0.3418,\n",
      "         0.3327, 0.3399, 0.3363, 0.3338, 0.3421, 0.3358, 0.3238, 0.3427, 0.3199]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.2710, 0.3158, 0.3603, 0.3857, 0.3965, 0.3361, 0.3802, 0.3489, 0.3638,\n",
      "         0.3806, 0.3452, 0.3364, 0.3801, 0.3608, 0.3385, 0.0653, 0.3591, 0.1832]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3124, 0.3420, 0.3785, 0.3810, 0.3893, 0.3392, 0.3825, 0.3520, 0.3689,\n",
      "         0.3724, 0.3377, 0.3320, 0.3912, 0.3628, 0.3433, 0.0596, 0.3639, 0.3254]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3530, 0.3295, 0.3635, 0.3716, 0.3366, 0.3464, 0.3470, 0.3332, 0.3508,\n",
      "         0.3453, 0.3436, 0.3280, 0.3838, 0.3515, 0.3267, 0.0750, 0.3679, 0.3313]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3471, 0.3406, 0.3420, 0.3440, 0.2612, 0.3390, 0.3332, 0.3336, 0.3427,\n",
      "         0.3345, 0.3371, 0.3400, 0.3394, 0.3325, 0.3418, 0.3343, 0.3412, 0.3438]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3431, 0.3279, 0.3424, 0.3400, 0.3209, 0.3400, 0.3384, 0.3303, 0.3415,\n",
      "         0.3375, 0.3268, 0.3412, 0.3442, 0.3309, 0.3391, 0.2609, 0.3387, 0.3315]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3426, 0.3332, 0.3412, 0.3301, 0.3446, 0.3085, 0.3385, 0.3152, 0.3268,\n",
      "         0.3393, 0.3270, 0.3284, 0.3419, 0.3154, 0.3285, 0.2987, 0.3445, 0.3402]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3436, 0.3134, 0.3376, 0.3350, 0.3419, 0.3051, 0.3386, 0.3223, 0.3385,\n",
      "         0.3369, 0.3174, 0.3175, 0.3439, 0.3314, 0.3175, 0.3188, 0.3424, 0.3339]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "current 0.9406276941299438 / max 1.0324344635009766 /batch_mean 0.8073760271072388 /batch_max 0.9987949728965759 \n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3462, 0.3356, 0.3438, 0.3345, 0.3349, 0.2828, 0.3449, 0.2965, 0.3406,\n",
      "         0.3313, 0.3204, 0.3232, 0.3238, 0.3418, 0.3175, 0.3262, 0.3321, 0.3332]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3462, 0.3356, 0.3438, 0.3345, 0.3349, 0.2828, 0.3449, 0.2965, 0.3406,\n",
      "         0.3313, 0.3204, 0.3232, 0.3238, 0.3418, 0.3175, 0.3262, 0.3321, 0.3332]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3461, 0.3326, 0.3429, 0.3087, 0.2973, 0.2660, 0.3439, 0.2619, 0.3236,\n",
      "         0.3213, 0.3413, 0.3467, 0.3237, 0.3286, 0.2321, 0.2615, 0.3405, 0.3339]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3560, 0.3474, 0.3593, 0.3366, 0.3086, 0.2977, 0.3521, 0.2207, 0.2917,\n",
      "         0.3254, 0.3465, 0.3555, 0.3208, 0.3433, 0.2668, 0.1139, 0.3470, 0.3600]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3448, 0.3176, 0.3414, 0.3371, 0.3206, 0.3013, 0.3384, 0.3017, 0.3288,\n",
      "         0.3350, 0.2590, 0.3429, 0.3370, 0.3321, 0.3223, 0.3062, 0.3442, 0.3505]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3374, 0.3447, 0.3389, 0.3393, 0.3312, 0.3390, 0.3168, 0.2993, 0.3006,\n",
      "         0.3452, 0.3360, 0.3351, 0.3400, 0.3379, 0.3418, 0.2938, 0.3454, 0.3420]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3359, 0.3411, 0.3432, 0.3250, 0.3264, 0.3395, 0.3350, 0.3315, 0.2834,\n",
      "         0.3456, 0.3375, 0.3386, 0.3396, 0.3162, 0.3311, 0.3238, 0.3443, 0.3469]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3405, 0.3158, 0.3458, 0.3414, 0.3232, 0.3212, 0.3270, 0.2557, 0.3278,\n",
      "         0.3484, 0.3409, 0.3477, 0.3500, 0.3119, 0.3309, 0.3117, 0.3389, 0.3305]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3271, 0.3365, 0.3461, 0.3521, 0.3460, 0.2876, 0.3363, 0.1123, 0.3517,\n",
      "         0.3613, 0.3482, 0.3540, 0.3332, 0.3477, 0.3295, 0.2548, 0.3470, 0.3476]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.3296, 0.3367, 0.3358, 0.3391, 0.2917, 0.3014, 0.3013, 0.1316, 0.3541,\n",
      "         0.3504, 0.3500, 0.3462, 0.3195, 0.3389, 0.3421, 0.3128, 0.3421, 0.3253]],\n",
      "       grad_fn=<AddBackward0>)                 covar_outputscale 0.0010000175097957253                 noise 0.010000010021030903\n",
      "##############################\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/grid_kernel.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/grid_kernel.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39m#model.initialize(**hypers)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/grid_kernel.ipynb#ch0000002?line=4'>5</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,n_steps)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/grid_kernel.ipynb#ch0000002?line=5'>6</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mrun(report_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:18\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, report_freq)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=13'>14</a>\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=17'>18</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=19'>20</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m report_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=21'>22</a>\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain_targets\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/gibo/optim.py:100\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=97'>98</a>\u001b[0m \u001b[39m# Sample locally to optimize gradient information\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=98'>99</a>\u001b[0m bounds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelta]]) \u001b[39m+\u001b[39m theta_i\n\u001b[0;32m--> <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=99'>100</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize_information(objective_env,model,bounds)\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=101'>102</a>\u001b[0m \u001b[39m# Take one step in direction of the gradient\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=102'>103</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_gradient_step(model, theta_i)\n",
      "File \u001b[0;32m~/Desktop/explo/src/gibo/optim.py:45\u001b[0m, in \u001b[0;36mGIBOptimizer.optimize_information\u001b[0;34m(self, objective_env, model, bounds)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=33'>34</a>\u001b[0m new_x, _ \u001b[39m=\u001b[39m botorch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39moptimize_acqf(\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=34'>35</a>\u001b[0m     acq_function\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradInfo,\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=35'>36</a>\u001b[0m     bounds\u001b[39m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=40'>41</a>\u001b[0m     return_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=41'>42</a>\u001b[0m     sequential\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=43'>44</a>\u001b[0m \u001b[39m# Update training points.\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=44'>45</a>\u001b[0m new_y,new_s \u001b[39m=\u001b[39m objective_env(new_x)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=45'>46</a>\u001b[0m model\u001b[39m.\u001b[39mupdate_train_data(new_x,new_y,new_s, strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=46'>47</a>\u001b[0m model\u001b[39m.\u001b[39mposterior(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtheta_i)  \u001b[39m## hotfix\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/explo/src/environment.py:77\u001b[0m, in \u001b[0;36mEnvironmentObjective.__call__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/environment.py?line=75'>76</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, params: torch\u001b[39m.\u001b[39mTensor) :\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/environment.py?line=76'>77</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(params)\n",
      "File \u001b[0;32m~/Desktop/explo/src/environment.py:133\u001b[0m, in \u001b[0;36mEnvironmentObjective.run\u001b[0;34m(self, params, render, test)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=128'>129</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_steps):  \u001b[39m# rollout\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=129'>130</a>\u001b[0m     \n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=130'>131</a>\u001b[0m     \u001b[39m#### no need for grads here\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=131'>132</a>\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///home/q123/Desktop/explo/src/environment.py?line=132'>133</a>\u001b[0m         actions[t] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(params,states[t]\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=133'>134</a>\u001b[0m         \u001b[39m#actions[t] = self.mlp(params,states[t])\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=134'>135</a>\u001b[0m     \u001b[39m###########################\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/Desktop/explo/src/environment.py?line=136'>137</a>\u001b[0m     state, rewards[t], done, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(actions[t]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1046'>1047</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1047'>1048</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1048'>1049</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1049'>1050</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1050'>1051</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1051'>1052</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1052'>1053</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/explo/src/policy.py:81\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, params, states)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=76'>77</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,params,states):\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=78'>79</a>\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMLP : params \u001b[39m\u001b[39m{\u001b[39;00mparams\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m states \u001b[39m\u001b[39m{\u001b[39;00mstates\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/policy.py?line=80'>81</a>\u001b[0m     weights,biases \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_weights(params)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=81'>82</a>\u001b[0m     outputs \u001b[39m=\u001b[39m states\u001b[39m.\u001b[39mT\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=83'>84</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i,(w,b) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=84'>85</a>\u001b[0m                         \u001b[39mzip\u001b[39m(weights,biases)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=85'>86</a>\u001b[0m                         ):\n",
      "File \u001b[0;32m~/Desktop/explo/src/policy.py:58\u001b[0m, in \u001b[0;36mMLP.create_weights\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=55'>56</a>\u001b[0m start \u001b[39m=\u001b[39m deepcopy(end)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=56'>57</a>\u001b[0m end   \u001b[39m=\u001b[39m deepcopy(start)  \u001b[39m+\u001b[39m (in_size \u001b[39m*\u001b[39m out_size)\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/policy.py?line=57'>58</a>\u001b[0m weight \u001b[39m=\u001b[39m params[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m,start:end]\u001b[39m.\u001b[39;49mreshape(\u001b[39m*\u001b[39;49mparams\u001b[39m.\u001b[39;49mshape[:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],out_size,in_size)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=59'>60</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_bias:\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/policy.py?line=61'>62</a>\u001b[0m     bias \u001b[39m=\u001b[39m params[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,end:end\u001b[39m+\u001b[39mout_size]\u001b[39m.\u001b[39mreshape(\u001b[39m*\u001b[39mparams\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],out_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model,objective_env = setup_experiment(env_name,model_config,n_init)\n",
    "#optimizer = BOptimizer()\n",
    "optimizer = GIBOptimizer(model)\n",
    "#model.initialize(**hypers)\n",
    "trainer = Trainer(model,objective_env,optimizer,n_steps)\n",
    "trainer.run(report_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prior_mean': 0.0,\n",
       " 'ard_num_dims': 'dim_search_space',\n",
       " 'N_max': 32,\n",
       " 'lengthscale_constraint': {'constraint': None, 'kwargs': None},\n",
       " 'lengthscale_hyperprior': {'prior': gpytorch.priors.torch_priors.UniformPrior,\n",
       "  'kwargs': {'a': 0.01, 'b': 0.3}},\n",
       " 'outputscale_constraint': {'constraint': gpytorch.constraints.constraints.GreaterThan,\n",
       "  'kwargs': {'lower_bound': 0.001}},\n",
       " 'outputscale_hyperprior': {'prior': gpytorch.priors.torch_priors.NormalPrior,\n",
       "  'kwargs': {'loc': 2.0, 'scale': 1.0}},\n",
       " 'noise_constraint': {'constraint': None, 'kwargs': None},\n",
       " 'noise_hyperprior': {'prior': None, 'kwargs': None}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = \"/home/q123/Desktop/explo/configs/swimmer.yaml\"\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "        cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Translate config dictionary.\n",
    "cfg = insert(cfg, insertion_config)\n",
    "model_config = cfg[\"optimizer_config\"][\"model_config\"]\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
