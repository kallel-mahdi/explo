{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "\n",
    "import torch \n",
    "import logging\n",
    "import logging.config\n",
    "\n",
    "import yaml\n",
    "\n",
    "from src.config import insertion_config,insert\n",
    "from src.helpers import setup_experiment\n",
    "from src.trainer import Trainer\n",
    "from src.gibo.optim import GIBOptimizer\n",
    "from src.optim import BOptimizer\n",
    "\n",
    "logging.config.fileConfig('logging.conf')\n",
    "# create root logger\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Swimmer-v2\"\n",
    "kernel_name = \"rbf\"\n",
    "n_init = 2\n",
    "n_steps = 200\n",
    "\n",
    "\n",
    "import gpytorch \n",
    "\n",
    "model_config = {\n",
    "        \"prior_mean\":0,\n",
    "        \"ard_num_dims\":18,\n",
    "        \"N_max\":32,\n",
    "        # \"lengthscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.001),\n",
    "        #\"lengthscale_hyperprior\":gpytorch.priors.torch_priors.UniformPrior(a=0.01,b=0.3),\n",
    "        \"lengthscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        \"outputscale_constraint\":gpytorch.constraints.constraints.GreaterThan(0.001),\n",
    "        \"outputscale_hyperprior\":gpytorch.priors.torch_priors.NormalPrior(loc=2.0,scale=1.0),\n",
    "        \"noise_constraint\":None,\n",
    "        \"noise_hyperprior\":None,\n",
    "        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment Swimmer-v2 is out of date. You should consider upgrading to version `v3` with the environment ID `Swimmer-v3`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 2.0                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[1.9997, 2.0151, 2.0176, 2.0135, 2.0514, 2.0192, 2.0177, 2.0232, 2.0090,\n",
      "         0.4631, 2.0352, 2.0190, 2.0190, 2.0409, 2.0637, 1.9579, 2.0174, 2.0198]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.005731678102165461                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[1.9393, 2.1404, 1.7687, 2.1149, 1.7566, 1.1593, 2.0191, 1.8973, 2.0340,\n",
      "         1.7639, 2.1189, 2.1226, 2.1234, 2.1130, 0.4033, 2.0735, 1.9811, 1.8287]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.05945008248090744                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[1.7705, 2.0854, 1.7236, 2.1964, 1.8514, 2.1417, 2.0329, 2.1314, 2.0898,\n",
      "         1.3941, 2.1272, 2.2287, 1.1813, 1.4260, 0.4175, 2.0695, 2.1512, 1.3860]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.10419643670320511                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[1.8991, 1.9814, 2.0801, 2.0315, 1.5980, 0.2827, 0.1765, 0.2301, 2.0381,\n",
      "         2.1226, 2.0205, 2.0458, 2.0241, 0.6856, 0.2062, 2.0843, 1.7585, 1.9917]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.09213416278362274                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.5505, 0.4452, 1.7693, 2.0005, 1.9930, 0.3098, 0.1811, 0.1548, 2.0680,\n",
      "         2.1343, 1.6731, 2.1080, 1.9434, 2.1225, 1.6556, 2.1128, 1.9670, 2.0705]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.11272458732128143                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.6804, 1.2373, 1.1258, 2.1802, 2.0238, 0.2990, 0.1641, 0.1828, 2.1620,\n",
      "         2.1482, 1.9583, 2.1014, 2.1874, 2.1213, 2.1096, 2.1548, 2.1045, 2.0437]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.09501103311777115                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[0.5017, 0.4331, 0.4124, 2.1008, 2.1079, 2.0242, 2.0115, 2.0279, 2.0864,\n",
      "         2.0882, 2.0647, 2.0998, 2.0967, 2.0717, 2.0710, 2.1022, 2.0853, 1.9997]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.02978166751563549                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[1.9716, 1.9695, 1.9806, 2.0048, 2.0042, 1.9973, 2.0025, 2.0015, 2.0034,\n",
      "         1.9944, 2.0011, 2.0016, 1.9993, 1.9973, 2.0035, 2.0019, 2.0029, 1.9796]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.0010000821202993393                 noise 0.009999999776482582\n",
      "##############################\n",
      "current 0.6874987483024597 / max 0.7970696091651917 /batch_mean 0.6759383082389832 /batch_max 0.7970696091651917 \n",
      "##############################\n",
      "covar_lengthscale tensor([[2.0211, 2.0291, 2.0291, 2.0200, 2.0233, 1.9930, 2.0177, 2.0198, 2.0061,\n",
      "         2.0207, 2.0081, 2.0275, 1.9986, 1.9975, 2.0113, 2.0071, 2.0246, 0.1619]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.0010000825859606266                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[2.0211, 2.0291, 2.0291, 2.0200, 2.0233, 1.9930, 2.0177, 2.0198, 2.0061,\n",
      "         2.0207, 2.0081, 2.0275, 1.9986, 1.9975, 2.0113, 2.0071, 2.0246, 0.1619]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.0010000825859606266                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[2.0208, 2.0196, 2.0219, 2.0175, 2.0198, 1.9957, 2.0187, 2.0169, 2.0001,\n",
      "         2.0175, 2.0069, 2.0244, 1.9951, 1.9897, 2.0072, 2.0037, 2.0233, 0.1727]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.0010000827023759484                 noise 0.009999999776482582\n",
      "##############################\n",
      "TRUNCAAATING OLD DATAAAAAAAAAA\n",
      "##############################\n",
      "covar_lengthscale tensor([[2.0147, 2.0099, 2.0156, 2.0097, 2.0133, 1.9698, 2.0102, 2.0090, 1.9765,\n",
      "         2.0027, 1.9863, 2.0130, 1.9709, 1.9739, 2.0008, 1.9912, 2.0136, 0.1507]],\n",
      "       grad_fn=<SoftplusBackward>)                 covar_outputscale 0.001000082935206592                 noise 0.009999999776482582\n",
      "##############################\n",
      "root : DEBUG : Fitting failed on try 1.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to manually set a parameter value that is out of bounds of its current constraints, Positive(). Most likely, you want to do the following:\n likelihood = GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(better_lower_bound))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/grid_kernel.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/grid_kernel.ipynb#ch0000002?line=3'>4</a>\u001b[0m \u001b[39m#model.initialize(**hypers)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/grid_kernel.ipynb#ch0000002?line=4'>5</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model,objective_env,optimizer,n_steps)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/grid_kernel.ipynb#ch0000002?line=5'>6</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mrun(report_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/explo/src/trainer.py:18\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self, report_freq)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=13'>14</a>\u001b[0m objective_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective_env  \n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_steps):\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=17'>18</a>\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep(model,objective_env)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=19'>20</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m report_freq \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m i\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mreport_freq:\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/trainer.py?line=21'>22</a>\u001b[0m         \u001b[39mmax\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain_targets\u001b[39m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/Desktop/explo/src/gibo/optim.py:89\u001b[0m, in \u001b[0;36mGIBOptimizer.step\u001b[0;34m(self, model, objective_env)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=86'>87</a>\u001b[0m \u001b[39m# Adjust hyperparameters\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=87'>88</a>\u001b[0m mll \u001b[39m=\u001b[39m ExactMarginalLogLikelihood(model\u001b[39m.\u001b[39mlikelihood, model)\n\u001b[0;32m---> <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=88'>89</a>\u001b[0m fit_gpytorch_model(mll)\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=89'>90</a>\u001b[0m \u001b[39m# Restrict data to only recent points\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/q123/Desktop/explo/src/gibo/optim.py?line=90'>91</a>\u001b[0m last_x \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtrain_inputs[\u001b[39m0\u001b[39m][\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mN_max:]\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/fit.py:128\u001b[0m, in \u001b[0;36mfit_gpytorch_model\u001b[0;34m(mll, optimizer, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/fit.py?line=125'>126</a>\u001b[0m \u001b[39mif\u001b[39;00m retry \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# use normal initial conditions on first try\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/fit.py?line=126'>127</a>\u001b[0m     mll\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_state_dict(original_state_dict)\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/fit.py?line=127'>128</a>\u001b[0m     sample_all_priors(mll\u001b[39m.\u001b[39;49mmodel)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/fit.py?line=128'>129</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/fit.py?line=129'>130</a>\u001b[0m     mll, _ \u001b[39m=\u001b[39m optimizer(mll, track_iterations\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py:44\u001b[0m, in \u001b[0;36msample_all_priors\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=39'>40</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=40'>41</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust provide inverse transform to be able to sample from prior.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=41'>42</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=42'>43</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=43'>44</a>\u001b[0m     setting_closure(module, prior\u001b[39m.\u001b[39;49msample(closure(module)\u001b[39m.\u001b[39;49mshape))\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=44'>45</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=45'>46</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=46'>47</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`rsample` not implemented for \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(prior)\u001b[39m}\u001b[39;00m\u001b[39m. Skipping.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=47'>48</a>\u001b[0m         BotorchWarning,\n\u001b[1;32m     <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/botorch/optim/utils.py?line=48'>49</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:175\u001b[0m, in \u001b[0;36mKernel.__init__.<locals>.<lambda>\u001b[0;34m(m, v)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=171'>172</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(lengthscale_prior, Prior):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=172'>173</a>\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected gpytorch.priors.Prior but got \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(lengthscale_prior)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=173'>174</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_prior(\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=174'>175</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlengthscale_prior\u001b[39m\u001b[39m\"\u001b[39m, lengthscale_prior, \u001b[39mlambda\u001b[39;00m m: m\u001b[39m.\u001b[39mlengthscale, \u001b[39mlambda\u001b[39;00m m, v: m\u001b[39m.\u001b[39;49m_set_lengthscale(v)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=175'>176</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=177'>178</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister_constraint(\u001b[39m\"\u001b[39m\u001b[39mraw_lengthscale\u001b[39m\u001b[39m\"\u001b[39m, lengthscale_constraint)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=179'>180</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_module \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py:258\u001b[0m, in \u001b[0;36mKernel._set_lengthscale\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=254'>255</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(value):\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=255'>256</a>\u001b[0m     value \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(value)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_lengthscale)\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/kernels/kernel.py?line=257'>258</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize(raw_lengthscale\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_lengthscale_constraint\u001b[39m.\u001b[39;49minverse_transform(value))\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py:103\u001b[0m, in \u001b[0;36mModule.initialize\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=100'>101</a>\u001b[0m constraint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconstraint_for_parameter_name(name)\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=101'>102</a>\u001b[0m \u001b[39mif\u001b[39;00m constraint \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constraint\u001b[39m.\u001b[39menforced \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m constraint\u001b[39m.\u001b[39mcheck_raw(val):\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=102'>103</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=103'>104</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempting to manually set a parameter value that is out of bounds of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=104'>105</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mits current constraints, \u001b[39m\u001b[39m{\u001b[39;00mconstraint\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=105'>106</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMost likely, you want to do the following:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m likelihood = GaussianLikelihood\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=106'>107</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(noise_constraint=gpytorch.constraints.GreaterThan(better_lower_bound))\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=107'>108</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=108'>109</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/gpytorch/module.py?line=109'>110</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(name)\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcopy_(val\u001b[39m.\u001b[39mexpand_as(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattr__\u001b[39m(name)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to manually set a parameter value that is out of bounds of its current constraints, Positive(). Most likely, you want to do the following:\n likelihood = GaussianLikelihood(noise_constraint=gpytorch.constraints.GreaterThan(better_lower_bound))"
     ]
    }
   ],
   "source": [
    "\n",
    "model,objective_env = setup_experiment(env_name,model_config,n_init)\n",
    "#optimizer = BOptimizer()\n",
    "optimizer = GIBOptimizer(model)\n",
    "#model.initialize(**hypers)\n",
    "trainer = Trainer(model,objective_env,optimizer,n_steps)\n",
    "trainer.run(report_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prior_mean': 0.0,\n",
       " 'ard_num_dims': 'dim_search_space',\n",
       " 'N_max': 32,\n",
       " 'lengthscale_constraint': {'constraint': None, 'kwargs': None},\n",
       " 'lengthscale_hyperprior': {'prior': gpytorch.priors.torch_priors.UniformPrior,\n",
       "  'kwargs': {'a': 0.01, 'b': 0.3}},\n",
       " 'outputscale_constraint': {'constraint': gpytorch.constraints.constraints.GreaterThan,\n",
       "  'kwargs': {'lower_bound': 0.001}},\n",
       " 'outputscale_hyperprior': {'prior': gpytorch.priors.torch_priors.NormalPrior,\n",
       "  'kwargs': {'loc': 2.0, 'scale': 1.0}},\n",
       " 'noise_constraint': {'constraint': None, 'kwargs': None},\n",
       " 'noise_hyperprior': {'prior': None, 'kwargs': None}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_file = \"/home/q123/Desktop/explo/configs/swimmer.yaml\"\n",
    "\n",
    "with open(config_file, 'r') as f:\n",
    "        cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "# Translate config dictionary.\n",
    "cfg = insert(cfg, insertion_config)\n",
    "model_config = cfg[\"optimizer_config\"][\"model_config\"]\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
