{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo/\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.environment import EnvironmentObjective\n",
    "\n",
    "\n",
    "\n",
    "class BasicNumGrad:\n",
    "    \n",
    "    def __init__(self, env, policy,policy_params,\n",
    "                 params_per_step,episodes_per_param,n_workers):\n",
    "        \n",
    "        self.env_obj = EnvironmentObjective(env, policy)\n",
    "        self.policy_params = policy_params\n",
    "        self.optimizer = torch.optim.Adam([self.policy_params])\n",
    "        \n",
    "        \n",
    "    def approx_grad(self, sigma=1e-1, roll_per_parms=10, param_per_step=10):\n",
    "        \n",
    "        policy_params = self.policy_params\n",
    "        all_e, all_f = [], []\n",
    "        \n",
    "        for k in range(param_per_step):\n",
    "            \n",
    "            all_e.append(torch.randn_like(policy_params) * sigma)\n",
    "            self.env_obj.mlp.set_weights(policy_params + all_e[-1])\n",
    "            all_f.append(self.env_obj.run_many(None, roll_per_parms)[0].item())\n",
    "\n",
    "            # mirror perturbation\n",
    "            all_e.append(-all_e[-1])\n",
    "            self.env_obj.mlp.set_weights(policy_params + all_e[-1])\n",
    "            all_f.append(self.env_obj.run_many(None, roll_per_parms)[0].item())\n",
    "\n",
    "        nb_evals = len(all_f)\n",
    "\n",
    "        # weights = np.asarray(all_f)\n",
    "        # weights = (weights - weights.mean())  # also seems to do ok\n",
    "        weights = np.argsort(all_f).argsort() / (nb_evals - 1) - .5\n",
    "\n",
    "        return sum([w * e for w, e in zip(weights, all_e)]) / sigma / nb_evals, mu, all_f\n",
    "\n",
    "    def optimize(self, step_size=1e-3, nb_steps=100, **approx_grad_kwargs):\n",
    "        for k in range(nb_steps):\n",
    "            grad, old_par, evals = self.approx_grad(**approx_grad_kwargs)\n",
    "            print(f'iteration {k}, mean {sum(evals)/len(evals)} max {max(evals)}')\n",
    "            adam_grad = self.adamize(grad, k + 1)\n",
    "            self.env_obj.mlp.set_weights(old_par + step_size * adam_grad)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     torch.set_num_threads(1)\n",
    "#     # env = gym.make('Pendulum-v1')\n",
    "#     env = gym.make('Walker2DBulletEnv-v0')\n",
    "#     mlp = MLPSequential([env.observation_space.shape[0], 64, 64, env.action_space.shape[0]])\n",
    "\n",
    "#     # num grad\n",
    "#     optimizer = BasicNumGrad(env, mlp)\n",
    "#     optimizer.optimize(step_size=1e-3, nb_steps=500, sigma=2e-2, roll_per_parms=10, param_per_step=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class ESOptimizer(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self,env,params_init,sigma,episodes_per_param):\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def run_noisy_params(env,params,\n",
    "                        seed,sigma,episodes_per_param):\n",
    "        \n",
    "        \"\"\" Generate and run a pair of symmetric noisy parameters\n",
    "\n",
    "        Returns:\n",
    "            weighted_noise: J(theta+eps)*eps\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Generate noisy parameters\n",
    "        ## Noise is different for each seed\n",
    "        torch.manual_seed(seed)\n",
    "        eps = torch.randn_like(params) * sigma\n",
    "        \n",
    "        params1 = params + eps\n",
    "        params2 = params - eps ## symmetric noise\n",
    "\n",
    "        tmp_env = deepcopy(env)\n",
    "        rewards1,states1 = tmp_env.run_many(params1,episodes_per_param)\n",
    "        rewards2,states2 = tmp_env.run_many(params2,episodes_per_param)\n",
    "        \n",
    "        weighted_noise = (1/sigma)*(rewards1*eps - rewards2*eps)*0.5 ## \n",
    "        \n",
    "        return weighted_noise\n",
    "\n",
    "\n",
    "\n",
    "    def compute_gradient(env,params,sigma,\n",
    "                    params_per_step,episodes_per_param,n_workers=None):\n",
    "\n",
    "        args = [(env,params,i,1,episodes_per_param) for i in range(params_per_step)]\n",
    "        \n",
    "        # Step 1: Init multiprocessing.Pool()\n",
    "\n",
    "        if n_workers is None : n_workers = mp.cpu_count()\n",
    "        pool = mp.Pool(n_workers)\n",
    "\n",
    "        # Step 2:  Run processes (we might need to use mapreduce to avoid big memory usage)\n",
    "        weighted_noises = pool.starmap(run_noisy_params,args) ## list of [(reward,eps)]\n",
    "\n",
    "        # Step 3: Wait for workers to run then close pool\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "        gradient  = torch.vstack(weighted_noises).mean(dim=0)\n",
    "        \n",
    "        return gradient\n",
    "    \n",
    "    \n",
    "    def step(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n",
      "MathLog.src.helpers : WARNING : MLP dimensions : [8, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:69: UserWarning: \u001b[33mWARN: Agent's minimum action space value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:73: UserWarning: \u001b[33mWARN: Agent's maximum action space value is infinity. This is probably too high\u001b[0m\n",
      "  logger.warn(\n",
      "/home/q123/miniconda3/envs/boptim/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ard_num_dims = 18\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo/\n",
    "from src.helpers import setup_experiment\n",
    "from src.config import get_configs\n",
    "import torch\n",
    "\n",
    "env_name = \"Swimmer-v4\"\n",
    "kernel_name = \"rbf\"\n",
    "\n",
    "env_config,likelihood_config,kernel_config,optimizer_config,trainer_config = get_configs(env_name,kernel_name)\n",
    "_,env = setup_experiment(env_config,kernel_config,likelihood_config,additional_layers=[])\n",
    "\n",
    "\n",
    "# grad = compute_gradient(env,torch.zeros(18),sigma=1e-2,\n",
    "#                 params_per_step=50,episodes_per_param=1,n_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0076,  0.0013, -0.0323, -0.0074, -0.0014, -0.0015, -0.0093,  0.0106,\n",
      "        -0.0187,  0.0316, -0.0071, -0.0038,  0.0127, -0.0035,  0.0080, -0.0112,\n",
      "         0.0071, -0.0030])\n",
      "tensor([ 6.6228e-03, -8.3212e-04, -2.4226e-02, -7.8172e-03,  5.2993e-03,\n",
      "        -5.2986e-03, -9.9881e-05,  1.2232e-02, -2.4621e-02,  3.5464e-02,\n",
      "        -9.2076e-03, -3.2949e-03,  9.3940e-03, -4.2922e-03,  1.3703e-02,\n",
      "        -5.1019e-03,  3.0720e-03, -2.1394e-03])\n"
     ]
    }
   ],
   "source": [
    "grad1 = compute_gradient(env,torch.zeros(18),sigma=1e-6,\n",
    "                params_per_step=200,episodes_per_param=5,n_workers=8)\n",
    "\n",
    "grad2 = compute_gradient(env,torch.zeros(18),sigma=1e-6,\n",
    "                params_per_step=400,episodes_per_param=5,n_workers=8)\n",
    "\n",
    "print(grad1)\n",
    "print(grad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7038)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(grad2/grad1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('boptim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8389904c907846b71296796d17b1509d31543c622799a32225d90d0bb5700220"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
