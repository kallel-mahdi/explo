{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Linear,Sequential,Identity\n",
    "from typing import Tuple, List, Callable, Union, Optional\n",
    "from itertools import chain\n",
    "import torch\n",
    "\n",
    "class MLP():\n",
    "    \n",
    "    def __init__(\n",
    "                self,\n",
    "                Ls: List[int],\n",
    "                add_bias: bool = False,\n",
    "                nonlinearity: Optional[Callable] = None,\n",
    "                ):\n",
    "        \n",
    "        \"\"\"Inits MLP.\"\"\"\n",
    "\n",
    "        self.Ls = Ls\n",
    "        self.add_bias = add_bias\n",
    "        self.weight_sizes  = [(in_size,out_size)\n",
    "                                for in_size, out_size in zip(Ls[:-1], Ls[1:])]\n",
    "        if self.add_bias :\n",
    "            \n",
    "            self.bias_sizes = [(out_size)\n",
    "                                for  out_size in Ls[1:]  ]\n",
    "        \n",
    "        self.len_params = sum(\n",
    "            [\n",
    "                (in_size + 1 * add_bias) * out_size\n",
    "                for in_size, out_size in zip(Ls[:-1], Ls[1:])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if nonlinearity is None: \n",
    "            self.nonlinearity = Identity\n",
    "    \n",
    "    def reset_weights(self,net,params):\n",
    "        \n",
    "        start,end = (0,0)\n",
    "        \n",
    "        for layer,(in_size,out_size) in zip(net,self.weight_sizes):\n",
    "            \n",
    "            start = end\n",
    "            end   = start  + (in_size * out_size)\n",
    "            end   = start + in_size * out_size        \n",
    "            \n",
    "            weight_params = params[start:end].reshape(out_size,in_size)\n",
    "            layer.weight.data = weight_params\n",
    "            \n",
    "            if self.add_bias : \n",
    "                bias_params = params[end: end+ out_size].reshape(out_size)\n",
    "                end = end + out_size\n",
    "                layer.bias.data = bias_params\n",
    "        \n",
    "        return net \n",
    "    \n",
    "    def build_net(self):\n",
    "        \n",
    "        ### initialize deep layers\n",
    "        layer_list = [ [Linear(in_size,out_size,bias=self.add_bias),self.nonlinearity]\n",
    "                        for (in_size,out_size) in self.weight_sizes[:-1]]\n",
    "        \n",
    "        ### last layer has no nonlinearity\n",
    "        layer_list.append([Linear(*self.weight_sizes[-1],bias=self.add_bias)])\n",
    "        \n",
    "        ### initialize model\n",
    "        net = Sequential(*chain(*layer_list))\n",
    "        \n",
    "        return net\n",
    "\n",
    "        \n",
    "    def __call__(self,states,params):\n",
    "        \n",
    "        \n",
    "        ### we initialize network at each call (maybe reset network in future)\n",
    "        net = self.build_net()\n",
    "        #############\n",
    "        net = self.reset_weights(net,params)\n",
    "        \n",
    "        return net(states)\n",
    "    \n",
    "    \n",
    "mlp = MLP([8,2],add_bias=True)\n",
    "params = torch.rand(mlp.len_params)\n",
    "states = torch.rand(10,5,8)\n",
    "mlp(states,params).size()\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
