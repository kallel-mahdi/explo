{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/q123/Desktop/explo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd /home/q123/Desktop/explo\n",
    "from src.policy import MLP\n",
    "from src.environment import EnvironmentObjective\n",
    "\n",
    "import torch\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.linalg import norm\n",
    "mlp = MLP([3,1])\n",
    "\n",
    "# Initialize environment\n",
    "\n",
    "objective_env = EnvironmentObjective(\n",
    "  env=gym.make(\"Pendulum-v1\"),\n",
    "  policy=mlp,\n",
    "  manipulate_state=None,\n",
    "  manipulate_reward=None,\n",
    ")\n",
    "states = objective_env.get_grid()\n",
    "\n",
    "### initialize train_x, train_y\n",
    "train_x = torch.rand(1,100,mlp.len_params) ## [n_trials,n_params]\n",
    "test_x = torch.rand(1,1,mlp.len_params) ## acquisition point\n",
    "\n",
    "#params_batch = torch.hstack([train_x,test_x])\n",
    "params_batch = test_x\n",
    "A  = [norm(mlp(states,p))\n",
    "                for p in params_batch.flatten(end_dim=-2)\n",
    "                ]\n",
    "\n",
    "gradient = torch.autograd.grad(outputs=A[0], inputs=test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.5545, 0.2673, 0.4952]]), tensor([1.]))\n"
     ]
    }
   ],
   "source": [
    "states = torch.rand(1,3,requires_grad=False)\n",
    "net = torch.nn.Linear(3,1)\n",
    "test_x = torch.ones(3,1,requires_grad=True)\n",
    "net.weight.data = torch.nn.Parameter(test_x.T)\n",
    "\n",
    "A =torch.sum(net(states))\n",
    "gradient = torch.autograd.grad(outputs=A,inputs=net.parameters())\n",
    "print(gradient)\n",
    "# print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None,)\n"
     ]
    }
   ],
   "source": [
    "states = torch.rand(1,3,requires_grad=False)\n",
    "net = torch.nn.Linear(3,1)\n",
    "test_x = torch.ones(3,1,requires_grad=True)\n",
    "net.weight.data = test_x.T\n",
    "#############################\n",
    "\n",
    "A =torch.sum(net(states))\n",
    "gradient = torch.autograd.grad(outputs=A,inputs=test_x,allow_unused=True)\n",
    "print(gradient)\n",
    "# print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(torch.nn.Module):\n",
    "    def __init__(self,parameters):\n",
    "        \n",
    "        self.net = \n",
    "        \n",
    "        \n",
    "    def forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Function\n",
    "\n",
    "MLP(Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx,input,params):\n",
    "        ctx.save_for_backward(ctx,input,params)\n",
    "        output = self.net(params)\n",
    "        \n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx,input,params):\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/q123/Desktop/explo/experiments/bucket.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/bucket.ipynb#ch0000028?line=4'>5</a>\u001b[0m \u001b[39m#############################\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/bucket.ipynb#ch0000028?line=6'>7</a>\u001b[0m A \u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msum(net(states))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/bucket.ipynb#ch0000028?line=7'>8</a>\u001b[0m gradient \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(outputs\u001b[39m=\u001b[39;49mA,inputs\u001b[39m=\u001b[39;49mtest_x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/bucket.ipynb#ch0000028?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(gradient)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/q123/Desktop/explo/experiments/bucket.ipynb#ch0000028?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(states)\n",
      "File \u001b[0;32m~/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py:226\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=222'>223</a>\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=223'>224</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=225'>226</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=226'>227</a>\u001b[0m     outputs, grad_outputs_, retain_graph, create_graph,\n\u001b[1;32m    <a href='file:///home/q123/miniconda3/envs/explo/lib/python3.8/site-packages/torch/autograd/__init__.py?line=227'>228</a>\u001b[0m     inputs, allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "states = torch.rand(1,3,requires_grad=False)\n",
    "net = torch.nn.Linear(3,1)\n",
    "test_x = torch.ones(3,1,requires_grad=True)\n",
    "net.weight.data = torch.nn.Parameter(test_x.T)\n",
    "#############################\n",
    "\n",
    "A =torch.sum(net(states))\n",
    "gradient = torch.autograd.grad(outputs=A,inputs=test_x)\n",
    "print(gradient)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.1829],\n",
      "        [0.9422],\n",
      "        [0.8886]]),)\n",
      "tensor([[0.1829, 0.9422, 0.8886]])\n"
     ]
    }
   ],
   "source": [
    "states = torch.rand(1,3,requires_grad=False)\n",
    "net = torch.rand(3,1,requires_grad=True)\n",
    "A = torch.sum(states@net)\n",
    "gradient = torch.autograd.grad(outputs=A,inputs=net)\n",
    "print(gradient)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.8859, 2.6932, 1.9828, 0.8859, 2.6932, 1.9828, 0.8859, 2.6932,\n",
      "          1.9828, 1.8540, 1.8540, 1.8540, 1.8540, 1.8540, 1.8540, 1.8540,\n",
      "          1.8540, 1.8540, 0.0000]]]),)\n"
     ]
    }
   ],
   "source": [
    "states = torch.rand(1,3,requires_grad=False)\n",
    "a = torch.ones(1,1,19,requires_grad=True)\n",
    "mini_a = a[:,:,:9].reshape(a.shape[:-1]+(3,3))\n",
    "mini_b = a[:,:,9:18].reshape(a.shape[:-1]+(3,3))\n",
    "A = torch.sum(mini_b@mini_a@states.T)\n",
    "gradient = torch.autograd.grad(outputs=A,inputs=a)\n",
    "gradient[0].shape\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b54cb4d83655428105eabb77a9cd1898504607119e0ebf088afaf3437f4d048"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('explo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
